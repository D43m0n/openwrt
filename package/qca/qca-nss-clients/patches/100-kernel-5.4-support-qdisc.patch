diff -uprN nss-clients-old/nss_qdisc/igs/Makefile nss-clients/nss_qdisc/igs/Makefile
--- nss-clients-old/nss_qdisc/igs/Makefile	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/igs/Makefile	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,10 @@
+# Makefile for IGS (Ingress Shaping)
+
+ccflags-y += $(NSS_CCFLAGS) -I$(obj)/../../exports
+ccflags-y += -DNSS_IGS_DEBUG_LEVEL=2
+ccflags-y += -Wall -Werror
+
+obj-m += act_nssmirred.o
+act_nssmirred-objs := \
+		      nss_mirred.o \
+		      nss_ifb.o
diff -uprN nss-clients-old/nss_qdisc/igs/nss_ifb.c nss-clients/nss_qdisc/igs/nss_ifb.c
--- nss-clients-old/nss_qdisc/igs/nss_ifb.c	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/igs/nss_ifb.c	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,621 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2019-2020 The Linux Foundation. All rights reserved.
+ * Permission to use, copy, modify, and/or distribute this software for
+ * any purpose with or without fee is hereby granted, provided that the
+ * above copyright notice and this permission notice appear in all copies.
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
+ * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#include <nss_api_if.h>
+#include <nss_cmn.h>
+#include <net/netfilter/nf_conntrack_dscpremark_ext.h>
+#include "nss_mirred.h"
+#include "nss_igs.h"
+#include "nss_ifb.h"
+
+/*
+ * TODO: Current implementation only supports one IFB interface to be mapped with
+ * any one interface at a time. This has to be changed to support the mapping of
+ * an IFB device to multiple interfaces.
+ */
+static LIST_HEAD(nss_ifb_list);			/* List of IFB and its mapped interface */
+static DEFINE_SPINLOCK(nss_ifb_list_lock);	/* Lock for the ifb list */
+
+/*
+ * nss_ifb_msg_response
+ *	NSS firmware message response structure.
+ */
+static struct nss_ifb_msg_response {
+	struct semaphore sem;
+	wait_queue_head_t wq;
+	enum nss_cmn_response response;
+	bool cond;
+} msg_response;
+
+/*
+ * nss_ifb_igs_ip_pre_routing_hook()
+ *	Copy class-id to Linux CT structure.
+ *
+ * Copy class-id from tc_index field of skb in ingress QoS fields inside
+ * DSCP CT extention structure.
+ */
+unsigned int nss_ifb_igs_ip_pre_routing_hook(void *priv, struct sk_buff *skb,
+		 const struct nf_hook_state *state)
+{
+	struct nf_conn *ct;
+	struct nf_ct_dscpremark_ext *dscpcte;
+	enum ip_conntrack_info ctinfo;
+
+	if (unlikely(!skb))
+		return NF_ACCEPT;
+
+	/*
+	 * Return if ingress qostag value (saved in tc_index field) is 0.
+	 */
+	if (likely(!skb->tc_index))
+		return NF_ACCEPT;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+		return NF_ACCEPT;
+
+	spin_lock_bh(&ct->lock);
+	dscpcte = nf_ct_dscpremark_ext_find(ct);
+	if (!dscpcte) {
+		spin_unlock_bh(&ct->lock);
+		return NF_ACCEPT;
+	}
+
+	/*
+	 * Copy ingress qostag value (saved in tc_index) to ingress
+	 * qostag fields of DSCP CT extension structure.
+	 */
+	if (IP_CT_DIR_ORIGINAL == CTINFO2DIR(ctinfo)) {
+		dscpcte->igs_flow_qos_tag = skb->tc_index;
+	} else {
+		dscpcte->igs_reply_qos_tag = skb->tc_index;
+	}
+	spin_unlock_bh(&ct->lock);
+
+	/*
+	 * Reset the tc_index field as it no longer required.
+	 */
+	skb->tc_index = 0;
+	return NF_ACCEPT;
+}
+
+/*
+ * nss_ifb_list_del()
+ *	API to delete member in ifb list.
+ */
+void nss_ifb_list_del(struct nss_ifb_info *ifb_info)
+{
+	spin_lock_bh(&nss_ifb_list_lock);
+	list_del(&ifb_info->map_list);
+	spin_unlock_bh(&nss_ifb_list_lock);
+}
+
+/*
+ * nss_ifb_list_add()
+ *	API to add member in ifb list.
+ */
+static void nss_ifb_list_add(struct nss_ifb_info *ifb_info)
+{
+	spin_lock_bh(&nss_ifb_list_lock);
+	list_add(&(ifb_info->map_list), &nss_ifb_list);
+	spin_unlock_bh(&nss_ifb_list_lock);
+}
+
+/*
+ * nss_ifb_is_mapped()
+ *	Returns the map status of the given ifb bind structure.
+ */
+bool nss_ifb_is_mapped(struct nss_ifb_info *ifb_info)
+{
+	bool is_mapped;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	is_mapped = ifb_info->is_mapped;
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return is_mapped;
+}
+
+/*
+ * nss_ifb_config_msg_init()
+ *	Initialize IFB configure interface's message.
+ */
+static void nss_ifb_config_msg_init(struct nss_if_msg *ncm, uint16_t if_num,
+		 uint32_t type,  uint32_t len, void *cb, void *app_data)
+{
+	nss_cmn_msg_init(&ncm->cm, if_num, type, len, cb, app_data);
+}
+
+/*
+ * nss_ifb_clear_config_cb()
+ *	CLEAR configure handler for an IFB mapped interface.
+ */
+static void nss_ifb_clear_config_cb(void *app_data, struct nss_if_msg *nim)
+{
+	struct nss_ifb_info *ifb_info = (struct nss_ifb_info *)app_data;
+	bool ret;
+
+	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
+		nss_igs_error("Response error: %d\n", nim->cm.response);
+		return;
+	}
+
+	do {
+		ret = spin_trylock_bh(&nss_ifb_list_lock);
+	} while (!ret);
+	ifb_info->is_mapped = false;
+	spin_unlock_bh(&nss_ifb_list_lock);
+}
+
+/*
+ * nss_ifb_async_cb()
+ *	IFB asynchronous handler for an IFB mapped interface.
+ */
+static void nss_ifb_async_cb(void *app_data, struct nss_if_msg *nim)
+{
+	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
+		nss_igs_error("Response error: %d\n", nim->cm.response);
+	}
+}
+
+/*
+ * nss_ifb_wake_up_cb()
+ *	IFB wake up handler for an IFB mapped interface.
+ */
+static void nss_ifb_wake_up_cb(void *app_data, struct nss_if_msg *nim)
+{
+	msg_response.response = nim->cm.response;
+	msg_response.cond = 0;
+	wake_up(&msg_response.wq);
+}
+
+/*
+ * nss_ifb_config_msg_fill()
+ *	Fill the IFB configure message.
+ */
+static bool nss_ifb_config_msg_fill(struct nss_if_msg *nim_ptr, struct net_device *dev,
+		int32_t ifb_num, enum nss_ifb_if_config config, void *cb)
+{
+	uint32_t if_src_num;
+
+	if (netif_is_ifb_dev(dev)) {
+		if_src_num = nss_cmn_get_interface_number_by_dev_and_type(dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+		if (if_src_num < 0) {
+			nss_igs_error("invalid IFB device %s\n", dev->name);
+			return -1;
+		}
+	} else {
+		if_src_num = nss_cmn_get_interface_number_by_dev(dev);
+		if (if_src_num < 0) {
+			nss_igs_error("invalid device %s\n", dev->name);
+			return -1;
+		}
+	}
+
+	switch (config) {
+	case NSS_IFB_SET_IGS_NODE:
+		nss_ifb_config_msg_init(nim_ptr, if_src_num, NSS_IF_SET_IGS_NODE,
+			sizeof(struct nss_if_igs_config), nss_ifb_wake_up_cb, cb);
+		nim_ptr->msg.config_igs.igs_num = ifb_num;
+		break;
+	case NSS_IFB_CLEAR_IGS_NODE:
+		nss_ifb_config_msg_init(nim_ptr, if_src_num, NSS_IF_CLEAR_IGS_NODE,
+			sizeof(struct nss_if_igs_config), nss_ifb_clear_config_cb, cb);
+		nim_ptr->msg.config_igs.igs_num = ifb_num;
+		break;
+	case NSS_IFB_SET_NEXTHOP:
+		nss_ifb_config_msg_init(nim_ptr, if_src_num, NSS_IF_SET_NEXTHOP,
+			sizeof(struct nss_if_set_nexthop), nss_ifb_wake_up_cb, cb);
+		nim_ptr->msg.set_nexthop.nexthop = ifb_num;
+		break;
+	case NSS_IFB_RESET_NEXTHOP:
+		nss_ifb_config_msg_init(nim_ptr, if_src_num, NSS_IF_RESET_NEXTHOP,
+			sizeof(struct nss_if_set_nexthop), nss_ifb_async_cb, cb);
+		nim_ptr->msg.set_nexthop.nexthop = ifb_num;
+		break;
+	case NSS_IFB_OPEN:
+		nss_ifb_config_msg_init(nim_ptr, if_src_num, NSS_IF_OPEN,
+			sizeof(struct nss_if_open), nss_ifb_async_cb, cb);
+		/*
+		 * Reset the elements of interface's open configuration.
+		 */
+		memset (&nim_ptr->msg.open, 0, sizeof(struct nss_if_open));
+		break;
+	case NSS_IFB_CLOSE:
+		nss_ifb_config_msg_init(nim_ptr, if_src_num, NSS_IF_CLOSE,
+			sizeof(struct nss_if_close), nss_ifb_async_cb, cb);
+		/*
+		 * Reset the elements of interface's close configuration.
+		 */
+		memset (&nim_ptr->msg.close, 0, sizeof(struct nss_if_close));
+		break;
+	}
+
+	return 0;
+}
+
+/*
+ * nss_ifb_config_msg_tx()
+ *	Send IFB configure message to an IFB mapped interface.
+ */
+int32_t nss_ifb_config_msg_tx(struct net_device *dev, int32_t ifb_num,
+		 enum nss_ifb_if_config config, void *cb)
+{
+	struct nss_if_msg nim;
+	int32_t ret;
+
+	if ((ret = nss_ifb_config_msg_fill(&nim, dev, ifb_num, config, cb))) {
+		nss_igs_error("Error in setting up IFB %d config message\n", config);
+		return -1;
+	}
+
+	ret = nss_if_tx_msg(nss_igs_get_context(), &nim);
+	if (ret != NSS_TX_SUCCESS) {
+		nss_igs_error("failed to send config message\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+/*
+ * nss_ifb_config_msg_tx_sync()
+ *	Send IFB configure message to an IFB mapped interface and wait for the response.
+ */
+int32_t nss_ifb_config_msg_tx_sync(struct net_device *dev, int32_t ifb_num,
+		 enum nss_ifb_if_config config, void *cb)
+{
+	struct nss_if_msg nim;
+	int32_t ret;
+
+	if ((ret = nss_ifb_config_msg_fill(&nim, dev, ifb_num, config, cb))) {
+		nss_igs_error("Error in setting up IFB %d config message\n", config);
+		return -1;
+	}
+
+	down(&msg_response.sem);
+	ret = nss_if_tx_msg(nss_igs_get_context(), &nim);
+	if (ret != NSS_TX_SUCCESS) {
+		up(&msg_response.sem);
+		nss_igs_error("failed to send config message\n");
+		return -1;
+	}
+
+	msg_response.cond = 1;
+	if (!wait_event_timeout(msg_response.wq, msg_response.cond == 0, NSS_IFB_MSG_TIMEOUT)) {
+		nss_igs_error("config for attach interface msg timeout\n");
+		up(&msg_response.sem);
+		return -1;
+	} else if (msg_response.response != NSS_CMN_RESPONSE_ACK) {
+		up(&msg_response.sem);
+		nss_igs_error("config for attach interface msg return with response: %d\n", msg_response.response);
+		return -1;
+	}
+
+	up(&msg_response.sem);
+	return 0;
+}
+
+/*
+ * nss_ifb_reset_nexthop()
+ *	Send RESET NEXTHOP configure message to an IFB mapped interface.
+ */
+bool nss_ifb_reset_nexthop(struct nss_ifb_info *ifb_info)
+{
+	int32_t if_num;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	if (!(ifb_info->is_mapped)) {
+		nss_igs_info("%s IFB device mapped flag is not set\n", ifb_info->ifb_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return true;
+	}
+
+	/*
+	 * Send RESET NEXTHOP config message to the mapped interface.
+	 */
+	if_num = nss_cmn_get_interface_number_by_dev_and_type(ifb_info->ifb_dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (if_num < 0) {
+		nss_igs_error("No %s IFB device found in NSS firmware\n", ifb_info->ifb_dev->name);
+	}
+
+	if (nss_ifb_config_msg_tx(ifb_info->map_dev, if_num, NSS_IFB_RESET_NEXTHOP, NULL) < 0) {
+		nss_igs_error("Sending RESET NEXTHOP config to %s dev failed\n", ifb_info->map_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return false;
+	}
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return true;
+}
+
+/*
+ * nss_ifb_down()
+ *	Send interface's DOWN configure message to an IFB interface.
+ */
+bool nss_ifb_down(struct nss_ifb_info *ifb_info)
+{
+	int32_t ifb_num;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	if (!(ifb_info->is_mapped)) {
+		nss_igs_info("%s IFB device mapped flag is not set\n", ifb_info->ifb_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return true;
+	}
+
+	/*
+	 * Send interface's DOWN config message to an IFB interface.
+	 */
+	ifb_num = nss_cmn_get_interface_number_by_dev_and_type(ifb_info->ifb_dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (ifb_num < 0) {
+		nss_igs_error("No %s IFB device found in NSS FW\n", ifb_info->ifb_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return false;
+	}
+
+	if (nss_ifb_config_msg_tx(ifb_info->ifb_dev, ifb_num, NSS_IFB_CLOSE, ifb_info) < 0) {
+		nss_igs_error("Sending unassign to %s dev failed\n", ifb_info->map_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return false;
+	}
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return true;
+}
+
+/*
+ * nss_ifb_up()
+ *	Send interface's UP configure message to an IFB interface.
+ */
+bool nss_ifb_up(struct nss_ifb_info *ifb_info)
+{
+	int32_t ifb_num;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	if (!(ifb_info->is_mapped)) {
+		nss_igs_info("%s IFB device mapped flag is not set\n", ifb_info->ifb_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return true;
+	}
+
+	/*
+	 * Send interface's UP config message to an IFB interface.
+	 */
+	ifb_num = nss_cmn_get_interface_number_by_dev_and_type(ifb_info->ifb_dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (ifb_num < 0) {
+		nss_igs_error("No %s IFB device found in NSS FW\n", ifb_info->ifb_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return false;
+	}
+
+	if (nss_ifb_config_msg_tx(ifb_info->ifb_dev, ifb_num, NSS_IFB_OPEN, ifb_info) < 0) {
+		nss_igs_error("Sending unassign to %s dev failed\n", ifb_info->map_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return false;
+	}
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return true;
+}
+
+/*
+ * nss_ifb_clear_igs_node()
+ *	Send CLEAR configure message to an IFB mapped interface.
+ */
+bool nss_ifb_clear_igs_node(struct nss_ifb_info *ifb_info)
+{
+	int32_t if_num;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	if (!(ifb_info->is_mapped)) {
+		nss_igs_info("%s IFB device mapped flag is not set\n", ifb_info->ifb_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return true;
+	}
+
+	/*
+	 * Send CLEAR config message to the mapped interface.
+	 */
+	if_num = nss_cmn_get_interface_number_by_dev_and_type(ifb_info->ifb_dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (if_num < 0) {
+		nss_igs_error("No %s IFB device found in NSS firmware\n", ifb_info->ifb_dev->name);
+	}
+
+	if (nss_ifb_config_msg_tx(ifb_info->map_dev, if_num, NSS_IFB_CLEAR_IGS_NODE, ifb_info) < 0) {
+		nss_igs_error("Sending unassign to %s dev failed\n", ifb_info->map_dev->name);
+		spin_unlock_bh(&nss_ifb_list_lock);
+		return false;
+	}
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return true;
+}
+
+/*
+ * nss_ifb_init()
+ *	Initialization API.
+ */
+void nss_ifb_init()
+{
+	sema_init(&msg_response.sem, 1);
+	init_waitqueue_head(&msg_response.wq);
+}
+
+/*
+ * nss_ifb_find_map_dev()
+ *	Find and return the IFB mapped netdev in the ifb list.
+ */
+struct nss_ifb_info *nss_ifb_find_map_dev(struct net_device *dev)
+{
+	struct nss_ifb_info *ifb_info;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	list_for_each_entry(ifb_info, &nss_ifb_list, map_list) {
+		if (ifb_info->map_dev == dev) {
+			spin_unlock_bh(&nss_ifb_list_lock);
+			return ifb_info;
+		}
+	}
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return NULL;
+}
+
+/*
+ * nss_ifb_find_dev()
+ *	Find and return the IFB netdev in the ifb list.
+ */
+struct nss_ifb_info *nss_ifb_find_dev(struct net_device *dev)
+{
+	struct nss_ifb_info *ifb_info;
+
+	spin_lock_bh(&nss_ifb_list_lock);
+	list_for_each_entry(ifb_info, &nss_ifb_list, map_list) {
+		if (ifb_info->ifb_dev == dev) {
+			spin_unlock_bh(&nss_ifb_list_lock);
+			return ifb_info;
+		}
+	}
+	spin_unlock_bh(&nss_ifb_list_lock);
+	return NULL;
+}
+
+/*
+ * nss_ifb_bind()
+ *	API to bind an IFB device with its requested mapped interface.
+ */
+int32_t nss_ifb_bind(struct nss_ifb_info *ifb_info, struct net_device *from_dev,
+		struct net_device *to_dev)
+{
+	if (!ifb_info) {
+		/*
+		 * IFB not present in local LL.
+		 * Add the entry in LL.
+		 */
+		ifb_info = kmalloc(sizeof(*ifb_info), GFP_KERNEL);
+		if (!ifb_info) {
+			nss_igs_error("kmalloc failed\n");
+			return -ENOMEM;
+		}
+		ifb_info->ifb_dev = to_dev;
+		ifb_info->map_dev = from_dev;
+		ifb_info->is_mapped = true;
+		nss_ifb_list_add(ifb_info);
+	} else {
+		/*
+		 * IFB present in local LL and its is_mapped is not set.
+		 * make the ifb_info's is_mapped to true again.
+		 */
+		spin_lock_bh(&nss_ifb_list_lock);
+		ifb_info->map_dev = from_dev;
+		ifb_info->is_mapped = true;
+		spin_unlock_bh(&nss_ifb_list_lock);
+	}
+	return 0;
+}
+
+/*
+ * nss_ifb_update_dev_stats()
+ *	IFB stats function to copy the common stats to the netdevice.
+ */
+static void nss_ifb_update_dev_stats(struct net_device *dev, struct nss_igs_stats_sync_msg *sync_stats)
+{
+	struct pcpu_sw_netstats stats;
+	struct nss_cmn_node_stats *node_stats = &(sync_stats->node_stats);
+
+	if (!dev) {
+		nss_igs_error("Device is NULL\n");
+		return;
+	}
+
+	u64_stats_init(&stats.syncp);
+	u64_stats_update_begin(&stats.syncp);
+
+	/*
+	 * In NSS firmware, the IFB interface's stats are getting updated
+	 * post shaping. Therefore IFB interface's stats should be updated
+	 * with NSS firmware's IFB TX stats only.
+	 */
+	stats.rx_packets = stats.tx_packets = node_stats->tx_packets;
+	stats.rx_bytes = stats.tx_bytes = node_stats->tx_bytes;
+	dev->stats.rx_dropped = dev->stats.tx_dropped += sync_stats->igs_stats.tx_dropped;
+	u64_stats_update_end(&stats.syncp);
+
+	ifb_update_offload_stats(dev, &stats);
+}
+
+/*
+ * nss_ifb_event_cb()
+ *	Event Callback for IFB interface to receive events from NSS firmware.
+ */
+static void nss_ifb_event_cb(void *if_ctx, struct nss_cmn_msg *ncm)
+{
+	struct net_device *netdev = if_ctx;
+	struct nss_igs_msg *nim = (struct nss_igs_msg *)ncm;
+
+	switch (ncm->type) {
+	case NSS_IGS_MSG_SYNC_STATS:
+		nss_ifb_update_dev_stats(netdev, (struct nss_igs_stats_sync_msg *)&nim->msg.stats);
+		break;
+
+	default:
+		nss_igs_error("%px: Unknown Event from NSS\n", netdev);
+		break;
+	}
+}
+
+/*
+ * nss_ifb_delete_if()
+ *	Delete an IFB interface in NSS Firmware.
+ */
+void nss_ifb_delete_if(int32_t if_num)
+{
+	nss_igs_unregister_if(if_num);
+	if (nss_dynamic_interface_dealloc_node(if_num, NSS_DYNAMIC_INTERFACE_TYPE_IGS)
+			 != NSS_TX_SUCCESS) {
+		nss_igs_error("Failed to de-alloc IFB dynamic interface\n");
+	}
+}
+
+/*
+ * nss_ifb_create_if()
+ *	Create an IFB interface in NSS Firmware.
+ */
+int32_t nss_ifb_create_if(struct net_device *dev)
+{
+	int32_t if_num, ret;
+	uint32_t features = 0;
+	struct nss_ctx_instance *nss_ctx;
+
+	if_num = nss_dynamic_interface_alloc_node(NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (if_num < 0) {
+		nss_igs_error("%d interface creation failed\n", if_num);
+		return -1;
+	}
+
+	nss_ctx = nss_igs_register_if(if_num,
+			NSS_DYNAMIC_INTERFACE_TYPE_IGS,
+			nss_ifb_event_cb,
+			dev,
+			features);
+	if (!nss_ctx) {
+		nss_igs_error("%d interface registration failed\n", if_num);
+		goto registration_fail;
+	}
+	return if_num;
+
+registration_fail:
+	ret = nss_dynamic_interface_dealloc_node(if_num, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (ret != NSS_TX_SUCCESS) {
+		nss_igs_error("%d interface dealloc failed\n", if_num);
+	}
+	return -1;
+}
diff -uprN nss-clients-old/nss_qdisc/igs/nss_ifb.h nss-clients/nss_qdisc/igs/nss_ifb.h
--- nss-clients-old/nss_qdisc/igs/nss_ifb.h	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/igs/nss_ifb.h	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,138 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2019 The Linux Foundation. All rights reserved.
+ * Permission to use, copy, modify, and/or distribute this software for
+ * any purpose with or without fee is hereby granted, provided that the
+ * above copyright notice and this permission notice appear in all copies.
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
+ * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#define NSS_IFB_MSG_TIMEOUT (600*HZ)	/* 1 min timeout */
+
+/*
+ * nss_ifb_if_config
+ *	Types of IFB configuration messages.
+ */
+enum nss_ifb_if_config {
+	NSS_IFB_SET_IGS_NODE,
+	NSS_IFB_CLEAR_IGS_NODE,
+	NSS_IFB_SET_NEXTHOP,
+	NSS_IFB_RESET_NEXTHOP,
+	NSS_IFB_OPEN,
+	NSS_IFB_CLOSE,
+};
+
+/*
+ * nss_ifb_info
+ *	IFB and its mapped interface's bind structure.
+ */
+struct nss_ifb_info {
+	struct net_device *ifb_dev;	/* IFB device */
+	struct net_device *map_dev;	/* Device mapped to an IFB device */
+	struct list_head map_list;	/* Internal list */
+	bool is_mapped;			/* Flag to indicate whether mapping is valid or not */
+};
+
+/*
+ * nss_ifb_igs_ip_pre_routing_hook()
+ *	Copy class-id to Linux CT structure.
+ *
+ * Copy class-id from tc_index field of skb in ingress QoS fields inside
+ * DSCP CT extention structure.
+ */
+extern unsigned int nss_ifb_igs_ip_pre_routing_hook(void *priv, struct sk_buff *skb,
+		 const struct nf_hook_state *state);
+
+/*
+ * nss_ifb_list_del()
+ *	API to delete member in ifb list.
+ */
+extern void nss_ifb_list_del(struct nss_ifb_info *ifb_info);
+
+/*
+ * nss_ifb_is_mapped()
+ *	Returns the map status of the given ifb bind structure.
+ */
+extern bool nss_ifb_is_mapped(struct nss_ifb_info *ifb_info);
+
+/*
+ * nss_ifb_config_msg_tx()
+ *	Send IFB configure message to an IFB mapped interface.
+ */
+extern int32_t nss_ifb_config_msg_tx(struct net_device *dev, int32_t ifb_num,
+		 enum nss_ifb_if_config config, void *cb);
+
+/*
+ * nss_ifb_config_msg_tx_sync()
+ *	Send IFB configure message to an IFB mapped interface and wait for the response.
+ */
+extern int32_t nss_ifb_config_msg_tx_sync(struct net_device *dev, int32_t ifb_num,
+		 enum nss_ifb_if_config config, void *cb);
+
+/*
+ * nss_ifb_reset_nexthop()
+ *	Send RESET NEXTHOP configure message to an IFB mapped interface.
+ */
+extern bool nss_ifb_reset_nexthop(struct nss_ifb_info *ifb_info);
+
+/*
+ * nss_ifb_clear_igs_node()
+ *	Send CLEAR configure message to an IFB mapped interface.
+ */
+extern bool nss_ifb_clear_igs_node(struct nss_ifb_info *ifb_info);
+
+/*
+ * nss_ifb_down()
+ *	Send interface's DOWN configure message to an IFB interface.
+ */
+extern bool nss_ifb_down(struct nss_ifb_info *ifb_info);
+
+/*
+ * nss_ifb_up()
+ *	Send interface's UP configure message to an IFB interface.
+ */
+extern bool nss_ifb_up(struct nss_ifb_info *ifb_info);
+
+/*
+ * nss_ifb_init()
+ *	Initialization API.
+ */
+extern void nss_ifb_init(void);
+
+/*
+ * nss_ifb_find_map_dev()
+ *	Find and return the IFB mapped netdev in the ifb list.
+ */
+extern struct nss_ifb_info *nss_ifb_find_map_dev(struct net_device *dev);
+
+/*
+ * nss_ifb_find_dev()
+ *	Find and return the IFB netdev in the ifb list.
+ */
+extern struct nss_ifb_info *nss_ifb_find_dev(struct net_device *dev);
+
+/*
+ * nss_ifb_bind()
+ *	API to bind an IFB device with its requested mapped interface.
+ */
+extern int32_t nss_ifb_bind(struct nss_ifb_info *ifb_info, struct net_device *from_dev,
+		struct net_device *to_dev);
+
+/*
+ * nss_ifb_delete_if()
+ *	Delete an IFB interface in NSS Firmware.
+ */
+extern void nss_ifb_delete_if(int32_t if_num);
+
+/*
+ * nss_ifb_create_if()
+ *	Create an IFB interface in NSS Firmware.
+ */
+extern int32_t nss_ifb_create_if(struct net_device *dev);
diff -uprN nss-clients-old/nss_qdisc/igs/nss_igs.h nss-clients/nss_qdisc/igs/nss_igs.h
--- nss-clients-old/nss_qdisc/igs/nss_igs.h	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/igs/nss_igs.h	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,66 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2019 The Linux Foundation. All rights reserved.
+ * Permission to use, copy, modify, and/or distribute this software for
+ * any purpose with or without fee is hereby granted, provided that the
+ * above copyright notice and this permission notice appear in all copies.
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
+ * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#define NSS_IGS_DEBUG_LEVEL_ERROR 1
+#define NSS_IGS_DEBUG_LEVEL_WARN 2
+#define NSS_IGS_DEBUG_LEVEL_INFO 3
+#define NSS_IGS_DEBUG_LEVEL_TRACE 4
+
+/*
+ * Debug message for module init and exit
+ */
+#define nss_igs_info_always(s, ...) printk(KERN_INFO"%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
+
+/*
+ * Error and warn message will be enabled by default in Makefile
+ */
+#if (NSS_IGS_DEBUG_LEVEL < NSS_IGS_DEBUG_LEVEL_ERROR)
+#define nss_igs_assert(s, ...)
+#define nss_igs_error(s, ...)
+#else
+#define nss_igs_assert(c, s, ...) { if (!(c)) { pr_emerg("ASSERT: %s:%d:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__); BUG(); } }
+#define nss_igs_error(s, ...) pr_err("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+
+#if (NSS_IGS_DEBUG_LEVEL < NSS_IGS_DEBUG_LEVEL_WARN)
+#define nss_igs_warning(s, ...)
+#else
+#define nss_igs_warning(s, ...) pr_warn("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+
+#if defined(CONFIG_DYNAMIC_DEBUG)
+/*
+ * Compile messages for dynamic enable/disable
+ */
+#define nss_igs_info(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
+#define nss_igs_trace(s, ...) pr_debug("%s[%d]:" s, __func__, __LINE__, ##__VA_ARGS__)
+
+#else
+/*
+ * Statically compile messages at different levels
+ */
+#if (NSS_IGS_DEBUG_LEVEL < NSS_IGS_DEBUG_LEVEL_INFO)
+#define nss_igs_info(s, ...)
+#else
+#define nss_igs_info(s, ...) pr_notice("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+
+#if (NSS_IGS_DEBUG_LEVEL < NSS_IGS_DEBUG_LEVEL_TRACE)
+#define nss_igs_trace(s, ...)
+#else
+#define nss_igs_trace(s, ...) pr_info("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#endif
+#endif
diff -uprN nss-clients-old/nss_qdisc/igs/nss_mirred.c nss-clients/nss_qdisc/igs/nss_mirred.c
--- nss-clients-old/nss_qdisc/igs/nss_mirred.c	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/igs/nss_mirred.c	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,769 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2019-2020 The Linux Foundation. All rights reserved.
+ * Permission to use, copy, modify, and/or distribute this software for
+ * any purpose with or without fee is hereby granted, provided that the
+ * above copyright notice and this permission notice appear in all copies.
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
+ * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#include <nss_api_if.h>
+#include <nss_cmn.h>
+#include <linux/tc_act/tc_nss_mirred.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include "nss_mirred.h"
+#include "nss_igs.h"
+#include "nss_ifb.h"
+
+static LIST_HEAD(nss_mirred_list);		/* List for all nss mirred actions */
+static DEFINE_SPINLOCK(nss_mirred_list_lock);	/* Lock for the nss mirred list */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+static unsigned int nss_mirred_net_id;		/* NSS mirror net ID */
+static struct tc_action_ops nss_mirred_act_ops;	/* NSS action mirror ops */
+#endif
+
+/*
+ * nss_mirred_release()
+ *	Cleanup the resources for nss mirred action.
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+static void nss_mirred_release(struct tc_action *tc_act, int bind)
+#else
+static void nss_mirred_release(struct tc_action *tc_act)
+#endif
+{
+	struct nss_mirred_tcf *act = nss_mirred_get(tc_act);
+	struct net_device *dev = rcu_dereference_protected(act->tcfm_dev, 1);
+	struct nss_ifb_info *ifb_info = nss_ifb_find_dev(dev);
+
+	if (!ifb_info) {
+		nss_igs_error("IFB device %s not found in the linked list \n", dev->name);
+		return;
+	}
+
+	/*
+	 * Send IFB RESET NEXTHOP configure message to the mapped interface.
+	 */
+	if (!nss_ifb_reset_nexthop(ifb_info)) {
+		nss_igs_error("Error in sending IFB RESET NEXTHOP configure message\n");
+	}
+
+	if (!nss_ifb_clear_igs_node(ifb_info)) {
+		nss_igs_error("Error in sending IFB CLEAR configure message\n");
+	}
+
+	/*
+	 * Delete the nss mirred action list.
+	 */
+	spin_lock_bh(&nss_mirred_list_lock);
+	list_del(&act->tcfm_list);
+	spin_unlock_bh(&nss_mirred_list_lock);
+	if (dev) {
+		dev_put(dev);
+	}
+}
+
+/*
+ * nss_mirred_policy
+ *	nss mirred policy structure.
+ */
+static const struct nla_policy nss_mirred_policy[TC_NSS_MIRRED_MAX + 1] = {
+	[TC_NSS_MIRRED_PARMS] = { .len = sizeof(struct tc_nss_mirred) },
+};
+
+/*
+ * nss_mirred_init()
+ *	Initialize the nss mirred action.
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+static int nss_mirred_init(struct net *net, struct nlattr *nla,
+			   struct nlattr *est, struct tc_action *tc_act, int ovr,
+			   int bind)
+{
+#else
+static int nss_mirred_init(struct net *net, struct nlattr *nla,
+			   struct nlattr *est, struct tc_action **tc_act, int ovr,
+			   int bind, bool rtnl_held, struct tcf_proto *tp,
+			   struct netlink_ext_ack *extack)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+	u32 index;
+#endif
+	struct nlattr *arr[TC_NSS_MIRRED_MAX + 1];
+	struct tc_nss_mirred *parm;
+	struct nss_mirred_tcf *act;
+	struct net_device *to_dev, *from_dev;
+	struct nss_ifb_info *ifb_info;
+	int32_t ret, ifb_num;
+
+	if (!nla) {
+		return -EINVAL;
+	}
+
+	/*
+	 * Parse and validate the user configurations.
+	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 2, 0))
+	ret = nla_parse_nested(arr, TC_NSS_MIRRED_MAX, nla, nss_mirred_policy);
+#else
+	ret = nla_parse_nested_deprecated(arr, TC_NSS_MIRRED_MAX, nla, nss_mirred_policy, extack);
+#endif
+	if (ret < 0) {
+		return ret;
+	}
+	if (!arr[TC_NSS_MIRRED_PARMS]) {
+		return -EINVAL;
+	}
+
+	parm = nla_data(arr[TC_NSS_MIRRED_PARMS]);
+	if (!parm->from_ifindex || !parm->to_ifindex) {
+		nss_igs_error("Invalid ifindex: from_ifindex: %u, to_ifindex: %u\n",
+				parm->from_ifindex, parm->to_ifindex);
+		return -EINVAL;
+	}
+
+	from_dev = __dev_get_by_index(net, parm->from_ifindex);
+	if (!from_dev) {
+		nss_igs_error("No device found for %u ifindex\n", parm->from_ifindex);
+		return -ENODEV;
+	}
+
+	if (nss_cmn_get_interface_number_by_dev(from_dev) < 0) {
+		nss_igs_error("No NSS FW device found for %s\n", from_dev->name);
+		return -ENODEV;
+	}
+
+	if (netif_is_ifb_dev(from_dev)) {
+		nss_igs_error("IFB device %s as from_dev\n", from_dev->name);
+		return -ENODEV;
+	}
+
+	to_dev = __dev_get_by_index(net, parm->to_ifindex);
+	if (!to_dev) {
+		nss_igs_error("No device found for %u ifindex\n", parm->to_ifindex);
+		return -ENODEV;
+	}
+
+	if (!netif_is_ifb_dev(to_dev)) {
+		nss_igs_error("%s is not an IFB device\n", to_dev->name);
+		return -ENODEV;
+	}
+
+	ifb_info = nss_ifb_find_map_dev(from_dev);
+	if (ifb_info) {
+		if (nss_ifb_is_mapped(ifb_info)) {
+			nss_igs_error("%s device is already mapped to the other IFB device\n",
+					from_dev->name);
+			return -EEXIST;
+		}
+	}
+
+	ifb_info = nss_ifb_find_dev(to_dev);
+	if (ifb_info) {
+		if (nss_ifb_is_mapped(ifb_info)) {
+			nss_igs_error("%s IFB device is already mapped to the other device\n",
+					to_dev->name);
+			return -EEXIST;
+		}
+	}
+
+	ifb_num = nss_cmn_get_interface_number_by_dev_and_type(to_dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+	if (ifb_num < 0) {
+		/*
+		 * Create the IFB instance in the NSS firmware.
+		 */
+		ifb_num = nss_ifb_create_if(to_dev);
+		if (ifb_num < 0) {
+			nss_igs_error("failure in IFB creation\n");
+			return -EINVAL;
+		}
+	}
+
+	/*
+	 * Send config message to the interface attached to an IFB interface.
+	 */
+	if (nss_ifb_config_msg_tx_sync(from_dev, ifb_num, NSS_IFB_SET_IGS_NODE, NULL) < 0) {
+		nss_igs_error("Sending config to %s dev failed\n", from_dev->name);
+		return -EINVAL;
+	}
+
+	/*
+	 * Send next hop config message to the interface attached to an IFB interface.
+	 */
+	if (nss_ifb_config_msg_tx_sync(from_dev, ifb_num, NSS_IFB_SET_NEXTHOP, NULL) < 0) {
+		nss_igs_error("Sending next hop config to %s dev failed\n", from_dev->name);
+		return -EINVAL;
+	}
+
+	/*
+	 * Bind an IFB device with its requested mapped interface.
+	 */
+	ret = nss_ifb_bind(ifb_info, from_dev, to_dev);
+	if (ret < 0) {
+		nss_igs_error(" Binding an IFB device failed\n");
+		nss_ifb_delete_if(ifb_num);
+		return ret;
+	}
+
+	/*
+	 * Return error if nss mirred action index is present in the hash.
+	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	if (tcf_hash_check(parm->index, tc_act, bind)) {
+		return -EEXIST;
+	}
+
+	ret = tcf_hash_create(parm->index, est, tc_act, sizeof(*act),
+			bind, true);
+	if (ret) {
+		return ret;
+	}
+
+	act = nss_mirred_get(tc_act);
+#else
+	index = parm->index;
+	ret = tcf_idr_check_alloc(tn, &index, tc_act, bind);
+	if (ret < 0) {
+		return ret;
+	}
+
+	if (ret && bind) {
+		return 0;
+	}
+
+	if (!ret) {
+		ret = tcf_idr_create(tn, index, est, tc_act, &nss_mirred_act_ops,
+				bind, true);
+		if (ret) {
+			tcf_idr_cleanup(tn, index);
+			return ret;
+		}
+	}
+
+	act = nss_mirred_get(*tc_act);
+#endif
+	/*
+	 * Fill up the nss mirred tc parameters to
+	 * its local action structure.
+	 */
+	ASSERT_RTNL();
+	act->tcf_action = parm->action;
+	act->tcfm_from_ifindex = parm->from_ifindex;
+	act->tcfm_to_ifindex = parm->to_ifindex;
+	dev_hold(to_dev);
+	rcu_assign_pointer(act->tcfm_dev, to_dev);
+
+	/*
+	 * Add the new action instance to the nss mirred action list.
+	 */
+	spin_lock_bh(&nss_mirred_list_lock);
+	list_add(&act->tcfm_list, &nss_mirred_list);
+	spin_unlock_bh(&nss_mirred_list_lock);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	tcf_hash_insert(tc_act);
+#endif
+
+	return ACT_P_CREATED;
+}
+
+/*
+ * nss_mirred_act()
+ *	nss mirred action handler.
+ */
+static int nss_mirred_act(struct sk_buff *skb, const struct tc_action *tc_act,
+		      struct tcf_result *res)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	struct nss_mirred_tcf *act = tc_act->priv;
+#else
+	struct nss_mirred_tcf *act = nss_mirred_get(tc_act);
+#endif
+	struct net_device *dev;
+	struct sk_buff *skb_new;
+	int retval, err;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	u32 skb_tc_at = G_TC_AT(skb->tc_verd);
+
+	/*
+	 * Return if skb is not at ingress.
+	 */
+	if (!(skb_tc_at & AT_INGRESS)) {
+		return TC_ACT_UNSPEC;
+	}
+
+#else
+	if (!skb_at_tc_ingress(skb)) {
+		return TC_ACT_UNSPEC;
+	}
+#endif
+
+	/*
+	 * Update the last use of action.
+	 */
+	tcf_lastuse_update(&act->tcf_tm);
+	bstats_cpu_update(this_cpu_ptr(act->common.cpu_bstats), skb);
+
+	rcu_read_lock();
+	retval = READ_ONCE(act->tcf_action);
+	dev = rcu_dereference(act->tcfm_dev);
+	if (unlikely(!dev)) {
+		nss_igs_error("tc nssmirred: target device is gone\n");
+		goto out;
+	}
+
+	if (unlikely(!(dev->flags & IFF_UP))) {
+		nss_igs_error("tc nssmirred: device %s is down\n", dev->name);
+		goto out;
+	}
+
+	/*
+	 * Redirect the packet to the attached IFB interface
+	 */
+	skb_new = skb_clone(skb, GFP_ATOMIC);
+	if (!skb_new) {
+		goto out;
+	}
+
+	skb_new->skb_iif = skb->dev->ifindex;
+	skb_new->dev = dev;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	skb_new->tc_verd = SET_TC_FROM(skb_new->tc_verd, skb_tc_at);
+	skb_push_rcsum(skb_new, skb->mac_len);
+	skb_sender_cpu_clear(skb_new);
+#else
+	skb_set_redirected(skb_new, skb_new->tc_at_ingress);
+	skb_push_rcsum(skb_new, skb->mac_len);
+#endif
+
+	err = dev_queue_xmit(skb_new);
+	if (!err) {
+		rcu_read_unlock();
+		return retval;
+	}
+out:
+	qstats_overlimit_inc(this_cpu_ptr(act->common.cpu_qstats));
+	retval = TC_ACT_SHOT;
+	rcu_read_unlock();
+	return retval;
+}
+
+/*
+ * nss_mirred_dump()
+ *	Dump the nssmirred action configurations.
+ */
+static int nss_mirred_dump(struct sk_buff *skb, struct tc_action *tc_act, int bind, int ref)
+{
+	struct tcf_t filter;
+	unsigned char *tail = skb_tail_pointer(skb);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	struct nss_mirred_tcf *act = tc_act->priv;
+#else
+	struct nss_mirred_tcf *act = nss_mirred_get(tc_act);
+#endif
+	struct tc_nss_mirred opt = {
+		.index   = act->tcf_index,
+		.action  = act->tcf_action,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+		.refcnt  = act->tcf_refcnt - ref,
+		.bindcnt = act->tcf_bindcnt - bind,
+#else
+		.refcnt  = refcount_read(&act->tcf_refcnt) - ref,
+		.bindcnt = atomic_read(&act->tcf_bindcnt) - bind,
+#endif
+		.from_ifindex = act->tcfm_from_ifindex,
+		.to_ifindex = act->tcfm_to_ifindex,
+	};
+
+	if (nla_put(skb, TC_NSS_MIRRED_PARMS, sizeof(opt), &opt)) {
+		goto out;
+	}
+	filter.install = jiffies_to_clock_t(jiffies - act->tcf_tm.install);
+	filter.lastuse = jiffies_to_clock_t(jiffies - act->tcf_tm.lastuse);
+	filter.expires = jiffies_to_clock_t(act->tcf_tm.expires);
+	if (nla_put(skb, TC_NSS_MIRRED_TM, sizeof(filter), &filter)) {
+		goto out;
+	}
+	return skb->len;
+
+out:
+	nlmsg_trim(skb, tail);
+	return -1;
+}
+
+/*
+ * nss_mirred_unregister_event_handler()
+ *	nss mirred un-register event handler.
+ */
+static void nss_mirred_unregister_event_handler(struct net_device *dev)
+{
+	struct nss_ifb_info *ifb_info;
+
+	/*
+	 * IFB interface.
+	 */
+	if (netif_is_ifb_dev(dev)) {
+		ifb_info = nss_ifb_find_dev(dev);
+	} else {
+		/*
+		 * Check if the device is an IFB mapped device.
+		 */
+		ifb_info = nss_ifb_find_map_dev(dev);
+	}
+
+	/*
+	 * Device not present in ifb list.
+	 */
+	if (!ifb_info) {
+		return;
+	}
+
+	/*
+	 * Send IFB RESET NEXTHOP configure message to the mapped interface.
+	 */
+	if (!nss_ifb_reset_nexthop(ifb_info)) {
+		nss_igs_error("Error in sending IFB RESET NEXTHOP configure message\n");
+	}
+
+	/*
+	 * Send IFB CLEAR configure message to the mapped interface.
+	 */
+	if (!nss_ifb_clear_igs_node(ifb_info)) {
+		nss_igs_error("Error in sending IFB CLEAR configure message\n");
+	}
+	if (netif_is_ifb_dev(dev)) {
+		int32_t ifb_num = nss_cmn_get_interface_number_by_dev_and_type(dev, NSS_DYNAMIC_INTERFACE_TYPE_IGS);
+
+		if (ifb_num < 0) {
+			nss_igs_error("Invalid %s IFB device\n", dev->name);
+			return;
+		}
+		nss_ifb_delete_if(ifb_num);
+		nss_ifb_list_del(ifb_info);
+	}
+}
+
+/*
+ * nss_mirred_down_event_handler()
+ *	nss mirred interface's down event handler.
+ */
+static void nss_mirred_down_event_handler(struct net_device *dev)
+{
+	struct nss_ifb_info *ifb_info;
+
+	/*
+	 * IFB interface.
+	 */
+	if (!netif_is_ifb_dev(dev)) {
+		return;
+	}
+
+	ifb_info = nss_ifb_find_dev(dev);
+
+	if (!ifb_info) {
+		return;
+	}
+
+	if (!nss_ifb_down(ifb_info)) {
+		nss_igs_error("Error in sending IFB DOWN configure message\n");
+	}
+}
+
+/*
+ * nss_mirred_up_event_handler()
+ *	nss mirred interface's up event handler.
+ */
+static void nss_mirred_up_event_handler(struct net_device *dev)
+{
+	struct nss_ifb_info *ifb_info;
+
+	/*
+	 * IFB interface.
+	 */
+	if (!netif_is_ifb_dev(dev)) {
+		return;
+	}
+
+	ifb_info = nss_ifb_find_dev(dev);
+
+	if (!ifb_info) {
+		return;
+	}
+
+	if (!nss_ifb_up(ifb_info)) {
+		nss_igs_error("Error in sending IFB UP configure message\n");
+	}
+}
+
+/*
+ * nss_mirred_device_event()
+ *	nssmirred device event callback.
+ */
+static int nss_mirred_device_event(struct notifier_block *unused,
+		unsigned long event, void *ptr)
+{
+	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
+	struct nss_mirred_tcf *act;
+
+	switch (event) {
+	case NETDEV_UNREGISTER:
+		nss_mirred_unregister_event_handler(dev);
+
+		ASSERT_RTNL();
+
+		/*
+		 * Free up the actions instance present in
+		 * the nss mirred list.
+		 */
+		spin_lock_bh(&nss_mirred_list_lock);
+		list_for_each_entry(act, &nss_mirred_list, tcfm_list) {
+			if (rcu_access_pointer(act->tcfm_dev) == dev) {
+				dev_put(dev);
+				RCU_INIT_POINTER(act->tcfm_dev, NULL);
+			}
+		}
+		spin_unlock_bh(&nss_mirred_list_lock);
+		break;
+	case NETDEV_UP:
+		nss_mirred_up_event_handler(dev);
+		break;
+	case NETDEV_DOWN:
+		nss_mirred_down_event_handler(dev);
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+/*
+ * nss_mirred_walker
+ *	nssmirred tcf_action walker
+ */
+static int nss_mirred_walker(struct net *net, struct sk_buff *skb,
+		struct netlink_callback *cb, int type,
+		const struct tc_action_ops *ops,
+		struct netlink_ext_ack *extack)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+
+	return tcf_generic_walker(tn, skb, cb, type, ops, extack);
+}
+
+/*
+ * nss_mirred_search
+ *	nssmirred search idr function.
+ */
+static int nss_mirred_search(struct net *net, struct tc_action **a, u32 index)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+
+	return tcf_idr_search(tn, a, index);
+}
+
+/*
+ * nss_mirred_dev_put
+ *	Release igs dev
+ */
+static void nss_mirred_dev_put(void *priv)
+{
+	struct net_device *dev = priv;
+
+	dev_put(dev);
+}
+
+/*
+ * nss_mirred_device
+ *	Get the igs dev.
+ */
+static struct net_device *nss_mirred_device(const struct tc_action *a, tc_action_priv_destructor *destructor)
+{
+	struct nss_mirred_tcf *m = nss_mirred_get(a);
+	struct net_device *dev;
+
+	rcu_read_lock();
+	dev = rcu_dereference(m->tcfm_dev);
+	if (dev) {
+		dev_hold(dev);
+		*destructor = nss_mirred_dev_put;
+	}
+	rcu_read_unlock();
+
+	return dev;
+}
+#endif
+
+/*
+ * nss_mirred_device_notifier
+ *	nss mirred device notifier structure.
+ */
+static struct notifier_block nss_mirred_device_notifier = {
+	.notifier_call = nss_mirred_device_event,
+};
+
+/*
+ * nss_mirred_act_ops
+ *	Registration structure for nss mirred action.
+ */
+static struct tc_action_ops nss_mirred_act_ops = {
+	.kind		=	"nssmirred",
+	.owner		=	THIS_MODULE,
+	.act		=	nss_mirred_act,
+	.dump		=	nss_mirred_dump,
+	.cleanup	=	nss_mirred_release,
+	.init		=	nss_mirred_init,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.type		=	TCA_ACT_MIRRED_NSS,
+#else
+	.id		=	TCA_ID_MIRRED_NSS,
+	.walk		=	nss_mirred_walker,
+	.lookup		=	nss_mirred_search,
+	.size           =       sizeof(struct nss_mirred_tcf),
+	.get_dev	=	nss_mirred_device
+#endif
+};
+
+/*
+ * nss_mirred_igs_nf_ops
+ *	Pre-routing hooks into netfilter packet monitoring point.
+ */
+struct nf_hook_ops nss_mirred_igs_nf_ops[] __read_mostly = {
+	/*
+	 * Pre routing hook is used to copy class-id to the ECM rule.
+	 */
+	{
+		.hook		=	nss_ifb_igs_ip_pre_routing_hook,
+		.pf		=	NFPROTO_IPV4,
+		.hooknum	=	NF_INET_PRE_ROUTING,
+		.priority	=	NF_IP_PRI_CONNTRACK + 1,
+	},
+	{
+		.hook		=	nss_ifb_igs_ip_pre_routing_hook,
+		.pf		=	NFPROTO_IPV6,
+		.hooknum	=	NF_INET_PRE_ROUTING,
+		.priority	=	NF_IP_PRI_CONNTRACK + 1,
+	},
+};
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+/*
+ * nss_mirred_init_net
+ *	nssmirred net init function.
+ */
+static __net_init int nss_mirred_init_net(struct net *net)
+{
+	struct tc_action_net *tn = net_generic(net, nss_mirred_net_id);
+	nf_register_net_hooks(net, nss_mirred_igs_nf_ops,
+			ARRAY_SIZE(nss_mirred_igs_nf_ops));
+
+	return tc_action_net_init(net, tn, &nss_mirred_act_ops);
+}
+
+/*
+ * nss_mirred_exit_net
+ *	nssmirred net exit function.
+ */
+static void __net_exit nss_mirred_exit_net(struct net *net)
+{
+	nf_unregister_net_hooks(net, nss_mirred_igs_nf_ops,
+			ARRAY_SIZE(nss_mirred_igs_nf_ops));
+}
+
+/*
+ * nss_mirred_exit_batch_net
+ *	nssmirred exit_batch_net function.
+ */
+static void __net_exit nss_mirred_exit_batch_net(struct list_head *net_list)
+{
+	tc_action_net_exit(net_list, nss_mirred_net_id);
+}
+
+/*
+ * nss_mirred_net_ops
+ *	Per netdevice ops.
+ */
+static struct pernet_operations nss_mirred_net_ops = {
+	.init = nss_mirred_init_net,
+	.exit = nss_mirred_exit_net,
+	.exit_batch = nss_mirred_exit_batch_net,
+	.id   = &nss_mirred_net_id,
+	.size = sizeof(struct tc_action_net),
+};
+#endif
+
+/*
+ * nss_mirred_init_module()
+ *	nssmirred init function.
+ */
+static int __init nss_mirred_init_module(void)
+{
+	int err = register_netdevice_notifier(&nss_mirred_device_notifier);
+	if (err) {
+		return err;
+	}
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	err = tcf_register_action(&nss_mirred_act_ops, NSS_MIRRED_TAB_MASK);
+	if (err) {
+		unregister_netdevice_notifier(&nss_mirred_device_notifier);
+		return err;
+	}
+
+	err = nf_register_hooks(nss_mirred_igs_nf_ops, ARRAY_SIZE(nss_mirred_igs_nf_ops));
+	if (err < 0) {
+		nss_igs_error("Registering ingress nf hooks failed, ret: %d\n", err);
+		tcf_unregister_action(&nss_mirred_act_ops);
+		unregister_netdevice_notifier(&nss_mirred_device_notifier);
+		return err;
+	}
+#else
+	err = tcf_register_action(&nss_mirred_act_ops, &nss_mirred_net_ops);
+	if (err) {
+		unregister_netdevice_notifier(&nss_mirred_device_notifier);
+		return err;
+	}
+#endif
+
+	/*
+	 * Set the IGS module reference variable.
+	 */
+	nss_igs_module_save(&nss_mirred_act_ops, THIS_MODULE);
+
+	nss_ifb_init();
+	return 0;
+}
+
+/*
+ * nss_mirred_cleanup_module()
+ *	nssmirred exit function.
+ */
+static void __exit nss_mirred_cleanup_module(void)
+{
+	/*
+	 * Reset the IGS module reference variable.
+	 */
+	nss_igs_module_save(&nss_mirred_act_ops, NULL);
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	nf_unregister_hooks(nss_mirred_igs_nf_ops, ARRAY_SIZE(nss_mirred_igs_nf_ops));
+
+	/*
+	 * Un-register nss mirred action.
+	 */
+	tcf_unregister_action(&nss_mirred_act_ops);
+#else
+	tcf_unregister_action(&nss_mirred_act_ops, &nss_mirred_net_ops);
+#endif
+	unregister_netdevice_notifier(&nss_mirred_device_notifier);
+}
+
+module_init(nss_mirred_init_module);
+module_exit(nss_mirred_cleanup_module);
+
+MODULE_LICENSE("Dual BSD/GPL");
diff -uprN nss-clients-old/nss_qdisc/igs/nss_mirred.h nss-clients/nss_qdisc/igs/nss_mirred.h
--- nss-clients-old/nss_qdisc/igs/nss_mirred.h	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/igs/nss_mirred.h	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,54 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2019-2020 The Linux Foundation. All rights reserved.
+ * Permission to use, copy, modify, and/or distribute this software for
+ * any purpose with or without fee is hereby granted, provided that the
+ * above copyright notice and this permission notice appear in all copies.
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
+ * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#include <linux/version.h>
+#include <net/act_api.h>
+
+#define NSS_MIRRED_TAB_MASK 7
+
+/*
+ * nss_mirred_tcf
+ *	nss mirred internal structure.
+ */
+struct nss_mirred_tcf {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	struct tcf_common common;		/* Common filter structure */
+#else
+	struct tc_action common;		/* Common filter structure */
+#endif
+	__u32 tcfm_to_ifindex;			/* Index number of device to which
+						 * traffic will be redirected.
+						 */
+	__u32 tcfm_from_ifindex;		/* Index number of device from which
+						 * traffic will be redirected.
+						 */
+	struct net_device __rcu *tcfm_dev;	/* net device pointer of the device
+						 * to which traffic will be redirected.
+						 */
+	struct list_head tcfm_list;		/* list for the nss mirred action */
+};
+
+/*
+ * To get the pointer of nss mirred action structure from the common
+ * tc_action structure pointer.
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+#define nss_mirred_get(a) \
+	container_of(a->priv, struct nss_mirred_tcf, common)
+#else
+#define nss_mirred_get(a) ((struct nss_mirred_tcf *)a)
+#endif
+
diff -uprN nss-clients-old/nss_qdisc/Makefile nss-clients/nss_qdisc/Makefile
--- nss-clients-old/nss_qdisc/Makefile	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/Makefile	2022-09-03 10:42:47.580000000 +0900
@@ -6,21 +6,25 @@ ifeq ($(SoC),$(filter $(SoC),ipq807x ipq
 ccflags-y += -DNSS_QDISC_PPE_SUPPORT -DNSS_QDISC_BRIDGE_SUPPORT
 endif
 
-ccflags-y += -Werror
+ccflags-y += -Wall -Werror
 
 obj-m += qca-nss-qdisc.o
-qca-nss-qdisc-objs := 	nss_qdisc.o \
-			nss_fifo.o \
+qca-nss-qdisc-objs := 	nss_bf.o \
+			nss_blackhole.o \
 			nss_codel.o \
-			nss_tbl.o \
-			nss_prio.o \
-			nss_bf.o \
-			nss_wrr.o \
+			nss_fifo.o \
 			nss_htb.o \
-			nss_blackhole.o \
-			nss_wred.o
+			nss_prio.o \
+			nss_qdisc.o \
+			nss_qdisc_htable.o \
+			nss_qdisc_stats.o \
+			nss_tbl.o \
+			nss_wred.o \
+			nss_wrr.o
 
 ifeq ($(SoC),$(filter $(SoC),ipq807x ipq807x_64 ipq60xx ipq60xx_64))
 qca-nss-qdisc-objs += 	nss_ppe.o \
 			nss_ppe_mc.o
 endif
+
+obj-$(igs)+= igs/
diff -uprN nss-clients-old/nss_qdisc/nss_bf.c nss-clients/nss_qdisc/nss_bf.c
--- nss-clients-old/nss_qdisc/nss_bf.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_bf.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2017 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2017, 2019-2021, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -58,7 +58,7 @@ static inline struct nss_bf_class_data *
 	struct Qdisc_class_common *clc;
 	clc = qdisc_class_find(&q->clhash, classid);
 	if (clc == NULL) {
-		nss_qdisc_info("Cannot find class with classid %u in qdisc %p hash table %p\n", classid, sch, &q->clhash);
+		nss_qdisc_info("Cannot find class with classid %u in qdisc %px hash table %px\n", classid, sch, &q->clhash);
 		return NULL;
 	}
 	return container_of(clc, struct nss_bf_class_data, cl_common);
@@ -68,12 +68,20 @@ static inline struct nss_bf_class_data *
  * nss_bf_change_class()
  *	Configures a new class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
 		  struct nlattr **tca, unsigned long *arg)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_bf_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
+		  struct nlattr **tca, unsigned long *arg, struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)*arg;
 	struct nlattr *opt = tca[TCA_OPTIONS];
+	struct nlattr *tb[TCA_NSSBF_MAX + 1];
 	struct tc_nssbf_class_qopt *qopt;
 	struct nss_if_msg nim_config;
 	struct net_device *dev = qdisc_dev(sch);
@@ -84,7 +92,12 @@ static int nss_bf_change_class(struct Qd
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, TCA_NSSBF_MAX, TCA_NSSBF_CLASS_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_CLASS_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_CLASS_PARMS, extack);
+#endif
+
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -102,7 +115,7 @@ static int nss_bf_change_class(struct Qd
 			return -EINVAL;
 		}
 
-		nss_qdisc_info("Bf class %u allocated %p\n", classid, cl);
+		nss_qdisc_info("Bf class %u allocated %px\n", classid, cl);
 		cl->cl_common.classid = classid;
 
 		/*
@@ -111,17 +124,18 @@ static int nss_bf_change_class(struct Qd
 		 * reference count should not be 0.
 		 */
 		cl->qdisc = &noop_qdisc;
-		atomic_set(&cl->nq.refcnt, 1);
+		nss_qdisc_atomic_set(&cl->nq);
 		*arg = (unsigned long)cl;
 
-		nss_qdisc_info("Adding classid %u to qdisc %p hash queue %p\n", classid, sch, &q->clhash);
+		nss_qdisc_info("Adding classid %u to qdisc %px hash queue %px\n", classid, sch, &q->clhash);
 
 		/*
 		 * This is where a class gets initialized. Classes do not have a init function
 		 * that is registered to Linux. Therefore we initialize the NSSBF_GROUP shaper
 		 * here.
 		 */
-		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_BF_GROUP, classid, accel_mode) < 0) {
+		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_BF_GROUP, classid, accel_mode, extack) < 0)
+		{
 			nss_qdisc_error("Nss init for class %u failed\n", classid);
 			kfree(cl);
 			return -EINVAL;
@@ -160,11 +174,6 @@ static int nss_bf_change_class(struct Qd
 		 */
 		qdisc_class_hash_grow(sch, &q->clhash);
 
-		/*
-		 * Start the stats polling timer
-		 */
-		nss_qdisc_start_basic_stats_polling(&cl->nq);
-
 		nss_qdisc_info("Class %u successfully allocated\n", classid);
 	}
 
@@ -229,7 +238,7 @@ static void nss_bf_destroy_class(struct
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
 	struct nss_if_msg nim;
 
-	nss_qdisc_info("Destroying bf class %p from qdisc %p\n", cl, sch);
+	nss_qdisc_info("Destroying bf class %px from qdisc %px\n", cl, sch);
 
 	/*
 	 * Note, this function gets called even for NSSBF and not just for NSSBF_GROUP.
@@ -238,8 +247,8 @@ static void nss_bf_destroy_class(struct
 	 * only for the root qdisc.
 	 */
 	if (cl == &q->root) {
-		nss_qdisc_info("We do not destroy bf class %p here since this is "
-				"the qdisc %p\n", cl, sch);
+		nss_qdisc_info("We do not destroy bf class %px here since this is "
+				"the qdisc %px\n", cl, sch);
 		return;
 	}
 
@@ -260,12 +269,7 @@ static void nss_bf_destroy_class(struct
 	/*
 	 * And now we destroy the child.
 	 */
-	qdisc_destroy(cl->qdisc);
-
-	/*
-	 * Stop the stats polling timer and free class
-	 */
-	nss_qdisc_stop_basic_stats_polling(&cl->nq);
+	 nss_qdisc_put(cl->qdisc);
 
 	/*
 	 * Destroy the shaper in NSS
@@ -300,7 +304,7 @@ static int nss_bf_delete_class(struct Qd
 	/*
 	 * The message to NSS should be sent to the parent of this class
 	 */
-	nss_qdisc_info("Detaching bf class: %p\n", cl);
+	nss_qdisc_info("Detaching bf class: %px\n", cl);
 	nim.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = q->nq.qos_tag;
 	nim.msg.shaper_configure.config.msg.shaper_node_config.snc.bf_detach.child_qos_tag = cl->nq.qos_tag;
 	if (nss_qdisc_node_detach(&q->nq, nq_child, &nim,
@@ -311,12 +315,21 @@ static int nss_bf_delete_class(struct Qd
 	sch_tree_lock(sch);
 	qdisc_reset(cl->qdisc);
 	qdisc_class_hash_remove(&q->clhash, &cl->cl_common);
-	refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+	refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
 	sch_tree_unlock(sch);
+
+	/*
+	 * For 5.4 and above kernels, calling nss_htb_destroy_class
+	 * explicitly as there is no put_class which would have called
+	 * nss_bf_destroy_class when refcnt becomes zero.
+	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0))
+	nss_bf_destroy_class(sch, cl);
+#else
 	if (!refcnt) {
-		nss_qdisc_error("Reference count should not be zero for class %p\n", cl);
+		nss_qdisc_error("Reference count should not be zero for class %px\n", cl);
 	}
-
+#endif
 	return 0;
 }
 
@@ -324,8 +337,13 @@ static int nss_bf_delete_class(struct Qd
  * nss_bf_graft_class()
  *	Replaces the qdisc attached to the provided class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
 								 struct Qdisc **old)
+#else
+static int nss_bf_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
+								 struct Qdisc **old, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)arg;
@@ -333,10 +351,10 @@ static int nss_bf_graft_class(struct Qdi
 	struct nss_if_msg nim_attach;
 	struct nss_qdisc *nq_new = qdisc_priv(new);
 
-	nss_qdisc_info("Grafting class %p\n", sch);
+	nss_qdisc_info("Grafting class %px\n", sch);
 
 	if (cl == &q->root) {
-		nss_qdisc_error("Can't graft root class %p\n", cl);
+		nss_qdisc_error("Can't graft root class %px\n", cl);
 		return -EINVAL;
 	}
 
@@ -351,10 +369,10 @@ static int nss_bf_graft_class(struct Qdi
 	 * Since we initially attached a noop qdisc as child (in Linux),
 	 * we do not perform a detach in the NSS if its a noop qdisc.
 	 */
-	nss_qdisc_info("Grafting old: %p with new: %p\n", *old, new);
+	nss_qdisc_info("Grafting old: %px with new: %px\n", *old, new);
 	if (*old != &noop_qdisc) {
 		struct nss_qdisc *nq_old = (struct nss_qdisc *)qdisc_priv(*old);
-		nss_qdisc_info("Detaching old: %p\n", *old);
+		nss_qdisc_info("Detaching old: %px\n", *old);
 		nim_detach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = cl->nq.qos_tag;
 		if (nss_qdisc_node_detach(&cl->nq, nq_old, &nim_detach,
 				NSS_SHAPER_CONFIG_TYPE_SHAPER_NODE_DETACH) < 0) {
@@ -367,7 +385,7 @@ static int nss_bf_graft_class(struct Qdi
 	 * to the NSS.
 	 */
 	if (new != &noop_qdisc) {
-		nss_qdisc_info("Attaching new: %p\n", new);
+		nss_qdisc_info("Attaching new: %px\n", new);
 		nim_attach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = cl->nq.qos_tag;
 		nim_attach.msg.shaper_configure.config.msg.shaper_node_config.snc.bf_group_attach.child_qos_tag = nq_new->qos_tag;
 		if (nss_qdisc_node_attach(&cl->nq, nq_new, &nim_attach,
@@ -393,7 +411,7 @@ static int nss_bf_graft_class(struct Qdi
 static struct Qdisc *nss_bf_leaf_class(struct Qdisc *sch, unsigned long arg)
 {
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)arg;
-	nss_qdisc_info("bf class leaf %p\n", cl);
+	nss_qdisc_info("bf class leaf %px\n", cl);
 
 	/*
 	 * Since all nss_bf groups are leaf nodes, we can always
@@ -408,13 +426,14 @@ static struct Qdisc *nss_bf_leaf_class(s
  */
 static void nss_bf_qlen_notify(struct Qdisc *sch, unsigned long arg)
 {
-	nss_qdisc_info("bf qlen notify %p\n", sch);
+	nss_qdisc_info("bf qlen notify %px\n", sch);
 	/*
 	 * Gets called when qlen of child changes (Useful for deactivating)
 	 * Not useful for us here.
 	 */
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 /*
  * nss_bf_get_class()
  *	Fetches the class pointer if provided the classid.
@@ -423,7 +442,7 @@ static unsigned long nss_bf_get_class(st
 {
 	struct nss_bf_class_data *cl = nss_bf_find_class(classid, sch);
 
-	nss_qdisc_info("Get bf class %p - class match = %p\n", sch, cl);
+	nss_qdisc_info("Get bf class %px - class match = %px\n", sch, cl);
 
 	if (cl != NULL)
 		atomic_add(1, &cl->nq.refcnt);
@@ -438,16 +457,30 @@ static unsigned long nss_bf_get_class(st
 static void nss_bf_put_class(struct Qdisc *sch, unsigned long arg)
 {
 	struct nss_bf_class_data *cl = (struct nss_bf_class_data *)arg;
-	nss_qdisc_info("bf put class for %p\n", cl);
+	nss_qdisc_info("bf put class for %px\n", cl);
 
 	/*
 	 * We are safe to destroy the qdisc if the reference count
 	 * goes down to 0.
 	 */
-	if (atomic_sub_return(1, &cl->nq.refcnt) == 0) {
+	if (nss_qdisc_atomic_sub_return(&cl->nq) == 0) {
 		nss_bf_destroy_class(sch, cl);
 	}
 }
+#else
+/*
+ * nss_bf_search_class()
+ *	Fetches the class pointer if provided the classid.
+ */
+static unsigned long nss_bf_search_class(struct Qdisc *sch, u32 classid)
+{
+	struct nss_bf_class_data *cl = nss_bf_find_class(classid, sch);
+
+	nss_qdisc_info("Get bf class %px - class match = %px\n", sch, cl);
+
+	return (unsigned long)cl;
+}
+#endif
 
 /*
  * nss_bf_dump_class()
@@ -460,7 +493,7 @@ static int nss_bf_dump_class(struct Qdis
 	struct nlattr *opts;
 	struct tc_nssbf_class_qopt qopt;
 
-	nss_qdisc_info("Dumping class %p of Qdisc %p\n", cl, sch);
+	nss_qdisc_info("Dumping class %px of Qdisc %px\n", cl, sch);
 
 	qopt.burst = cl->burst;
 	qopt.rate = cl->rate;
@@ -475,7 +508,7 @@ static int nss_bf_dump_class(struct Qdis
 	tcm->tcm_handle = cl->cl_common.classid;
 	tcm->tcm_info = cl->qdisc->handle;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSBF_CLASS_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -495,7 +528,7 @@ static int nss_bf_dump_class_stats(struc
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)arg;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &nq->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &nq->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &nq->qstats) < 0) {
 		return -1;
 	}
@@ -514,7 +547,7 @@ static void nss_bf_walk(struct Qdisc *sc
 	struct nss_bf_class_data *cl;
 	unsigned int i;
 
-	nss_qdisc_info("In bf walk %p\n", sch);
+	nss_qdisc_info("In bf walk %px\n", sch);
 	if (arg->stop)
 		return;
 
@@ -538,9 +571,15 @@ static void nss_bf_walk(struct Qdisc *sc
  * nss_bf_change_qdisc()
  *	Can be used to configure a nssbf qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_change_qdisc(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_bf_change_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSBF_MAX + 1];
 	struct tc_nssbf_qopt *qopt;
 
 	/*
@@ -563,7 +602,11 @@ static int nss_bf_change_qdisc(struct Qd
 	/*
 	 * If it is not NULL, parse to get qopt.
 	 */
-	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -586,8 +629,13 @@ static int nss_bf_change_qdisc(struct Qd
  */
 static void nss_bf_reset_class(struct nss_bf_class_data *cl)
 {
+	if (cl->qdisc == &noop_qdisc) {
+		nss_qdisc_trace("Class %x has no child qdisc to reset\n", cl->nq.qos_tag);
+		return;
+	}
+
 	nss_qdisc_reset(cl->qdisc);
-	nss_qdisc_info("Nssbf class resetted %p\n", cl->qdisc);
+	nss_qdisc_info("Nssbf class resetted %px\n", cl->qdisc);
 }
 
 /*
@@ -607,7 +655,7 @@ static void nss_bf_reset_qdisc(struct Qd
 	}
 
 	nss_qdisc_reset(sch);
-	nss_qdisc_info("Nssbf qdisc resetted %p\n", sch);
+	nss_qdisc_info("Nssbf qdisc resetted %px\n", sch);
 }
 
 /*
@@ -634,8 +682,8 @@ static void nss_bf_destroy_qdisc(struct
 			 * care of by the nss_bf_destroy() function.
 			 */
 			if (cl == &q->root) {
-				nss_qdisc_info("We do not detach or destroy bf class %p here since this is "
-						"the qdisc %p\n", cl, sch);
+				nss_qdisc_info("We do not detach or destroy bf class %px here since this is "
+						"the qdisc %px\n", cl, sch);
 				continue;
 			}
 
@@ -643,7 +691,7 @@ static void nss_bf_destroy_qdisc(struct
 			 * Reduce refcnt by 1 before destroying. This is to
 			 * ensure that polling of stat stops properly.
 			 */
-			atomic_sub(1, &cl->nq.refcnt);
+			 nss_qdisc_atomic_sub(&cl->nq);
 
 			/*
 			 * Detach class before destroying it. We dont check for noop qdisc here
@@ -667,31 +715,34 @@ static void nss_bf_destroy_qdisc(struct
 	qdisc_class_hash_destroy(&q->clhash);
 
 	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(&q->nq);
-
-	/*
 	 * Now we can go ahead and destroy the qdisc.
 	 * Note: We dont have to detach ourself from our parent because this
 	 *	 will be taken care of by the graft call.
 	 */
 	nss_qdisc_destroy(&q->nq);
-	nss_qdisc_info("Nssbf destroyed %p\n", sch);
+	nss_qdisc_info("Nssbf destroyed %px\n", sch);
 }
 
 /*
  * nss_bf_init_qdisc()
  *	Initializes the nssbf qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_bf_init_qdisc(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_bf_init_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_bf_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSBF_MAX + 1];
 	struct tc_nssbf_qopt *qopt;
 	int err;
 	unsigned int accel_mode;
 
-	nss_qdisc_info("Init bf qdisc %p\n", sch);
+	nss_qdisc_info("Init bf qdisc %px\n", sch);
 
 	err = qdisc_class_hash_init(&q->clhash);
 	if (err < 0) {
@@ -710,7 +761,11 @@ static int nss_bf_init_qdisc(struct Qdis
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_NSS_FW;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_bf_policy, tb, TCA_NSSBF_MAX, TCA_NSSBF_QDISC_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
@@ -720,7 +775,7 @@ static int nss_bf_init_qdisc(struct Qdis
 	/*
 	 * Initialize the NSSBF shaper in NSS
 	 */
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_BF, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_BF, 0, accel_mode, extack) < 0) {
 		return -EINVAL;
 	}
 
@@ -729,16 +784,15 @@ static int nss_bf_init_qdisc(struct Qdis
 	/*
 	 * Tune nss_bf parameters.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_bf_change_qdisc(sch, opt) < 0) {
+#else
+	if (nss_bf_change_qdisc(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(&q->nq);
-
 	return 0;
 }
 
@@ -756,7 +810,7 @@ static int nss_bf_dump_qdisc(struct Qdis
 	qopt.defcls = q->defcls;
 	qopt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (!opts || nla_put(skb, TCA_NSSBF_QDISC_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -772,9 +826,18 @@ nla_put_failure:
  * nss_bf_enqueue()
  *	Enqueues a skb to nssbf qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_bf_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_bf_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -786,6 +849,7 @@ static struct sk_buff *nss_bf_dequeue(st
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_bf_drop()
  *	Drops a single skb from linux queue, if not empty.
@@ -797,6 +861,7 @@ static unsigned int nss_bf_drop(struct Q
 	printk("In bf drop\n");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * Registration structure for nssbf class
@@ -807,8 +872,19 @@ const struct Qdisc_class_ops nss_bf_clas
 	.graft		= nss_bf_graft_class,
 	.leaf		= nss_bf_leaf_class,
 	.qlen_notify	= nss_bf_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_bf_get_class,
 	.put		= nss_bf_put_class,
+#else
+	.find		= nss_bf_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block      = nss_qdisc_tcf_block,
+#endif
+	.bind_tcf	= nss_qdisc_tcf_bind,
+	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_bf_dump_class,
 	.dump_stats	= nss_bf_dump_class_stats,
 	.walk		= nss_bf_walk
@@ -827,7 +903,9 @@ struct Qdisc_ops nss_bf_qdisc_ops __read
 	.enqueue	= nss_bf_enqueue,
 	.dequeue	= nss_bf_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_bf_drop,
+#endif
 	.cl_ops		= &nss_bf_class_ops,
 	.priv_size	= sizeof(struct nss_bf_sched_data),
 	.owner		= THIS_MODULE
diff -uprN nss-clients-old/nss_qdisc/nss_blackhole.c nss-clients/nss_qdisc/nss_blackhole.c
--- nss-clients-old/nss_qdisc/nss_blackhole.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_blackhole.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014, 2016-2017, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014, 2016-2017, 2020-2021,  The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -35,9 +35,18 @@ static struct nla_policy nss_blackhole_p
  * nss_blackhole_enqueue()
  *	Enqueue API for nss blackhole qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_blackhole_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_blackhole_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -49,6 +58,7 @@ static struct sk_buff *nss_blackhole_deq
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_blackhole_drop()
  *	The following function drops a packet from HLOS queue.
@@ -60,6 +70,7 @@ static unsigned int nss_blackhole_drop(s
 	nss_qdisc_info("qdisc %x dropping\n", sch->handle);
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_blackhole_reset()
@@ -79,11 +90,6 @@ static void nss_blackhole_destroy(struct
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)qdisc_priv(sch);
 
-	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(nq);
-
 	nss_qdisc_info("destroying qdisc %x\n", sch->handle);
 	nss_qdisc_destroy(nq);
 }
@@ -92,9 +98,15 @@ static void nss_blackhole_destroy(struct
  * nss_blackhole_change()
  *	Function call used to configure the parameters of the nss blackhole qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_blackhole_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_blackhole_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_blackhole_sched_data *q;
+	struct nlattr *tb[TCA_NSSBLACKHOLE_MAX + 1];
 	struct tc_nssblackhole_qopt *qopt;
 	struct nss_if_msg nim;
 
@@ -102,7 +114,11 @@ static int nss_blackhole_change(struct Q
 		return 0;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -154,9 +170,17 @@ static int nss_blackhole_change(struct Q
  * nss_blackhole_init()
  *	Initializes a nss blackhole qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_blackhole_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_blackhole_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSBLACKHOLE_MAX + 1];
 	struct tc_nssblackhole_qopt *qopt;
 	unsigned int accel_mode;
 
@@ -166,7 +190,11 @@ static int nss_blackhole_init(struct Qdi
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_PPE;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_blackhole_policy, tb, TCA_NSSBLACKHOLE_MAX, TCA_NSSBLACKHOLE_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
@@ -176,21 +204,21 @@ static int nss_blackhole_init(struct Qdi
 	nss_qdisc_info("qdisc %x initializing\n", sch->handle);
 	nss_blackhole_reset(sch);
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, accel_mode, extack) < 0)
+	{
 		return -EINVAL;
 	}
 
 	nss_qdisc_info("qdisc %x initialized with parent %x\n", sch->handle, sch->parent);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_blackhole_change(sch, opt) < 0) {
+#else
+	if (nss_blackhole_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(nq);
-
 	return 0;
 }
 
@@ -214,7 +242,7 @@ static int nss_blackhole_dump(struct Qdi
 	opt.set_default = q->set_default;
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -251,7 +279,9 @@ struct Qdisc_ops nss_blackhole_qdisc_ops
 	.enqueue	=	nss_blackhole_enqueue,
 	.dequeue	=	nss_blackhole_dequeue,
 	.peek		=	nss_blackhole_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_blackhole_drop,
+#endif
 	.init		=	nss_blackhole_init,
 	.reset		=	nss_blackhole_reset,
 	.destroy	=	nss_blackhole_destroy,
diff -uprN nss-clients-old/nss_qdisc/nss_codel.c nss-clients/nss_qdisc/nss_codel.c
--- nss-clients-old/nss_qdisc/nss_codel.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_codel.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014, 2016-2018, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014, 2016-2018, 2020-2021,  The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -76,9 +76,18 @@ static struct nla_policy nss_codel_polic
  * nss_codel_enqueue()
  *	Enqueue a packet into nss_codel queue in NSS firmware (bounce).
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_codel_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_codel_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -90,6 +99,7 @@ static struct sk_buff *nss_codel_dequeue
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_codel_drop()
  *	Drops a packet from the bounce complete queue.
@@ -100,6 +110,7 @@ static unsigned int nss_codel_drop(struc
 {
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_codel_reset()
@@ -144,10 +155,6 @@ static void nss_codel_destroy(struct Qdi
 {
 	struct nss_codel_sched_data *q = qdisc_priv(sch);
 
-	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(&q->nq);
 	nss_qdisc_destroy(&q->nq);
 	nss_codel_flow_queues_free(q);
 	nss_qdisc_info("nss_codel destroyed");
@@ -234,9 +241,15 @@ static int nss_codel_mem_sz_get(struct Q
  * nss_codel_change()
  *	Used to configure the nss_codel queue in NSS firmware.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_codel_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_codel_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_codel_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSCODEL_MAX + 1];
 	struct tc_nsscodel_qopt *qopt;
 	struct nss_if_msg nim;
 	struct net_device *dev = qdisc_dev(sch);
@@ -245,7 +258,11 @@ static int nss_codel_change(struct Qdisc
 	struct nss_shaper_node_config *config;
 	bool free_flow_queue = true;
 
-	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -381,16 +398,28 @@ fail:
  * nss_codel_init()
  *	Initializes the nss_codel qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_codel_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_codel_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSCODEL_MAX + 1];
 	struct tc_nsscodel_qopt *qopt;
 
 	if (!opt) {
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_codel_policy, tb, TCA_NSSCODEL_MAX, TCA_NSSCODEL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -404,7 +433,8 @@ static int nss_codel_init(struct Qdisc *
 	nss_qdisc_register_configure_callback(nq, nss_codel_configure_callback);
 	nss_qdisc_register_stats_callback(nq, nss_codel_stats_callback);
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_CODEL, 0, qopt->accel_mode) < 0) {
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_CODEL, 0, qopt->accel_mode, extack) < 0)
+	{
 		return -EINVAL;
 	}
 
@@ -412,16 +442,15 @@ static int nss_codel_init(struct Qdisc *
 		return -EINVAL;
 	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_codel_change(sch, opt) < 0) {
+#else
+	if (nss_codel_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(nq);
-
 	return 0;
 }
 
@@ -451,7 +480,7 @@ static int nss_codel_dump(struct Qdisc *
 	opt.flows = q->flows;
 	opt.ecn = q->ecn;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -511,7 +540,9 @@ struct Qdisc_ops nss_codel_qdisc_ops __r
 	.enqueue	=	nss_codel_enqueue,
 	.dequeue	=	nss_codel_dequeue,
 	.peek		=	nss_codel_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_codel_drop,
+#endif
 	.init		=	nss_codel_init,
 	.reset		=	nss_codel_reset,
 	.destroy	=	nss_codel_destroy,
@@ -530,7 +561,9 @@ struct Qdisc_ops nss_fq_codel_qdisc_ops
 	.enqueue	=	nss_codel_enqueue,
 	.dequeue	=	nss_codel_dequeue,
 	.peek		=	nss_codel_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_codel_drop,
+#endif
 	.init		=	nss_codel_init,
 	.reset		=	nss_codel_reset,
 	.destroy	=	nss_codel_destroy,
diff -uprN nss-clients-old/nss_qdisc/nss_fifo.c nss-clients/nss_qdisc/nss_fifo.c
--- nss-clients-old/nss_qdisc/nss_fifo.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_fifo.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014, 2016-2017, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014, 2016-2017, 2020-2021, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -29,9 +29,18 @@ static struct nla_policy nss_fifo_policy
 	[TCA_NSSFIFO_PARMS] = { .len = sizeof(struct tc_nssfifo_qopt) },
 };
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_fifo_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_fifo_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 static struct sk_buff *nss_fifo_dequeue(struct Qdisc *sch)
@@ -39,11 +48,13 @@ static struct sk_buff *nss_fifo_dequeue(
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static unsigned int nss_fifo_drop(struct Qdisc *sch)
 {
 	nss_qdisc_info("nss_fifo dropping");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 static void nss_fifo_reset(struct Qdisc *sch)
 {
@@ -55,17 +66,18 @@ static void nss_fifo_destroy(struct Qdis
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)qdisc_priv(sch);
 
-	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(nq);
-
 	nss_qdisc_destroy(nq);
 	nss_qdisc_info("nss_fifo destroyed");
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_params_validate_and_save(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_fifo_params_validate_and_save(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSFIFO_MAX + 1];
 	struct tc_nssfifo_qopt *qopt;
 	struct nss_fifo_sched_data *q = qdisc_priv(sch);
 	bool is_bfifo = (sch->ops == &nss_bfifo_qdisc_ops);
@@ -74,7 +86,11 @@ static int nss_fifo_params_validate_and_
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS, extack);
+#endif
 	if (!qopt) {
 		nss_qdisc_warning("Invalid input to fifo %x", sch->handle);
 		return -EINVAL;
@@ -101,7 +117,11 @@ static int nss_fifo_params_validate_and_
 }
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_ppe_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_fifo_ppe_change(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_fifo_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
@@ -150,29 +170,46 @@ fail:
 	/*
 	 * Fallback to nss qdisc if PPE Qdisc configuration failed at init time.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_ppe_fallback_to_nss(&q->nq, opt) < 0) {
-		nss_qdisc_warning("nss_fifo %x fallback to nss failed\n", sch->handle);
+#else
+	if (nss_ppe_fallback_to_nss(&q->nq, opt, extack) < 0) {
+#endif
+	nss_qdisc_warning("nss_fifo %x fallback to nss failed\n", sch->handle);
 		return -EINVAL;
 	}
 	return 0;
 }
 #endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_fifo_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_fifo_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
 	struct nss_if_msg nim;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_fifo_params_validate_and_save(sch, opt) < 0) {
-		nss_qdisc_warning("nss_fifo %p params validate and save failed\n", sch);
+#else
+	if (nss_fifo_params_validate_and_save(sch, opt, extack) < 0) {
+#endif
+		nss_qdisc_warning("nss_fifo %px params validate and save failed\n", sch);
 		return -EINVAL;
 	}
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 		if (nss_fifo_ppe_change(sch, opt) < 0) {
-			nss_qdisc_warning("nss_fifo %p params validate and save failed\n", sch);
+#else
+		if (nss_fifo_ppe_change(sch, opt, extack) < 0) {
+#endif
+			nss_qdisc_warning("nss_fifo %px params validate and save failed\n", sch);
 			return -EINVAL;
 		}
 		return 0;
@@ -183,7 +220,7 @@ static int nss_fifo_change(struct Qdisc
 	nim.msg.shaper_configure.config.msg.shaper_node_config.snc.fifo_param.limit = q->limit;
 	nim.msg.shaper_configure.config.msg.shaper_node_config.snc.fifo_param.drop_mode = NSS_SHAPER_FIFO_DROP_MODE_TAIL;
 	if (nss_qdisc_configure(&q->nq, &nim, NSS_SHAPER_CONFIG_TYPE_SHAPER_NODE_CHANGE_PARAM) < 0) {
-		nss_qdisc_error("nss_fifo %p configuration failed\n", sch);
+		nss_qdisc_error("nss_fifo %px configuration failed\n", sch);
 		return -EINVAL;
 	}
 
@@ -199,7 +236,7 @@ static int nss_fifo_change(struct Qdisc
 	 * Set this qdisc to be the default qdisc for enqueuing packets.
 	 */
 	if (nss_qdisc_set_default(nq) < 0) {
-		nss_qdisc_error("nss_fifo %p set_default failed\n", sch);
+		nss_qdisc_error("nss_fifo %px set_default failed\n", sch);
 		return -EINVAL;
 	}
 
@@ -208,9 +245,17 @@ static int nss_fifo_change(struct Qdisc
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_fifo_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_fifo_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSFIFO_MAX + 1];
 	struct tc_nssfifo_qopt *qopt;
 
 	if (!opt) {
@@ -220,28 +265,32 @@ static int nss_fifo_init(struct Qdisc *s
 	nss_qdisc_info("Initializing Fifo - type %d\n", NSS_SHAPER_NODE_TYPE_FIFO);
 	nss_fifo_reset(sch);
 
-	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_fifo_policy, tb, TCA_NSSFIFO_MAX, TCA_NSSFIFO_PARMS, extack);
+#endif
 	if (!qopt) {
 		nss_qdisc_warning("Invalid input to fifo %x", sch->handle);
 		return -EINVAL;
 	}
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, qopt->accel_mode) < 0) {
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_FIFO, 0, qopt->accel_mode, extack) < 0)
+	{
 		nss_qdisc_warning("Fifo %x init failed", sch->handle);
 		return -EINVAL;
 	}
 
 	nss_qdisc_info("NSS fifo initialized - handle %x parent %x\n", sch->handle, sch->parent);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_fifo_change(sch, opt) < 0) {
+#else
+	if (nss_fifo_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(nq);
-
 	return 0;
 }
 
@@ -262,7 +311,8 @@ static int nss_fifo_dump(struct Qdisc *s
 	opt.set_default = q->set_default;
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
+
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -290,7 +340,9 @@ struct Qdisc_ops nss_pfifo_qdisc_ops __r
 	.enqueue	=	nss_fifo_enqueue,
 	.dequeue	=	nss_fifo_dequeue,
 	.peek		=	nss_fifo_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_fifo_drop,
+#endif
 	.init		=	nss_fifo_init,
 	.reset		=	nss_fifo_reset,
 	.destroy	=	nss_fifo_destroy,
@@ -305,7 +357,9 @@ struct Qdisc_ops nss_bfifo_qdisc_ops __r
 	.enqueue	=	nss_fifo_enqueue,
 	.dequeue	=	nss_fifo_dequeue,
 	.peek		=	nss_fifo_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_fifo_drop,
+#endif
 	.init		=	nss_fifo_init,
 	.reset		=	nss_fifo_reset,
 	.destroy	=	nss_fifo_destroy,
diff -uprN nss-clients-old/nss_qdisc/nss_htb.c nss-clients/nss_qdisc/nss_htb.c
--- nss-clients-old/nss_qdisc/nss_htb.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_htb.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2017 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2017, 2019-2021, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -83,10 +83,16 @@ static inline struct nss_htb_class_data
  * nss_htb_class_params_validate_and_save()
  *	Validates and saves the qdisc configuration parameters.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
 					struct nss_htb_param *param)
+#else
+static int nss_htb_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
+					struct nss_htb_param *param, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nlattr *opt = tca[TCA_OPTIONS];
+	struct nlattr *tb[TCA_NSSHTB_MAX + 1];
 	struct tc_nsshtb_class_qopt *qopt;
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
 	struct net_device *dev = qdisc_dev(sch);
@@ -99,7 +105,11 @@ static int nss_htb_class_params_validate
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, TCA_NSSHTB_MAX, TCA_NSSHTB_CLASS_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_CLASS_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_CLASS_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -202,7 +212,7 @@ static struct nss_htb_class_data *nss_ht
 		return NULL;
 	}
 
-	nss_qdisc_trace("htb class %x allocated - addr %p\n", classid, cl);
+	nss_qdisc_trace("htb class %x allocated - addr %px\n", classid, cl);
 	cl->parent = parent;
 	cl->sch_common.classid = classid;
 
@@ -219,7 +229,7 @@ static struct nss_htb_class_data *nss_ht
 	 * reference count should not be 0.
 	 */
 	cl->qdisc = &noop_qdisc;
-	atomic_set(&cl->nq.refcnt, 1);
+	nss_qdisc_atomic_set(&cl->nq);
 
 	return cl;
 }
@@ -266,9 +276,16 @@ static int nss_htb_ppe_change_class(stru
  * nss_htb_change_class()
  *	Configures a new class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
 		  struct nlattr **tca, unsigned long *arg)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_htb_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
+		  struct nlattr **tca, unsigned long *arg, struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
 	struct nss_htb_class_data *cl = (struct nss_htb_class_data *)*arg;
 	struct nss_htb_class_data *parent;
@@ -282,7 +299,11 @@ static int nss_htb_change_class(struct Q
 
 	nss_qdisc_trace("configuring htb class %x of qdisc %x\n", classid, sch->handle);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_htb_class_params_validate_and_save(sch, tca, &param) < 0) {
+#else
+	if (nss_htb_class_params_validate_and_save(sch, tca, &param, extack) < 0) {
+#endif
 		nss_qdisc_warning("validation of configuration parameters for htb class %x failed\n",
 					sch->handle);
 		return -EINVAL;
@@ -332,7 +353,8 @@ static int nss_htb_change_class(struct Q
 		 * here.
 		 */
 		cl->nq.parent = nq_parent;
-		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_HTB_GROUP, classid, accel_mode) < 0) {
+		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_HTB_GROUP, classid, accel_mode, extack) < 0)
+		{
 			nss_qdisc_error("nss_init for htb class %x failed\n", classid);
 			goto failure;
 		}
@@ -387,11 +409,6 @@ static int nss_htb_change_class(struct Q
 		 */
 		qdisc_class_hash_grow(sch, &q->clhash);
 
-		/*
-		 * Start the stats polling timer
-		 */
-		nss_qdisc_start_basic_stats_polling(&cl->nq);
-
 		nss_qdisc_trace("class %x successfully allocated and initialized\n", classid);
 	}
 
@@ -478,12 +495,7 @@ static void nss_htb_destroy_class(struct
 	/*
 	 * And now we destroy the child.
 	 */
-	qdisc_destroy(cl->qdisc);
-
-	/*
-	 * Stop the stats polling timer and free class
-	 */
-	nss_qdisc_stop_basic_stats_polling(&cl->nq);
+	 nss_qdisc_put(cl->qdisc);
 
 	/*
 	 * Destroy the shaper in NSS
@@ -548,10 +560,16 @@ static int nss_htb_delete_class(struct Q
 	/*
 	 * If we are root class, we dont have to update our parent.
 	 * We simply deduct refcnt and return.
+	 * For 5.4 and above kernels, calling nss_htb_destroy_class
+	 * explicitly as there is no put_class which would have called
+	 * nss_htb_destroy_class when refcnt becomes zero.
 	 */
 	if (!cl->parent) {
-		refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+		refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
 		sch_tree_unlock(sch);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0))
+		nss_htb_destroy_class(sch, cl);
+#endif
 		return 0;
 	}
 
@@ -567,9 +585,17 @@ static int nss_htb_delete_class(struct Q
 	/*
 	 * Decrement refcnt and return
 	 */
-	refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+	refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
 	sch_tree_unlock(sch);
 
+	/*
+	 * For 5.4 and above kernels, calling nss_htb_destroy_class
+	 * explicitly as there is no put_class which would have called
+	 * nss_htb_destroy_class when refcnt becomes zero.
+	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0))
+	nss_htb_destroy_class(sch, cl);
+#endif
 	return 0;
 }
 
@@ -577,7 +603,12 @@ static int nss_htb_delete_class(struct Q
  * nss_htb_graft_class()
  *	Replaces the qdisc attached to the provided class.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new, struct Qdisc **old)
+#else
+static int nss_htb_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new, struct Qdisc **old,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_htb_class_data *cl = (struct nss_htb_class_data *)arg;
 	struct nss_if_msg nim_detach;
@@ -664,6 +695,7 @@ static void nss_htb_qlen_notify(struct Q
 	 */
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 /*
  * nss_htb_get_class()
  *	Fetches the class pointer if provided the classid.
@@ -695,10 +727,22 @@ static void nss_htb_put_class(struct Qdi
 	 * We are safe to destroy the qdisc if the reference count
 	 * goes down to 0.
 	 */
-	if (atomic_sub_return(1, &cl->nq.refcnt) == 0) {
+	if (nss_qdisc_atomic_sub_return(&cl->nq) == 0) {
 		nss_htb_destroy_class(sch, cl);
 	}
 }
+#else
+/*
+ * nss_htb_search_class()
+ *	Fetches the class pointer if provided the classid.
+ */
+static unsigned long nss_htb_search_class(struct Qdisc *sch, u32 classid)
+{
+	struct nss_htb_class_data *cl = nss_htb_find_class(classid, sch);
+
+	return (unsigned long)cl;
+}
+#endif
 
 /*
  * nss_htb_dump_class()
@@ -728,8 +772,7 @@ static int nss_htb_dump_class(struct Qdi
 	tcm->tcm_handle = cl->sch_common.classid;
 	tcm->tcm_info = cl->qdisc->handle;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
-
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSHTB_CLASS_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -750,7 +793,7 @@ static int nss_htb_dump_class_stats(stru
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)arg;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &nq->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &nq->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &nq->qstats) < 0) {
 		nss_qdisc_error("htb class %x stats dump failed\n", nq->qos_tag);
 		return -1;
@@ -795,9 +838,15 @@ static void nss_htb_walk(struct Qdisc *s
  * nss_htb_change_qdisc()
  *	Can be used to configure a htb qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_change_qdisc(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_htb_change_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSHTB_MAX + 1];
 	struct tc_nsshtb_qopt *qopt;
 
 	/*
@@ -820,7 +869,11 @@ static int nss_htb_change_qdisc(struct Q
 	/*
 	 * If it is not NULL, parse to get qopt.
 	 */
-	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -845,6 +898,11 @@ static int nss_htb_change_qdisc(struct Q
  */
 static void nss_htb_reset_class(struct nss_htb_class_data *cl)
 {
+	if (cl->qdisc == &noop_qdisc) {
+		nss_qdisc_trace("Class %x has no child qdisc to reset\n", cl->nq.qos_tag);
+		return;
+	}
+
 	nss_qdisc_reset(cl->qdisc);
 	nss_qdisc_trace("htb class %x reset\n", cl->nq.qos_tag);
 }
@@ -895,7 +953,7 @@ static void nss_htb_destroy_qdisc(struct
 			 * Reduce refcnt by 1 before destroying. This is to
 			 * ensure that polling of stat stops properly.
 			 */
-			atomic_sub(1, &cl->nq.refcnt);
+			 nss_qdisc_atomic_sub(&cl->nq);
 
 			/*
 			 * We are not root class. Therefore we reduce the children count
@@ -928,11 +986,6 @@ static void nss_htb_destroy_qdisc(struct
 	qdisc_class_hash_destroy(&q->clhash);
 
 	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(&q->nq);
-
-	/*
 	 * Now we can go ahead and destroy the qdisc.
 	 * Note: We dont have to detach ourself from our parent because this
 	 *	 will be taken care of by the graft call.
@@ -945,9 +998,17 @@ static void nss_htb_destroy_qdisc(struct
  * nss_htb_init_qdisc()
  *	Initializes the htb qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_htb_init_qdisc(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_htb_init_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_htb_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSHTB_MAX + 1];
 	struct tc_nsshtb_qopt *qopt;
 	int err;
 	unsigned int accel_mode;
@@ -964,7 +1025,11 @@ static int nss_htb_init_qdisc(struct Qdi
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_PPE;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_htb_policy, tb, TCA_NSSHTB_MAX, TCA_NSSHTB_QDISC_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
@@ -977,7 +1042,7 @@ static int nss_htb_init_qdisc(struct Qdi
 	/*
 	 * Initialize the NSSHTB shaper in NSS
 	 */
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_HTB, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_HTB, 0, accel_mode, extack) < 0) {
 		nss_qdisc_error("failed to initialize htb qdisc %x in nss", sch->handle);
 		return -EINVAL;
 	}
@@ -987,16 +1052,15 @@ static int nss_htb_init_qdisc(struct Qdi
 	/*
 	 * Tune HTB parameters
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_htb_change_qdisc(sch, opt) < 0) {
+#else
+	if (nss_htb_change_qdisc(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(&q->nq);
-
 	return 0;
 }
 
@@ -1016,7 +1080,8 @@ static int nss_htb_dump_qdisc(struct Qdi
 	qopt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
 	nss_qdisc_info("r2q = %u accel_mode = %u", qopt.r2q, qopt.accel_mode);
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (!opts || nla_put(skb, TCA_NSSHTB_QDISC_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -1032,9 +1097,18 @@ static int nss_htb_dump_qdisc(struct Qdi
  * nss_htb_enqueue()
  *	Enqueues a skb to htb qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_htb_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_htb_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -1046,6 +1120,7 @@ static struct sk_buff *nss_htb_dequeue(s
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_htb_drop()
  *	Drops a single skb from linux queue, if not empty.
@@ -1057,6 +1132,7 @@ static unsigned int nss_htb_drop(struct
 	nss_qdisc_trace("drop called on htb qdisc %x\n", sch->handle);
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * Registration structure for htb class
@@ -1067,8 +1143,19 @@ const struct Qdisc_class_ops nss_htb_cla
 	.graft		= nss_htb_graft_class,
 	.leaf		= nss_htb_leaf_class,
 	.qlen_notify	= nss_htb_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_htb_get_class,
 	.put		= nss_htb_put_class,
+#else
+	.find		=	nss_htb_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block	= nss_qdisc_tcf_block,
+#endif
+	.bind_tcf	= nss_qdisc_tcf_bind,
+	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_htb_dump_class,
 	.dump_stats	= nss_htb_dump_class_stats,
 	.walk		= nss_htb_walk
@@ -1087,7 +1174,9 @@ struct Qdisc_ops nss_htb_qdisc_ops __rea
 	.enqueue	= nss_htb_enqueue,
 	.dequeue	= nss_htb_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_htb_drop,
+#endif
 	.cl_ops		= &nss_htb_class_ops,
 	.priv_size	= sizeof(struct nss_htb_sched_data),
 	.owner		= THIS_MODULE
diff -uprN nss-clients-old/nss_qdisc/nss_ppe.c nss-clients/nss_qdisc/nss_ppe.c
--- nss-clients-old/nss_qdisc/nss_ppe.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_ppe.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2017-2019, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2017-2020, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -239,7 +239,10 @@ int nss_ppe_port_res_alloc(void)
 	ppe_qdisc_port[i].max[NSS_PPE_L0_EDRR] = NSS_PPE_LOOPBACK_L0_EDRR_MAX;
 	ppe_qdisc_port[i].base[NSS_PPE_L0_EDRR] = NSS_PPE_LOOPBACK_L0_EDRR_BASE;
 
-	for (type = 0; type < NSS_PPE_L0_SP; type++) {
+	ppe_qdisc_port[i].max[NSS_PPE_L0_SP] = NSS_PPE_LOOPBACK_L0_SP_MAX;
+	ppe_qdisc_port[i].base[NSS_PPE_L0_SP] = NSS_PPE_LOOPBACK_L0_SP_BASE;
+
+	for (type = 0; type <= NSS_PPE_L0_SP; type++) {
 		ppe_qdisc_port[i].res_free[type] = nss_ppe_res_entries_alloc(i, type);
 		if (!ppe_qdisc_port[i].res_free[type]) {
 			nss_qdisc_error("Resource list allocation failed for port:%u type:%u\n", i, type);
@@ -383,16 +386,24 @@ static int nss_ppe_l1_res_free(struct ns
 	uint32_t port_num = nss_ppe_port_num_get(nq);
 	struct nss_ppe_qdisc *npq = &nq->npq;
 
+	if (!npq->l1_valid) {
+		return 0;
+	}
+
 	/*
-	 * Bridge interface will have one level less than the max shaper levels.
+	 * Loopback will have one level less than the max shaper levels.
 	 * L1 scheduler was configured at init time, so resources were allocated.
 	 */
-	if (nq->is_bridge) {
-		npq->l0spid = 0;
-		return 0;
-	}
+	if (nq->needs_ppe_loopback) {
+		offset = npq->l0spid - nss_ppe_base_get(port_num, NSS_PPE_L0_SP);
+		if (nss_ppe_res_free(port_num, offset, NSS_PPE_L0_SP) != 0) {
+			nss_qdisc_error("Used res:%d not found for port:%d, type:%d\n", npq->l0spid, port_num, NSS_PPE_L0_SP);
+			return -EINVAL;
+		}
 
-	if (!npq->l1_valid) {
+		npq->l0spid = 0;
+		npq->l1_valid = false;
+		nss_qdisc_trace("loopback resource freed\n");
 		return 0;
 	}
 
@@ -445,6 +456,26 @@ static int nss_ppe_l1_res_alloc(struct n
 	struct nss_ppe_qdisc *npq = &nq->npq;
 
 	/*
+	 * Get Level 0 SP resource
+	 */
+	l0sp = nss_ppe_res_alloc(port_num, NSS_PPE_L0_SP);
+	if (!l0sp) {
+		nss_qdisc_warning("Free res not found for port:%d, type:%d \n", port_num, NSS_PPE_L0_SP);
+		goto fail;
+	}
+
+	/*
+	 * Loopback has no dedicated L1 schedulers. L0 SP is the only resource we
+	 * need to allocate.
+	 */
+	if (nq->needs_ppe_loopback) {
+		npq->l0spid = nss_ppe_base_get(port_num, NSS_PPE_L0_SP) + l0sp->offset;
+		npq->l1_valid = true;
+		nss_qdisc_info("Level1 scheduler resource allocation successful\n");
+		return 0;
+	}
+
+	/*
 	 * Get Level 1 DRR resource
 	 */
 	l1c_drr = nss_ppe_res_alloc(port_num, NSS_PPE_L1_CDRR);
@@ -460,15 +491,6 @@ static int nss_ppe_l1_res_alloc(struct n
 	}
 
 	/*
-	 * Get Level 0 SP resource
-	 */
-	l0sp = nss_ppe_res_alloc(port_num, NSS_PPE_L0_SP);
-	if (!l0sp) {
-		nss_qdisc_warning("Free res not found for port:%d, type:%d \n", port_num, NSS_PPE_L0_SP);
-		goto fail;
-	}
-
-	/*
 	 * Set Res id values in qdisc
 	 */
 	npq->q.ucast_qid = 0;
@@ -611,27 +633,37 @@ static int nss_ppe_l1_queue_scheduler_se
 	struct nss_ppe_qdisc *npq = &nq->npq;
 
 	/*
-	 * Bridge interface will have one level less than the max shaper levels.
+	 * Loopback will have one level less than the max shaper levels.
 	 * L1 scheduler was configured at init time, so no need to allocate resources.
 	 */
-	if (nq->is_bridge) {
+	if (nq->needs_ppe_loopback) {
 		/*
-		 * Set Res id values in qdisc
+		 * Allocate resource if we have not already done so.
 		 */
-		npq->l0spid = NSS_PPE_LOOPBACK_L0_SP_BASE;
+		if (!npq->l1_valid && nss_ppe_l1_res_alloc(nq) != 0) {
+			nss_qdisc_warning("SSDK level1 queue scheduler configuration failed\n");
+			return -EINVAL;
+		}
 
+		nss_qdisc_info("Allocated spid:%d expected:%d\n", npq->l0spid, NSS_PPE_LOOPBACK_L0_SP_BASE);
+
+		/*
+		 * L0 SP is the only resource we allocate in loopback, and that
+		 * does not require additional configuration. The next level of
+		 * C/E DRR will attach to the right priority slot.
+		 *
+		 * We simply return.
+		 */
 		nss_qdisc_info("SSDK level1 queue scheduler configuration successful\n");
 		return 0;
 	}
 
 	/*
-	 * Allocate new resources only if scheduler is not valid.
+	 * Allocate resources if we have not already done so.
 	 */
-	if (!npq->l1_valid) {
-		if (nss_ppe_l1_res_alloc(nq) != 0) {
-			nss_qdisc_warning("SSDK level1 queue scheduler configuration failed\n");
-			return -EINVAL;
-		}
+	if (!npq->l1_valid && nss_ppe_l1_res_alloc(nq) != 0) {
+		nss_qdisc_warning("SSDK level1 queue scheduler configuration failed\n");
+		return -EINVAL;
 	}
 
 	/*
@@ -685,7 +717,6 @@ static int nss_ppe_l0_res_free(struct ns
 		return -EINVAL;
 	}
 
-
 	/*
 	 * Reset Res id values in qdisc
 	 */
@@ -1197,9 +1228,9 @@ static int nss_ppe_max_level_get(struct
 	int level = NSS_PPE_MAX_LEVEL;
 
 	/*
-	 * For bridge ports, one level is being used by loopback.
+	 * Loopback uses one level.
 	 */
-	if (nq->is_bridge) {
+	if (nq->needs_ppe_loopback) {
 		level = level - 1;
 	}
 
@@ -1220,7 +1251,7 @@ static void nss_ppe_attach_free(uint32_t
 	ppe_port->res_free[res->type] = res;
 	spin_unlock_bh(&ppe_port->lock);
 
-	nss_qdisc_info("port:%d, type:%d, res:%p\n", port, res->type, res);
+	nss_qdisc_info("port:%d, type:%d, res:%px\n", port, res->type, res);
 	return;
 }
 
@@ -1287,7 +1318,7 @@ int nss_ppe_res_free(uint32_t port, uint
 
 success:
 	nss_ppe_attach_free(port, res);
-	nss_qdisc_info("port:%d, type:%d, res:%p\n", port, type, res);
+	nss_qdisc_info("port:%d, type:%d, res:%px\n", port, type, res);
 	return 0;
 }
 
@@ -1313,7 +1344,7 @@ struct nss_ppe_res *nss_ppe_res_alloc(ui
 	}
 	spin_unlock_bh(&ppe_port->lock);
 
-	nss_qdisc_info("port:%d, type:%d, res:%p\n", port, type, res);
+	nss_qdisc_info("port:%d, type:%d, res:%px\n", port, type, res);
 	return res;
 }
 
@@ -1338,7 +1369,7 @@ static int nss_ppe_default_conf_set(uint
 	nss_ppe_all_queue_disable(port_num);
 
 	/*
-	 * No resources were allocated for Port 0 (bridge interface).
+	 * No resources were allocated for Port 0 (Loopback port).
 	 * L1 scheduler was configured at init time.
 	 */
 	if (port_num == 0) {
@@ -1637,7 +1668,6 @@ static int nss_ppe_scheduler_set(struct
 			nss_ppe_queue_disable(nq);
 		}
 	} else {
-
 		/*
 		 * When a classful qdisc say HTB is configured with max levels of hierarchy,
 		 * and then if a qdisc say FIFO is attached at the last level, we will have all
@@ -1743,7 +1773,7 @@ int nss_ppe_set_parent(struct Qdisc *sch
 	struct net_device *dev = qdisc_dev(sch);
 	struct nss_qdisc *parent_nq = NULL;
 	struct Qdisc *parent_qdisc = NULL;
-	unsigned long parent_class;
+	unsigned long parent_class = 0;
 
 	/*
 	 * PPE Qdisc cannot be attached to NSS Qdisc.
@@ -1756,7 +1786,7 @@ int nss_ppe_set_parent(struct Qdisc *sch
 	}
 
 	if ((parent_nq) && (parent_nq->mode == NSS_QDISC_MODE_NSS)) {
-		nss_qdisc_info("HW qdisc/class %p cannot be attached to nss qdisc/class\n", nq->qdisc);
+		nss_qdisc_info("HW qdisc/class %px cannot be attached to nss qdisc/class\n", nq->qdisc);
 		return NSS_PPE_QDISC_PARENT_NOT_PPE;
 	}
 
@@ -1778,21 +1808,26 @@ int nss_ppe_set_parent(struct Qdisc *sch
 		 */
 		if ((parent_nq) && (parent_nq->npq.sub_type != NSS_SHAPER_CONFIG_PPE_SN_TYPE_PRIO) && (TC_H_MIN(parent))) {
 			if (!parent_qdisc) {
-				nss_qdisc_info("HW qdisc/class %p cannot be attached to non-existing class %x\n", nq->qdisc, parent);
+				nss_qdisc_info("HW qdisc/class %px cannot be attached to non-existing class %x\n", nq->qdisc, parent);
 				return NSS_PPE_QDISC_PARENT_NOT_EXISTING;
 			}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 			parent_class = parent_qdisc->ops->cl_ops->get(parent_qdisc, parent);
-
+#else
+			parent_class = parent_qdisc->ops->cl_ops->find(parent_qdisc, parent);
+#endif
 			if (!parent_class) {
 				nq->parent = NULL;
-				nss_qdisc_info("HW qdisc/class %p cannot be attached to non-existing class %x\n", nq->qdisc, parent);
+				nss_qdisc_info("HW qdisc/class %px cannot be attached to non-existing class %x\n", nq->qdisc, parent);
 				return NSS_PPE_QDISC_PARENT_NOT_EXISTING;
 
 			}
 
 			nq->parent = (struct nss_qdisc *)parent_class;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 			parent_qdisc->ops->cl_ops->put(parent_qdisc, parent_class);
+#endif
 		}
 	}
 
@@ -1897,7 +1932,7 @@ int nss_ppe_port_num_get(struct nss_qdis
 	 * Fetch port number based on interface type.
 	 * TODO: Change this when API from DP is available
 	 */
-	if (!(nq->is_bridge)) {
+	if (!nq->needs_ppe_loopback) {
 		port_num = nq->nss_interface_number;
 	}
 
@@ -1906,6 +1941,32 @@ int nss_ppe_port_num_get(struct nss_qdis
 }
 
 /*
+ * nss_ppe_all_queue_enable_hybrid()
+ *	Enables PPE queues when NSS queuing Qdiscs are attached in the hieracrchy.
+ */
+void nss_ppe_all_queue_enable_hybrid(struct nss_qdisc *nq)
+{
+	struct nss_qdisc *nq_root = qdisc_priv(qdisc_root(nq->qdisc));
+
+	if (!nq_root->hybrid_configured) {
+		return;
+	}
+
+	/*
+	 * In case of hybrid mode, we disable the PPE queues until
+	 * queueing Qdisc is attached in the hierarchy.
+	 */
+	if((nq->type == NSS_SHAPER_NODE_TYPE_CODEL)
+		|| (nq->type == NSS_SHAPER_NODE_TYPE_FIFO)
+		|| (nq->type == NSS_SHAPER_NODE_TYPE_BF)
+		|| (nq->type == NSS_SHAPER_NODE_TYPE_WRED)) {
+		uint32_t port_num = nss_ppe_port_num_get(nq);
+		nss_ppe_all_queue_enable(port_num);
+		nss_qdisc_info("Queues in hybrid mode enabled successfully for Qdisc %px (type %d)\n", nq, nq->type);
+	}
+}
+
+/*
  * nss_ppe_node_detach()
  *	Configuration function that helps detach a child shaper node from a parent.
  */
@@ -1919,7 +1980,7 @@ int nss_ppe_node_detach(struct nss_qdisc
 	 */
 	if (nq_child->mode != NSS_QDISC_MODE_PPE) {
 		if (nss_qdisc_set_hybrid_mode(nq_child, NSS_QDISC_HYBRID_MODE_DISABLE, 0) < 0) {
-			nss_qdisc_warning("detach of old qdisc %p failed\n", nq_child->qdisc);
+			nss_qdisc_warning("detach of old qdisc %px failed\n", nq_child->qdisc);
 			return -EINVAL;
 		}
 
@@ -1928,7 +1989,7 @@ int nss_ppe_node_detach(struct nss_qdisc
 
 	nss_ppe_destroy(nq_child);
 
-	nss_qdisc_info("Qdisc:%p, node:%p\n", nq, nq_child);
+	nss_qdisc_info("Qdisc:%px, node:%px\n", nq, nq_child);
 	return 0;
 }
 
@@ -1967,10 +2028,10 @@ int nss_ppe_node_attach(struct nss_qdisc
 	}
 
 	/*
-	 * Return error in case NSS Qdisc is attached to PPE qdisc on bridge interface.
+	 * Return error in case NSS Qdisc is attached to loopback.
 	 */
-	if (nq->is_bridge) {
-		nss_qdisc_warning("NSS Qdisc cannot be attached to PPE Qdisc on bridge interface.\n");
+	if (nq->needs_ppe_loopback) {
+		nss_qdisc_warning("NSS Qdisc cannot be attached to PPE Qdisc on loopback interface.\n");
 		return -EINVAL;
 	}
 
@@ -2020,7 +2081,7 @@ int nss_ppe_node_attach(struct nss_qdisc
 
 	nq_root->hybrid_configured = true;
 
-	nss_qdisc_info("Qdisc:%p, node:%p\n", nq, nq_child);
+	nss_qdisc_info("Qdisc:%px, node:%px\n", nq, nq_child);
 	return 0;
 }
 
@@ -2144,14 +2205,22 @@ fail:
  * nss_ppe_fallback_to_nss()
  *	Calls the initialization of NSS Qdisc when PPE initialization fails.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt)
+#else
+int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	nss_qdisc_destroy(nq);
 
 	memset(&nq->npq, 0, sizeof(struct nss_ppe_qdisc));
 	nq->ppe_init_failed = true;
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nq->qdisc->ops->init(nq->qdisc, opt) < 0) {
+#else
+	if (nq->qdisc->ops->init(nq->qdisc, opt, extack) < 0) {
+#endif
 			nss_qdisc_warning("Fallback to NSS Qdisc failed.\n");
 			return -EINVAL;
 	}
@@ -2186,7 +2255,7 @@ int nss_ppe_init(struct Qdisc *sch, stru
 	uint32_t port_num = nss_ppe_port_num_get(nq);
 
 	/*
-	 * HW qdisc is supported only on physical and bridge interfaces.
+	 * HW qdisc is supported only on physical and loopbaack ports.
 	 */
 	if (port_num >= NSS_PPE_PORT_MAX) {
 		nss_qdisc_info("HW qdisc not supported on port %d\n", port_num);
@@ -2268,7 +2337,7 @@ int nss_ppe_init(struct Qdisc *sch, stru
 		 * in qdisc that needs resource allocation in PPE. HTB qdisc on the other hand does
 		 * nothing useful and thus we don't allocate any resource".
 		 */
-		nss_qdisc_trace("Qdisc parent = %p, handle=%x\n", nq->parent,  nq->parent->qos_tag);
+		nss_qdisc_trace("Qdisc parent = %px, handle=%x\n", nq->parent,  nq->parent->qos_tag);
 		if ((nq->parent->npq.sub_type == NSS_SHAPER_CONFIG_PPE_SN_TYPE_HTB)) {
 			nq->npq.level = nq->parent->npq.level;
 		} else {
@@ -2285,7 +2354,7 @@ int nss_ppe_init(struct Qdisc *sch, stru
 	nq->mode = NSS_QDISC_MODE_PPE;
 	if (alloc_scheduler) {
 		if (nss_ppe_scheduler_set(nq) < 0) {
-			nss_qdisc_warning("%p SSDK scheduler configuration failed\n", sch);
+			nss_qdisc_warning("%px SSDK scheduler configuration failed\n", sch);
 			memset(&nq->npq, 0, sizeof(struct nss_ppe_qdisc));
 			nq->mode = NSS_QDISC_MODE_NSS;
 			return -1;
diff -uprN nss-clients-old/nss_qdisc/nss_ppe.h nss-clients/nss_qdisc/nss_ppe.h
--- nss-clients-old/nss_qdisc/nss_ppe.h	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_ppe.h	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2017, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2017, 2020, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -242,6 +242,12 @@ extern int nss_ppe_set_parent(struct Qdi
 extern int nss_ppe_get_max_prio_bands(struct nss_qdisc *nq);
 
 /*
+ * nss_ppe_all_queue_enable_hybrid()
+ *	Enables PPE queues when NSS queuing Qdiscs are attached in the hieracrchy.
+ */
+extern void nss_ppe_all_queue_enable_hybrid(struct nss_qdisc *nq);
+
+/*
  * nss_ppe_node_detach()
  *	Configuration function that helps detach a child shaper node from a parent.
  */
@@ -263,7 +269,11 @@ extern int nss_ppe_configure(struct nss_
  * nss_ppe_fallback_to_nss()
  *	Calls the initialization of NSS Qdisc when PPE initialization fails.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 extern int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt);
+#else
+extern int nss_ppe_fallback_to_nss(struct nss_qdisc *nq, struct nlattr *opt, struct netlink_ext_ack *extack);
+#endif
 
 /*
  * nss_ppe_destroy()
diff -uprN nss-clients-old/nss_qdisc/nss_prio.c nss-clients/nss_qdisc/nss_prio.c
--- nss-clients-old/nss_qdisc/nss_prio.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_prio.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2017 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2017, 2019-2021, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -37,9 +37,18 @@ static struct nla_policy nss_prio_policy
  * nss_prio_enqueue()
  *	Enqueues a skb to nssprio qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_prio_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_prio_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -51,6 +60,7 @@ static struct sk_buff *nss_prio_dequeue(
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_prio_drop()
  *	Drops a single skb from linux queue, if not empty.
@@ -61,6 +71,7 @@ static unsigned int nss_prio_drop(struct
 {
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_prio_peek()
@@ -117,15 +128,14 @@ static void nss_prio_destroy(struct Qdis
 		/*
 		 * We can now destroy it
 		 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0))
 		qdisc_destroy(q->queues[i]);
+#else
+		qdisc_put(q->queues[i]);
+#endif
 	}
 
 	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(&q->nq);
-
-	/*
 	 * Destroy the qdisc in NSS
 	 */
 	nss_qdisc_destroy(&q->nq);
@@ -157,8 +167,14 @@ static int nss_prio_get_max_bands(struct
  * nss_prio_change()
  *	Function call to configure the nssprio parameters
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_prio_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_prio_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSPRIO_MAX + 1];
 	struct nss_prio_sched_data *q;
 	struct tc_nssprio_qopt *qopt;
 
@@ -180,7 +196,11 @@ static int nss_prio_change(struct Qdisc
 		return 0;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -209,9 +229,17 @@ static int nss_prio_change(struct Qdisc
  * nss_prio_init()
  *	Initializes the nssprio qdisc
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_prio_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_prio_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_prio_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSPRIO_MAX + 1];
 	struct tc_nssprio_qopt *qopt;
 	int i;
 	unsigned int accel_mode;
@@ -223,29 +251,34 @@ static int nss_prio_init(struct Qdisc *s
 	if (!opt) {
 		accel_mode = TCA_NSS_ACCEL_MODE_PPE;
 	} else {
-		qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+		qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS);
+#else
+		qopt = nss_qdisc_qopt_get(opt, nss_prio_policy, tb, TCA_NSSPRIO_MAX, TCA_NSSPRIO_PARMS, extack);
+#endif
 		if (!qopt) {
 			return -EINVAL;
 		}
 		accel_mode = qopt->accel_mode;
 	}
 
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_PRIO, 0, accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_PRIO, 0, accel_mode, extack) < 0)
+	{
 		return -EINVAL;
 	}
 
 	nss_qdisc_info("Nssprio initialized - handle %x parent %x\n",
 			sch->handle, sch->parent);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_prio_change(sch, opt) < 0) {
+#else
+	if (nss_prio_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(&q->nq);
 	return 0;
 }
 
@@ -263,7 +296,7 @@ static int nss_prio_dump(struct Qdisc *s
 	qopt.bands = q->bands;
 	qopt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSPRIO_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -279,8 +312,14 @@ nla_put_failure:
  * nss_prio_graft()
  *	Replaces existing child qdisc with the new qdisc that is passed.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_prio_graft(struct Qdisc *sch, unsigned long arg,
 				struct Qdisc *new, struct Qdisc **old)
+#else
+static int nss_prio_graft(struct Qdisc *sch, unsigned long arg,
+				struct Qdisc *new, struct Qdisc **old,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_prio_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq_new = qdisc_priv(new);
@@ -300,10 +339,10 @@ static int nss_prio_graft(struct Qdisc *
 	*old = q->queues[band];
 	sch_tree_unlock(sch);
 
-	nss_qdisc_info("Grafting old: %p with new: %p\n", *old, new);
+	nss_qdisc_info("Grafting old: %px with new: %px\n", *old, new);
 	if (*old != &noop_qdisc) {
 		struct nss_qdisc *nq_old = qdisc_priv(*old);
-		nss_qdisc_info("Detaching old: %p\n", *old);
+		nss_qdisc_info("Detaching old: %px\n", *old);
 		nim_detach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = q->nq.qos_tag;
 
 		if (q->nq.mode == NSS_QDISC_MODE_NSS) {
@@ -365,6 +404,7 @@ static struct Qdisc *nss_prio_leaf(struc
 	return q->queues[band];
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 /*
  * nss_prio_get()
  *	Returns the band if provided the classid.
@@ -390,6 +430,24 @@ static void nss_prio_put(struct Qdisc *s
 {
 	nss_qdisc_info("Inside prio put\n");
 }
+#else
+/*
+ * nss_prio_search()
+ *	Returns the band if provided the classid.
+ */
+static unsigned long nss_prio_search(struct Qdisc *sch, u32 classid)
+{
+	struct nss_prio_sched_data *q = qdisc_priv(sch);
+	unsigned long band = TC_H_MIN(classid);
+
+	nss_qdisc_info("Inside get. Handle - %x Classid - %x Band %lu Available band %u\n", sch->handle, classid, band, q->bands);
+
+	if (band > q->bands)
+		return 0;
+
+	return band;
+}
+#endif
 
 /*
  * nss_prio_walk()
@@ -446,7 +504,7 @@ static int nss_prio_dump_class_stats(str
 	cl_q = q->queues[cl - 1];
 	cl_q->qstats.qlen = cl_q->q.qlen;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &cl_q->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &cl_q->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &cl_q->qstats) < 0)
 		return -1;
 
@@ -460,8 +518,19 @@ static int nss_prio_dump_class_stats(str
 const struct Qdisc_class_ops nss_prio_class_ops = {
 	.graft		=	nss_prio_graft,
 	.leaf		=	nss_prio_leaf,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		=	nss_prio_get,
 	.put		=	nss_prio_put,
+#else
+	.find       =   nss_prio_search,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.tcf_chain	=	nss_qdisc_tcf_chain,
+#else
+	.tcf_block	=	nss_qdisc_tcf_block,
+#endif
+	.bind_tcf	=	nss_qdisc_tcf_bind,
+	.unbind_tcf	=	nss_qdisc_tcf_unbind,
 	.walk		=	nss_prio_walk,
 	.dump		=	nss_prio_dump_class,
 	.dump_stats	=	nss_prio_dump_class_stats,
@@ -478,7 +547,9 @@ struct Qdisc_ops nss_prio_qdisc_ops __re
 	.enqueue	=	nss_prio_enqueue,
 	.dequeue	=	nss_prio_dequeue,
 	.peek		=	nss_prio_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_prio_drop,
+#endif
 	.init		=	nss_prio_init,
 	.reset		=	nss_prio_reset,
 	.destroy	=	nss_prio_destroy,
diff -uprN nss-clients-old/nss_qdisc/nss_qdisc.c nss-clients/nss_qdisc/nss_qdisc.c
--- nss-clients-old/nss_qdisc/nss_qdisc.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_qdisc.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2019 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2021 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -14,6 +14,7 @@
  **************************************************************************
  */
 
+#include <nss_api_if.h>
 #include "nss_qdisc.h"
 #include "nss_fifo.h"
 #include "nss_codel.h"
@@ -28,9 +29,6 @@
 
 void *nss_qdisc_ctx;			/* Shaping context for nss_qdisc */
 
-#define NSS_QDISC_COMMAND_TIMEOUT (600*HZ) /* We set 1min to be the command */
-					   /* timeout value for messages */
-
 /*
  * Defines related to root hash maintenance
  */
@@ -38,20 +36,68 @@ void *nss_qdisc_ctx;			/* Shaping contex
 #define NSS_QDISC_ROOT_HASH_MASK (NSS_QDISC_ROOT_HASH_SIZE - 1)
 
 /*
+ * nss_qdisc_get_interface_msg()
+ *	Returns the correct message that needs to be sent down to the NSS interface.
+ */
+int nss_qdisc_get_interface_msg(bool is_bridge, uint32_t msg_type)
+{
+	/*
+	 * We re-assign the message based on whether this is for the I shaper
+	 * or the B shaper. The is_bridge flag tells if we are on a bridge interface.
+	 */
+	if (is_bridge) {
+		switch (msg_type) {
+		case NSS_QDISC_IF_SHAPER_ASSIGN:
+			return NSS_IF_BSHAPER_ASSIGN;
+		case NSS_QDISC_IF_SHAPER_UNASSIGN:
+			return NSS_IF_BSHAPER_UNASSIGN;
+		case NSS_QDISC_IF_SHAPER_CONFIG:
+			return NSS_IF_BSHAPER_CONFIG;
+		default:
+			nss_qdisc_info("Unknown message type for a bridge - type %d", msg_type);
+			return -1;
+		}
+	} else {
+		switch (msg_type) {
+		case NSS_QDISC_IF_SHAPER_ASSIGN:
+			return NSS_IF_ISHAPER_ASSIGN;
+		case NSS_QDISC_IF_SHAPER_UNASSIGN:
+			return NSS_IF_ISHAPER_UNASSIGN;
+		case NSS_QDISC_IF_SHAPER_CONFIG:
+			return NSS_IF_ISHAPER_CONFIG;
+		default:
+			nss_qdisc_info("Unknown message type for an interface - type %d", msg_type);
+			return -1;
+		}
+	}
+}
+
+/*
+ * nss_qdisc_msg_init()
+ *      Initialize the qdisc specific message
+ */
+void nss_qdisc_msg_init(struct nss_if_msg *nim, uint16_t if_num, uint32_t msg_type, uint32_t len,
+				nss_if_msg_callback_t cb, void *app_data)
+{
+	nss_cmn_msg_init(&nim->cm, if_num, msg_type, len, (void *)cb, app_data);
+}
+
+/*
  * nss_qdisc_interface_is_virtual()
  *	Return true if it is redirect or bridge interface.
  */
 bool nss_qdisc_interface_is_virtual(struct nss_ctx_instance *nss_ctx, int32_t if_num)
 {
-#if defined(NSS_QDISC_BRIDGE_SUPPORT)
-	return nss_cmn_interface_is_redirect(nss_ctx, if_num) || nss_bridge_verify_if_num(if_num);
-#else
 	/*
 	 * If there is no bridge client, then bridge gets represented
 	 * as a redirect interface. So this check is sufficient.
 	 */
-	return nss_cmn_interface_is_redirect(nss_ctx, if_num);
+	bool is_virtual = nss_cmn_interface_is_redirect(nss_ctx, if_num) || nss_igs_verify_if_num(if_num);
+
+#if defined(NSS_QDISC_BRIDGE_SUPPORT)
+	is_virtual = is_virtual || nss_bridge_verify_if_num(if_num);
 #endif
+	return is_virtual;
 }
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
@@ -67,12 +113,25 @@ static int nss_qdisc_ppe_init(struct Qdi
 	 * Fallback to NSS Qdisc if PPE Qdisc configuration failed.
 	 */
 	if (nq->ppe_init_failed) {
-		nss_qdisc_info("Qdisc %p (type %d) HW Qdisc initialization already tried, creating NSS Qdisc\n",
+		nss_qdisc_info("Qdisc %px (type %d) HW Qdisc initialization already tried, creating NSS Qdisc\n",
 			nq->qdisc, nq->type);
 		return 0;
 	}
 
 	/*
+	 * Bridge and IFB needs PPE looback port shapers.
+	 */
+	if (nq->is_bridge || nss_igs_verify_if_num(nq->nss_interface_number)) {
+		nss_qdisc_info("Qdisc %px (type %d) init qdisc: %px, needs PPE loopback port\n",
+			nq->qdisc, nq->type, nq->qdisc);
+		nq->needs_ppe_loopback = true;
+	} else {
+		nss_qdisc_info("Qdisc %px (type %d) init qdisc: %px, does not need PPE loopback port\n",
+			nq->qdisc, nq->type, nq->qdisc);
+		nq->needs_ppe_loopback = false;
+	}
+
+	/*
 	 * Set the parent of PPE qdisc.
 	 */
 	status = nss_ppe_set_parent(sch, nq, parent);
@@ -92,13 +151,13 @@ static int nss_qdisc_ppe_init(struct Qdi
 			 * Therefore fallback only applies to qdiscs.
 			 */
 			if (nq->is_class) {
-			nss_qdisc_error("Qdisc %p (type %d) initializing HW class failed", nq->qdisc, nq->type);
+			nss_qdisc_error("Qdisc %px (type %d) initializing HW class failed", nq->qdisc, nq->type);
 			return -1;
 		}
-		nss_qdisc_info("Qdisc %p (type %d) initializing HW Qdisc failed, initializing NSS Qdisc \n",
+		nss_qdisc_info("Qdisc %px (type %d) initializing HW Qdisc failed, initializing NSS Qdisc \n",
 			nq->qdisc, nq->type);
 	} else {
-		nss_qdisc_info("Qdisc %p (type %d) successfully created in PPE\n", nq->qdisc, nq->type);
+		nss_qdisc_info("Qdisc %px (type %d) successfully created in PPE\n", nq->qdisc, nq->type);
 	}
 
 	return 0;
@@ -106,53 +165,6 @@ static int nss_qdisc_ppe_init(struct Qdi
 #endif
 
 /*
- * nss_qdisc_msg_init()
- *      Initialize the qdisc specific message
- */
-static void nss_qdisc_msg_init(struct nss_if_msg *nim, uint16_t if_num, uint32_t msg_type, uint32_t len,
-				nss_if_msg_callback_t cb, void *app_data)
-{
-	nss_cmn_msg_init(&nim->cm, if_num, msg_type, len, (void*)cb, app_data);
-}
-
-/*
- * nss_qdisc_get_interface_msg()
- *	Returns the correct message that needs to be sent down to the NSS interface.
- */
-static inline int nss_qdisc_get_interface_msg(bool is_bridge, uint32_t msg_type)
-{
-	/*
-	 * We re-assign the message based on whether this is for the I shaper
-	 * or the B shaper. The is_bridge flag tells if we are on a bridge interface.
-	 */
-	if (is_bridge) {
-		switch(msg_type) {
-		case NSS_QDISC_IF_SHAPER_ASSIGN:
-			return NSS_IF_BSHAPER_ASSIGN;
-		case NSS_QDISC_IF_SHAPER_UNASSIGN:
-			return NSS_IF_BSHAPER_UNASSIGN;
-		case NSS_QDISC_IF_SHAPER_CONFIG:
-			return NSS_IF_BSHAPER_CONFIG;
-		default:
-			nss_qdisc_info("Unknown message type for a bridge - type %d", msg_type);
-			return -1;
-		}
-	} else {
-		switch(msg_type) {
-		case NSS_QDISC_IF_SHAPER_ASSIGN:
-			return NSS_IF_ISHAPER_ASSIGN;
-		case NSS_QDISC_IF_SHAPER_UNASSIGN:
-			return NSS_IF_ISHAPER_UNASSIGN;
-		case NSS_QDISC_IF_SHAPER_CONFIG:
-			return NSS_IF_ISHAPER_CONFIG;
-		default:
-			nss_qdisc_info("Unknown message type for an interface - type %d", msg_type);
-			return -1;
-		}
-	}
-}
-
-/*
  * nss_qdisc_attach_bshaper_callback()
  *	Call back funtion for bridge shaper attach to an interface.
  */
@@ -189,7 +201,7 @@ static int nss_qdisc_attach_bshaper(stru
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("qdisc %p (type %d) is not ready: State - %d\n",
+		nss_qdisc_warning("qdisc %px (type %d) is not ready: State - %d\n",
 				sch, nq->type, state);
 		return -1;
 	}
@@ -282,7 +294,7 @@ static int nss_qdisc_detach_bshaper(stru
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("qdisc %p (type %d) is not ready: %d\n",
+		nss_qdisc_warning("qdisc %px (type %d) is not ready: %d\n",
 				sch, nq->type, state);
 		return -1;
 	}
@@ -474,7 +486,7 @@ nextdev:
  */
 static void nss_qdisc_root_cleanup_final(struct nss_qdisc *nq)
 {
-	nss_qdisc_info("Root qdisc %p (type %d) final cleanup\n",
+	nss_qdisc_info("Root qdisc %px (type %d) final cleanup\n",
 				nq->qdisc, nq->type);
 
 	/*
@@ -485,7 +497,7 @@ static void nss_qdisc_root_cleanup_final
 		/*
 		 * Unregister for bouncing to the NSS for bridge shaping
 		 */
-		nss_qdisc_info("Unregister for bridge bouncing: %p\n",
+		nss_qdisc_info("Unregister for bridge bouncing: %px\n",
 				nq->bounce_context);
 		nss_shaper_unregister_shaper_bounce_bridge(nq->nss_interface_number);
 
@@ -493,7 +505,7 @@ static void nss_qdisc_root_cleanup_final
 		 * Unregister the virtual interface we use to act as shaper
 		 * for bridge shaping.
 		 */
-		nss_qdisc_info("Release root bridge virtual interface: %p\n",
+		nss_qdisc_info("Release root bridge virtual interface: %px\n",
 				nq->virt_if_ctx);
 	}
 
@@ -506,7 +518,7 @@ static void nss_qdisc_root_cleanup_final
 		/*
 		 * Unregister for interface bouncing of packets
 		 */
-		nss_qdisc_info("Unregister for interface bouncing: %p\n",
+		nss_qdisc_info("Unregister for interface bouncing: %px\n",
 				nq->bounce_context);
 		nss_shaper_unregister_shaper_bounce_interface(nq->nss_interface_number);
 	}
@@ -533,7 +545,7 @@ static void nss_qdisc_root_cleanup_shape
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_error("Root qdisc %p (type %d) shaper unsassign FAILED\n", nq->qdisc, nq->type);
+		nss_qdisc_error("Root qdisc %px (type %d) shaper unsassign FAILED\n", nq->qdisc, nq->type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_UNASSIGN_SHAPER_FAIL);
 		wake_up(&nq->wait_queue);
 		return;
@@ -552,7 +564,7 @@ static void nss_qdisc_root_cleanup_shape
 	nss_tx_status_t rc;
 	int msg_type;
 
-	nss_qdisc_info("Root qdisc %p (type %d): shaper unassign: %d\n",
+	nss_qdisc_info("Root qdisc %px (type %d): shaper unassign: %d\n",
 			nq->qdisc, nq->type, nq->shaper_id);
 
 	msg_type = nss_qdisc_get_interface_msg(nq->is_bridge, NSS_QDISC_IF_SHAPER_UNASSIGN);
@@ -570,7 +582,7 @@ static void nss_qdisc_root_cleanup_shape
 		return;
 	}
 
-	nss_qdisc_error("Root qdisc %p (type %d): unassign command send failed: "
+	nss_qdisc_error("Root qdisc %px (type %d): unassign command send failed: "
 		"%d, shaper id: %d\n", nq->qdisc, nq->type, rc, nq->shaper_id);
 
 	atomic_set(&nq->state, NSS_QDISC_STATE_UNASSIGN_SHAPER_SEND_FAIL);
@@ -586,7 +598,7 @@ static void nss_qdisc_root_cleanup_free_
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_error("Root qdisc %p (type %d) free FAILED response "
+		nss_qdisc_error("Root qdisc %px (type %d) free FAILED response "
 					"type: %d\n", nq->qdisc, nq->type,
 					nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_NODE_FREE_FAIL);
@@ -594,10 +606,9 @@ static void nss_qdisc_root_cleanup_free_
 		return;
 	}
 
-	nss_qdisc_info("Root qdisc %p (type %d) free SUCCESS - response "
+	nss_qdisc_info("Root qdisc %px (type %d) free SUCCESS - response "
 			"type: %d\n", nq->qdisc, nq->type,
 			nim->msg.shaper_configure.config.response_type);
-
 	nss_qdisc_root_cleanup_shaper_unassign(nq);
 }
 
@@ -611,7 +622,7 @@ static void nss_qdisc_root_cleanup_free_
 	nss_tx_status_t rc;
 	int msg_type;
 
-	nss_qdisc_info("Root qdisc %p (type %d): freeing shaper node\n",
+	nss_qdisc_info("Root qdisc %px (type %d): freeing shaper node\n",
 			nq->qdisc, nq->type);
 
 	/*
@@ -633,7 +644,7 @@ static void nss_qdisc_root_cleanup_free_
 		return;
 	}
 
-	nss_qdisc_error("Qdisc %p (type %d): free command send "
+	nss_qdisc_error("Qdisc %px (type %d): free command send "
 		"failed: %d, qos tag: %x\n", nq->qdisc, nq->type,
 		rc, nq->qos_tag);
 
@@ -651,7 +662,7 @@ static void nss_qdisc_root_init_root_ass
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_warning("Root assign FAILED for qdisc %p (type %d), "
+		nss_qdisc_warning("Root assign FAILED for qdisc %px (type %d), "
 			"response type: %d\n", nq->qdisc, nq->type,
 			nim->msg.shaper_configure.config.response_type);
 		nq->pending_final_state = NSS_QDISC_STATE_ROOT_SET_FAIL;
@@ -659,7 +670,7 @@ static void nss_qdisc_root_init_root_ass
 		return;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): set as root is done. Response - %d"
+	nss_qdisc_info("Qdisc %px (type %d): set as root is done. Response - %d"
 			, nq->qdisc, nq->type, nim->msg.shaper_configure.config.response_type);
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 	wake_up(&nq->wait_queue);
@@ -677,7 +688,7 @@ static void nss_qdisc_root_init_alloc_no
 	int msg_type;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_info("Qdisc %p (type %d) root alloc node FAILED "
+		nss_qdisc_info("Qdisc %px (type %d) root alloc node FAILED "
 			"response type: %d\n", nq->qdisc, nq->type,
 			nim->msg.shaper_configure.config.response_type);
 
@@ -690,7 +701,7 @@ static void nss_qdisc_root_init_alloc_no
 		return;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d), shaper node alloc success: %u\n",
+	nss_qdisc_info("Qdisc %px (type %d), shaper node alloc success: %u\n",
 				nq->qdisc, nq->type, nq->shaper_id);
 
 	/*
@@ -751,7 +762,7 @@ static void nss_qdisc_root_init_shaper_a
 	 * Shaper has been allocated and assigned
 	 */
 	nq->shaper_id = nim->msg.shaper_assign.new_shaper_id;
-	nss_qdisc_info("Qdisc %p (type %d), shaper assigned: %u\n",
+	nss_qdisc_info("Qdisc %px (type %d), shaper assigned: %u\n",
 				nq->qdisc, nq->type, nq->shaper_id);
 
 	/*
@@ -773,14 +784,13 @@ static void nss_qdisc_root_init_shaper_a
 	/*
 	 * Unable to send alloc node command, cleanup from unassigning the shaper
 	 */
-	nss_qdisc_warning("Qdisc %p (type %d) create command failed: %d\n",
+	nss_qdisc_warning("Qdisc %px (type %d) create command failed: %d\n",
 			nq->qdisc, nq->type, rc);
 
 	nq->pending_final_state = NSS_QDISC_STATE_NODE_ALLOC_SEND_FAIL;
 	nss_qdisc_root_cleanup_shaper_unassign(nq);
 }
 
-
 /*
  * nss_qdisc_child_cleanup_final()
  *	Perform final cleanup of a shaper node after all shaper node
@@ -788,7 +798,7 @@ static void nss_qdisc_root_init_shaper_a
  */
 static void nss_qdisc_child_cleanup_final(struct nss_qdisc *nq)
 {
-	nss_qdisc_info("Final cleanup type %d: %p\n",
+	nss_qdisc_info("Final cleanup type %d: %px\n",
 			nq->type, nq->qdisc);
 
 	/*
@@ -804,7 +814,6 @@ static void nss_qdisc_child_cleanup_fina
 	wake_up(&nq->wait_queue);
 }
 
-
 /*
  * nss_qdisc_child_cleanup_free_node_callback()
  *	Invoked on the response to freeing a child shaper node
@@ -815,14 +824,14 @@ static void nss_qdisc_child_cleanup_free
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_error("Qdisc %p (type %d qos_tag %x): child free FAILED response type: %d\n",
+		nss_qdisc_error("Qdisc %px (type %d qos_tag %x): child free FAILED response type: %d\n",
 			nq->qdisc, nq->type, nq->qos_tag, nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_NODE_FREE_FAIL);
 		wake_up(&nq->wait_queue);
 		return;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): child shaper node "
+	nss_qdisc_info("Qdisc %px (type %d): child shaper node "
 			"free complete\n", nq->qdisc, nq->type);
 
 	/*
@@ -841,7 +850,7 @@ static void nss_qdisc_child_cleanup_free
 	nss_tx_status_t rc;
 	int msg_type;
 
-	nss_qdisc_info("Qdisc %p (type %d qos_tag %x): free shaper node command\n",
+	nss_qdisc_info("Qdisc %px (type %d qos_tag %x): free shaper node command\n",
 			nq->qdisc, nq->type, nq->qos_tag);
 
 	/*
@@ -859,7 +868,7 @@ static void nss_qdisc_child_cleanup_free
 		return;
 	}
 
-	nss_qdisc_error("Qdisc %p (type %d): child free node command send "
+	nss_qdisc_error("Qdisc %px (type %d): child free node command send "
 			"failed: %d, qos tag: %x\n", nq->qdisc, nq->type,
 			rc, nq->qos_tag);
 
@@ -876,7 +885,7 @@ static void nss_qdisc_child_init_alloc_n
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_error("Qdisc %p (type %d): child alloc node FAILED, response "
+		nss_qdisc_error("Qdisc %px (type %d): child alloc node FAILED, response "
 			"type: %d\n", nq->qdisc, nq->type, nim->msg.shaper_configure.config.response_type);
 		/*
 		 * Cleanup from final stage
@@ -889,7 +898,7 @@ static void nss_qdisc_child_init_alloc_n
 	/*
 	 * Shaper node has been allocated
 	 */
-	nss_qdisc_info("Qdisc %p (type %d): shaper node successfully "
+	nss_qdisc_info("Qdisc %px (type %d): shaper node successfully "
 			"created as a child node\n", nq->qdisc, nq->type);
 
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
@@ -914,7 +923,11 @@ static inline void nss_qdisc_add_to_tail
 	 * We do not use the qdisc_enqueue_tail() API here in order
 	 * to prevent stats from getting updated by the API.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	__skb_queue_tail(&sch->q, skb);
+#else
+	__qdisc_enqueue_tail(skb, &sch->q);
+#endif
 
 	spin_unlock_bh(&nq->bounce_protection_lock);
 };
@@ -929,7 +942,11 @@ static inline void nss_qdisc_add_to_tail
 	 * We do not use the qdisc_enqueue_tail() API here in order
 	 * to prevent stats from getting updated by the API.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
 	__skb_queue_tail(&sch->q, skb);
+#else
+	__qdisc_enqueue_tail(skb, &sch->q);
+#endif
 };
 
 /*
@@ -951,10 +968,12 @@ static inline struct sk_buff *nss_qdisc_
 	 * We use __skb_dequeue() to ensure that
 	 * stats don't get updated twice.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0))
 	skb = __skb_dequeue(&sch->q);
-
+#else
+	skb = __qdisc_dequeue_head(&sch->q);
+#endif
 	spin_unlock_bh(&nq->bounce_protection_lock);
-
 	return skb;
 };
 
@@ -968,7 +987,11 @@ static inline struct sk_buff *nss_qdisc_
 	 * We use __skb_dequeue() to ensure that
 	 * stats don't get updated twice.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0))
 	return __skb_dequeue(&sch->q);
+#else
+	return __qdisc_dequeue_head(&sch->q);
+#endif
 };
 
 /*
@@ -988,6 +1011,32 @@ static void nss_qdisc_bounce_callback(vo
 }
 
 /*
+ * nss_qdisc_mark_and_schedule()
+ *	Mark the classid in packet and enqueue it.
+ */
+static void nss_qdisc_mark_and_schedule(void *app_data, struct sk_buff *skb)
+{
+	struct Qdisc *sch = (struct Qdisc *)app_data;
+	uint16_t temp = TC_H_MAJ(skb->priority) >> 16;
+
+	/*
+	 * Restore the priority field of skb to its value before bouncing.
+	 * Before bounce, we saved the priority value to tc_index field.
+	 *
+	 * Save the qostag of shaped packet to tc_index field.
+	 */
+	skb->priority = (skb->tc_index << 16) | TC_H_MIN(skb->priority);
+	skb->tc_index = temp;
+
+	/*
+	 * Enqueue the packet for transmit and schedule a dequeue
+	 * This enqueue has to be protected in order to avoid corruption.
+	 */
+	nss_qdisc_add_to_tail_protected(skb, sch);
+	__netif_schedule(sch);
+}
+
+/*
  * nss_qdisc_replace()
  *	Used to replace old qdisc with a new qdisc.
  */
@@ -1020,24 +1069,33 @@ struct Qdisc *nss_qdisc_replace(struct Q
  * nss_qdisc_qopt_get()
  *	Extracts qopt from opt.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params)
+#else
 void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
-				uint32_t tca_max, uint32_t tca_params)
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params, struct netlink_ext_ack *extack)
+#endif
 {
-	struct nlattr *na[tca_max + 1];
 	int err;
 
 	if (!opt) {
 		return NULL;
 	}
 
-	err = nla_parse_nested(na, tca_max, opt, policy);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	err = nla_parse_nested(tb, tca_max, opt, policy);
+#else
+	err = nla_parse_nested_deprecated(tb, tca_max, opt, policy, extack);
+#endif
+
 	if (err < 0)
 		return NULL;
 
-	if (na[tca_params] == NULL)
+	if (tb[tca_params] == NULL)
 		return NULL;
 
-	return nla_data(na[tca_params]);
+	return nla_data(tb[tca_params]);
 }
 
 /*
@@ -1063,16 +1121,17 @@ struct sk_buff *nss_qdisc_peek(struct Qd
 	struct sk_buff *skb;
 
 	if (!nq->is_virtual) {
-		skb = skb_peek(&sch->q);
+		skb = qdisc_peek_head(sch);
 	} else {
 		spin_lock_bh(&nq->bounce_protection_lock);
-		skb = skb_peek(&sch->q);
+		skb = qdisc_peek_head(sch);
 		spin_unlock_bh(&nq->bounce_protection_lock);
 	}
 
 	return skb;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_qdisc_drop()
  *	Called to drop the packet at the head of queue
@@ -1095,6 +1154,7 @@ unsigned int nss_qdisc_drop(struct Qdisc
 
 	return ret;
 }
+#endif
 
 /*
  * nss_qdisc_reset()
@@ -1102,9 +1162,16 @@ unsigned int nss_qdisc_drop(struct Qdisc
  */
 void nss_qdisc_reset(struct Qdisc *sch)
 {
-	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nss_qdisc *nq;
 
-	nss_qdisc_info("Qdisc %p (type %d) resetting\n",
+	if(!(sch->flags & TCQ_F_NSS)) {
+		qdisc_reset_queue(sch);
+		nss_qdisc_info("Qdisc %px resetting non NSS qdisc\n", sch);
+		return;
+	}
+
+	nq = qdisc_priv(sch);
+	nss_qdisc_info("Qdisc %px (type %d) resetting\n",
 			sch, nq->type);
 
 	/*
@@ -1121,15 +1188,58 @@ void nss_qdisc_reset(struct Qdisc *sch)
 		spin_unlock_bh(&nq->bounce_protection_lock);
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d) reset complete\n",
+	nss_qdisc_info("Qdisc %px (type %d) reset complete\n",
 			sch, nq->type);
 }
 
 /*
+ * nss_qdisc_iterate_fl()
+ *	Iterate the filter list over the qdisc.
+ *
+ * Return 1, if the packet need not to be processed further, otherwise, return 0.
+ */
+static bool nss_qdisc_iterate_fl(struct sk_buff *skb, struct Qdisc *sch)
+{
+	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct tcf_proto *tcf;
+	struct tcf_result res;
+	int status;
+
+	if (!(tcf = rcu_dereference_bh(nq->filter_list))) {
+		return 0;
+	}
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	status = tc_classify(skb, tcf, &res, false);
+#else
+	status = tcf_classify(skb, tcf, &res, false);
+#endif
+	if ((status == TC_ACT_STOLEN) || (status == TC_ACT_QUEUED)) {
+		return 1;
+	}
+
+	/*
+	 * Check the tc filter's action result.
+	 * Save the higher 16-bits of skb's priority field in tc_index
+	 * and update it with the class-id to be used for ingress shaping
+	 * by NSS firmware.
+	 */
+	if (status != TC_ACT_UNSPEC) {
+		skb->tc_index = TC_H_MAJ(skb->priority) >> 16;
+		skb->priority = TC_H_MAKE(res.classid, skb->priority);
+	}
+	return 0;
+}
+
+/*
  * nss_qdisc_enqueue()
  *	Generic enqueue call for enqueuing packets into NSS for shaping
  */
-int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
+extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free)
+#endif
 {
 	struct nss_qdisc *nq = qdisc_priv(sch);
 	nss_tx_status_t status;
@@ -1138,8 +1248,8 @@ int nss_qdisc_enqueue(struct sk_buff *sk
 	 * If we are not the root qdisc then we should not be getting packets!!
 	 */
 	if (unlikely(!nq->is_root)) {
-		nss_qdisc_error("Qdisc %p (type %d): unexpected packet "
-			"for child qdisc - skb: %p\n", sch, nq->type, skb);
+		nss_qdisc_error("Qdisc %px (type %d): unexpected packet "
+			"for child qdisc - skb: %px\n", sch, nq->type, skb);
 		nss_qdisc_add_to_tail(skb, sch);
 		__netif_schedule(sch);
 		return NET_XMIT_SUCCESS;
@@ -1178,6 +1288,30 @@ int nss_qdisc_enqueue(struct sk_buff *sk
 	 * shaped we allow it to be dequeued for transmit.
 	 */
 
+	/*
+	 * Iterate over the filters attached to the qdisc.
+	 */
+	if (nss_qdisc_iterate_fl(skb, sch)) {
+		kfree_skb(skb);
+		return NET_XMIT_SUCCESS;
+	}
+
+	/*
+	 * Skip the shaping of already shaped packets.
+	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	if (skb->tc_verd & TC_NCLS_NSS) {
+		skb->tc_verd = CLR_TC_NCLS_NSS(skb->tc_verd);
+		nss_qdisc_mark_and_schedule(nq->qdisc, skb);
+		return NET_XMIT_SUCCESS;
+	}
+#else
+	if (skb_skip_tc_classify_offload(skb)) {
+		nss_qdisc_mark_and_schedule(nq->qdisc, skb);
+		return NET_XMIT_SUCCESS;
+	}
+#endif
+
 	if (!nq->is_virtual) {
 		/*
 		 * TX to an NSS physical - the shaping will occur as part of normal
@@ -1198,7 +1332,7 @@ int nss_qdisc_enqueue(struct sk_buff *sk
 			return NET_XMIT_SUCCESS;
 		}
 
-		nss_qdisc_trace("Qdisc %p (type %d): failed to bounce for bridge %d, skb: %p\n",
+		nss_qdisc_trace("Qdisc %px (type %d): failed to bounce for bridge %d, skb: %px\n",
 					sch, nq->type, nq->nss_interface_number, skb);
 		goto enqueue_drop;
 	}
@@ -1216,8 +1350,8 @@ int nss_qdisc_enqueue(struct sk_buff *sk
 	/*
 	 * We failed to bounce the packet for shaping on a virtual interface
 	 */
-	nss_qdisc_trace("Qdisc %p (type %d): failed to bounce for "
-		"interface: %d, skb: %p\n", sch, nq->type,
+	nss_qdisc_trace("Qdisc %px (type %d): failed to bounce for "
+		"interface: %d, skb: %px\n", sch, nq->type,
 		nq->nss_interface_number, skb);
 
 enqueue_drop:
@@ -1225,12 +1359,15 @@ enqueue_drop:
 	 * We were unable to transmit the packet for bridge shaping.
 	 * We therefore drop it.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	kfree_skb(skb);
 
 	spin_lock_bh(&nq->lock);
 	sch->qstats.drops++;
 	spin_unlock_bh(&nq->lock);
-
+#else
+	qdisc_drop(skb, sch, to_free);
+#endif
 	return NET_XMIT_DROP;
 }
 
@@ -1264,14 +1401,14 @@ static void nss_qdisc_set_hybrid_mode_ca
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_error("Qdisc %p (type %d): shaper node set default FAILED, response type: %d\n",
+		nss_qdisc_error("Qdisc %px (type %d): shaper node set default FAILED, response type: %d\n",
 			nq->qdisc, nq->type, nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_FAILED_RESPONSE);
 		wake_up(&nq->wait_queue);
 		return;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): attach complete\n", nq->qdisc, nq->type);
+	nss_qdisc_info("Qdisc %px (type %d): attach complete\n", nq->qdisc, nq->type);
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 	wake_up(&nq->wait_queue);
 }
@@ -1286,12 +1423,12 @@ int nss_qdisc_set_hybrid_mode(struct nss
 	int msg_type;
 	struct nss_if_msg nim;
 
-	nss_qdisc_info("Setting qdisc %p (type %d) as hybrid mode\n",
+	nss_qdisc_info("Setting qdisc %px (type %d) as hybrid mode\n",
 			nq->qdisc, nq->type);
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("Qdisc %p (type %d): qdisc state not ready: %d\n",
+		nss_qdisc_warning("Qdisc %px (type %d): qdisc state not ready: %d\n",
 				nq->qdisc, nq->type, state);
 		return -1;
 	}
@@ -1338,13 +1475,13 @@ int nss_qdisc_set_hybrid_mode(struct nss
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_error("Qdisc %p (type %d): failed to set hybrid mode "
+		nss_qdisc_error("Qdisc %px (type %d): failed to set hybrid mode "
 			"State: %d\n", nq->qdisc, nq->type, state);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): shaper node set hybrid mode complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): shaper node set hybrid mode complete\n",
 			nq->qdisc, nq->type);
 	return 0;
 }
@@ -1359,14 +1496,14 @@ static void nss_qdisc_set_default_callba
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_error("Qdisc %p (type %d): shaper node set default FAILED, response type: %d\n",
+		nss_qdisc_error("Qdisc %px (type %d): shaper node set default FAILED, response type: %d\n",
 			nq->qdisc, nq->type, nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_FAILED_RESPONSE);
 		wake_up(&nq->wait_queue);
 		return;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): attach complete\n", nq->qdisc, nq->type);
+	nss_qdisc_info("Qdisc %px (type %d): attach complete\n", nq->qdisc, nq->type);
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 	wake_up(&nq->wait_queue);
 }
@@ -1381,12 +1518,12 @@ int nss_qdisc_set_default(struct nss_qdi
 	int msg_type;
 	struct nss_if_msg nim;
 
-	nss_qdisc_info("Setting qdisc %p (type %d) as default\n",
+	nss_qdisc_info("Setting qdisc %px (type %d) as default\n",
 			nq->qdisc, nq->type);
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("Qdisc %p (type %d): qdisc state not ready: %d\n",
+		nss_qdisc_warning("Qdisc %px (type %d): qdisc state not ready: %d\n",
 				nq->qdisc, nq->type, state);
 		return -1;
 	}
@@ -1427,13 +1564,13 @@ int nss_qdisc_set_default(struct nss_qdi
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_error("Qdisc %p (type %d): failed to default "
+		nss_qdisc_error("Qdisc %px (type %d): failed to default "
 			"State: %d\n", nq->qdisc, nq->type, state);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): shaper node default complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): shaper node default complete\n",
 			nq->qdisc, nq->type);
 	return 0;
 }
@@ -1448,7 +1585,7 @@ static void nss_qdisc_node_attach_callba
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_info("Qdisc %p (type %d) shaper node attach FAILED - response "
+		nss_qdisc_info("Qdisc %px (type %d) shaper node attach FAILED - response "
 			"type: %d\n", nq->qdisc, nq->type,
 			nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_FAILED_RESPONSE);
@@ -1456,7 +1593,7 @@ static void nss_qdisc_node_attach_callba
 		return;
 	}
 
-	nss_qdisc_info("qdisc type %d: %p, attach complete\n",
+	nss_qdisc_info("qdisc type %d: %px, attach complete\n",
 			nq->type, nq->qdisc);
 
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
@@ -1473,12 +1610,12 @@ int nss_qdisc_node_attach(struct nss_qdi
 	int32_t state, rc;
 	int msg_type;
 
-	nss_qdisc_info("Qdisc %p (type %d) attaching\n",
+	nss_qdisc_info("Qdisc %px (type %d) attaching\n",
 			nq->qdisc, nq->type);
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
 		if (nss_ppe_node_attach(nq, nq_child) < 0) {
-			nss_qdisc_warning("attach of new qdisc %p failed\n", nq_child->qdisc);
+			nss_qdisc_warning("attach of new qdisc %px failed\n", nq_child->qdisc);
 			return -EINVAL;
 
 		}
@@ -1488,7 +1625,7 @@ int nss_qdisc_node_attach(struct nss_qdi
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("Qdisc %p (type %d): not ready, state: %d\n",
+		nss_qdisc_warning("Qdisc %px (type %d): not ready, state: %d\n",
 				nq->qdisc, nq->type, state);
 		return -1;
 	}
@@ -1528,7 +1665,7 @@ int nss_qdisc_node_attach(struct nss_qdi
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_error("Qdisc %p (type %d) failed to attach child "
+		nss_qdisc_error("Qdisc %px (type %d) failed to attach child "
 			"node, State: %d\n", nq->qdisc, nq->type, state);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
@@ -1541,7 +1678,15 @@ int nss_qdisc_node_attach(struct nss_qdi
 	nq_child->parent = nq;
 	spin_unlock_bh(&nq_child->lock);
 
-	nss_qdisc_info("Qdisc %p (type %d): shaper node attach complete\n",
+#if defined(NSS_QDISC_PPE_SUPPORT)
+	/*
+	 * In case of hybrid mode, enable PPE queues when NSS queuing
+	 * Qdiscs are attached in the hierarchy.
+	 */
+	nss_ppe_all_queue_enable_hybrid(nq_child);
+#endif
+
+	nss_qdisc_info("Qdisc %px (type %d): shaper node attach complete\n",
 			nq->qdisc, nq->type);
 	return 0;
 }
@@ -1556,7 +1701,7 @@ static void nss_qdisc_node_detach_callba
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_info("Qdisc %p (type %d): shaper node detach FAILED - response "
+		nss_qdisc_info("Qdisc %px (type %d): shaper node detach FAILED - response "
 			"type: %d\n", nq->qdisc, nq->type,
 			nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_FAILED_RESPONSE);
@@ -1564,7 +1709,7 @@ static void nss_qdisc_node_detach_callba
 		return;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): detach complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): detach complete\n",
 			nq->qdisc, nq->type);
 
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
@@ -1580,13 +1725,13 @@ int nss_qdisc_node_detach(struct nss_qdi
 {
 	int32_t state, rc, msg_type;
 
-	nss_qdisc_info("Qdisc %p (type %d) detaching\n",
+	nss_qdisc_info("Qdisc %px (type %d) detaching\n",
 			nq->qdisc, nq->type);
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
 		if (nss_ppe_node_detach(nq, nq_child) < 0) {
-			nss_qdisc_warning("detach of old qdisc %p failed\n", nq_child->qdisc);
+			nss_qdisc_warning("detach of old qdisc %px failed\n", nq_child->qdisc);
 			return -1;
 		}
 		nim->msg.shaper_configure.config.msg.shaper_node_config.snc.ppe_sn_detach.child_qos_tag = nq_child->qos_tag;
@@ -1595,7 +1740,7 @@ int nss_qdisc_node_detach(struct nss_qdi
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("Qdisc %p (type %d): not ready, state: %d\n",
+		nss_qdisc_warning("Qdisc %px (type %d): not ready, state: %d\n",
 				nq->qdisc, nq->type, state);
 		return -1;
 	}
@@ -1616,7 +1761,7 @@ int nss_qdisc_node_detach(struct nss_qdi
 	rc = nss_if_tx_msg(nq->nss_shaping_ctx, nim);
 
 	if (rc != NSS_TX_SUCCESS) {
-		nss_qdisc_warning("Qdisc %p (type %d): Failed to send configure "
+		nss_qdisc_warning("Qdisc %px (type %d): Failed to send configure "
 					"message.", nq->qdisc, nq->type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
@@ -1635,7 +1780,7 @@ int nss_qdisc_node_detach(struct nss_qdi
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_error("Qdisc %p (type %d): failed to detach child node, "
+		nss_qdisc_error("Qdisc %px (type %d): failed to detach child node, "
 				"State: %d\n", nq->qdisc, nq->type, state);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
@@ -1645,7 +1790,7 @@ int nss_qdisc_node_detach(struct nss_qdi
 	nq_child->parent = NULL;
 	spin_unlock_bh(&nq_child->lock);
 
-	nss_qdisc_info("Qdisc %p (type %d): shaper node detach complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): shaper node detach complete\n",
 			nq->qdisc, nq->type);
 	return 0;
 }
@@ -1660,7 +1805,7 @@ static void nss_qdisc_configure_callback
 	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
 
 	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_info("Qdisc %p (type %d): shaper node configure FAILED "
+		nss_qdisc_info("Qdisc %px (type %d): shaper node configure FAILED "
 			"response type: %d\n", nq->qdisc, nq->type,
 			nim->msg.shaper_configure.config.response_type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_FAILED_RESPONSE);
@@ -1676,7 +1821,7 @@ static void nss_qdisc_configure_callback
 		nq->config_cb(nq, &nim->msg.shaper_configure.config);
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): configuration complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): configuration complete\n",
 			nq->qdisc, nq->type);
 	atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 	wake_up(&nq->wait_queue);
@@ -1692,11 +1837,11 @@ int nss_qdisc_configure(struct nss_qdisc
 	int32_t state, rc;
 	int msg_type;
 
-	nss_qdisc_info("Qdisc %p (type %d) configuring\n", nq->qdisc, nq->type);
+	nss_qdisc_info("Qdisc %px (type %d) configuring\n", nq->qdisc, nq->type);
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("Qdisc %p (type %d): not ready for configure, "
+		nss_qdisc_warning("Qdisc %px (type %d): not ready for configure, "
 				"state : %d\n", nq->qdisc, nq->type, state);
 		return -1;
 	}
@@ -1717,7 +1862,7 @@ int nss_qdisc_configure(struct nss_qdisc
 	rc = nss_if_tx_msg(nq->nss_shaping_ctx, nim);
 
 	if (rc != NSS_TX_SUCCESS) {
-		nss_qdisc_warning("Qdisc %p (type %d): Failed to send configure "
+		nss_qdisc_warning("Qdisc %px (type %d): Failed to send configure "
 			"message\n", nq->qdisc, nq->type);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
@@ -1736,24 +1881,25 @@ int nss_qdisc_configure(struct nss_qdisc
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_error("Qdisc %p (type %d): failed to configure shaper "
+		nss_qdisc_error("Qdisc %px (type %d): failed to configure shaper "
 			"node: State: %d\n", nq->qdisc, nq->type, state);
 		atomic_set(&nq->state, NSS_QDISC_STATE_READY);
 		return -1;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): shaper node configure complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): shaper node configure complete\n",
 			nq->qdisc, nq->type);
 	return 0;
 }
 
+
 /*
  * nss_qdisc_register_configure_callback()
  *	Register shaper configure callback, which gets invoked on receiving a response.
  */
 void nss_qdisc_register_configure_callback(struct nss_qdisc *nq, nss_qdisc_configure_callback_t cb)
 {
-	nss_qdisc_assert(!nq->config_cb, "Qdisc %p: config callback already registered", nq);
+	nss_qdisc_assert(!nq->config_cb, "Qdisc %px: config callback already registered", nq);
 	nq->config_cb = cb;
 }
 
@@ -1763,7 +1909,7 @@ void nss_qdisc_register_configure_callba
  */
 void nss_qdisc_register_stats_callback(struct nss_qdisc *nq, nss_qdisc_stats_callback_t cb)
 {
-	nss_qdisc_assert(!nq->stats_cb, "Qdisc %p: config callback already registered", nq);
+	nss_qdisc_assert(!nq->stats_cb, "Qdisc %px: config callback already registered", nq);
 	nq->stats_cb = cb;
 }
 
@@ -1777,9 +1923,18 @@ void nss_qdisc_destroy(struct nss_qdisc
 	int32_t state;
 	nss_tx_status_t cmd_status;
 
-	nss_qdisc_info("Qdisc %p (type %d) destroy\n",
+	nss_qdisc_info("Qdisc %px (type %d) destroy\n",
 			nq->qdisc, nq->type);
 
+	/*
+	 * Destroy any attached filter over qdisc.
+	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	tcf_destroy_chain(&nq->filter_list);
+#else
+	tcf_block_put(nq->block);
+#endif
+
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
 		nss_ppe_destroy(nq);
@@ -1788,34 +1943,50 @@ void nss_qdisc_destroy(struct nss_qdisc
 
 	state = atomic_read(&nq->state);
 	if (state != NSS_QDISC_STATE_READY) {
-		nss_qdisc_warning("Qdisc %p (type %d): destroy not ready, "
+		nss_qdisc_warning("Qdisc %px (type %d): destroy not ready, "
 				"state: %d\n", nq->qdisc, nq->type, state);
 		return;
 	}
 
 	/*
+	 * Delete node from stats list
+	 */
+	nss_qdisc_stats_qdisc_detach(nq);
+
+	/*
 	 * How we begin to tidy up depends on whether we are root or child
 	 */
 	nq->pending_final_state = NSS_QDISC_STATE_IDLE;
-	if (nq->is_root) {
+	if (!nq->is_root) {
+		nss_qdisc_child_cleanup_free_node(nq);
+	} else {
 
 		/*
 		 * If this is root on a bridge interface, then unassign
 		 * the bshaper from all the attached interfaces.
 		 */
 		if (nq->is_bridge) {
-			nss_qdisc_info("Qdisc %p (type %d): is root on bridge. Need to "
+			nss_qdisc_info("Qdisc %px (type %d): is root on bridge. Need to "
 				"unassign bshapers from its interfaces\n", nq->qdisc, nq->type);
 			nss_qdisc_refresh_bshaper_assignment(nq->qdisc, NSS_QDISC_SCAN_AND_UNASSIGN_BSHAPER);
 		}
 
 		/*
+		 * Stop stats polling
+		 */
+		nss_qdisc_stats_stop_polling(nq);
+
+		/*
 		 * Begin by freeing the root shaper node
 		 */
 		nss_qdisc_root_cleanup_free_node(nq);
 
-	} else {
-		nss_qdisc_child_cleanup_free_node(nq);
+		/*
+		 * In case of IGS interface, release the reference of the IGS module.
+		 */
+		if (nss_igs_verify_if_num(nq->nss_interface_number)) {
+			nss_igs_module_put();
+		}
 	}
 
 	/*
@@ -1840,23 +2011,30 @@ void nss_qdisc_destroy(struct nss_qdisc
 		 */
 		cmd_status = nss_virt_if_destroy_sync(nq->virt_if_ctx);
 		if (cmd_status != NSS_TX_SUCCESS) {
-			nss_qdisc_error("Qdisc %p virtual interface %p destroy failed: %d\n",
+			nss_qdisc_error("Qdisc %px virtual interface %px destroy failed: %d\n",
 						nq->qdisc, nq->virt_if_ctx, cmd_status);
 		}
 		nq->virt_if_ctx = NULL;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d): destroy complete\n",
+	nss_qdisc_info("Qdisc %px (type %d): destroy complete\n",
 			nq->qdisc, nq->type);
 }
 
 /*
- * nss_qdisc_init()
+ * __nss_qdisc_init()
  *	Initializes a shaper in NSS, based on the position of this qdisc (child or root)
  *	and if its a normal interface or a bridge interface.
  */
-int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+int __nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode)
 {
+#else
+int __nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode,
+		struct netlink_ext_ack *extack)
+{
+	int err;
+#endif
 	struct Qdisc *root;
 	u32 parent;
 	nss_tx_status_t rc;
@@ -1868,9 +2046,9 @@ int nss_qdisc_init(struct Qdisc *sch, st
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	bool mode_ppe = false;
 #endif
-
+	bool igs_put = false;
 	if (accel_mode >= TCA_NSS_ACCEL_MODE_MAX) {
-		nss_qdisc_warning("Qdisc %p (type %d) accel_mode:%u should be < %u\n",
+		nss_qdisc_warning("Qdisc %px (type %d) accel_mode:%u should be < %u\n",
 					sch, nq->type, accel_mode, TCA_NSS_ACCEL_MODE_MAX);
 		return -1;
 	}
@@ -1925,6 +2103,12 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	atomic_set(&nq->state, NSS_QDISC_STATE_IDLE);
 
 	/*
+	 * Initialize filter list.
+	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	RCU_INIT_POINTER(nq->filter_list, NULL);
+#endif
+	/*
 	 * If we are a class, then classid is used as the qos tag.
 	 * Else the qdisc handle will be used as the qos tag.
 	 */
@@ -1944,11 +2128,13 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * true for classes. This is the reason why we check for classid.
 	 */
 	if ((sch->parent == TC_H_ROOT) && (!nq->is_class)) {
-		nss_qdisc_info("Qdisc %p (type %d) is root\n", nq->qdisc, nq->type);
+		nss_qdisc_info("Qdisc %px (type %d) is root\n", nq->qdisc, nq->type);
+		nss_qdisc_info("Qdisc %px dev-name %s qdisc_dev(sch)->qdisc %px, qdisc_dev(sch)->qdisc->handle %x\n", qdisc_dev(sch), qdisc_dev(sch)->name, qdisc_dev(sch)->qdisc, qdisc_dev(sch)->qdisc->handle);
+		nss_qdisc_info("Qdisc %px (sch %px) is root, sch->handle %x\n", nq->qdisc, sch, sch->handle);
 		nq->is_root = true;
 		root = sch;
 	} else {
-		nss_qdisc_info("Qdisc %p (type %d) not root\n", nq->qdisc, nq->type);
+		nss_qdisc_info("Qdisc %px (type %d) not root\n", nq->qdisc, nq->type);
 		nq->is_root = false;
 		root = qdisc_root(sch);
 	}
@@ -1958,24 +2144,43 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * or on a net device that is represented by a virtual NSS interface (e.g. WIFI)
 	 */
 	dev = qdisc_dev(sch);
-	nss_qdisc_info("Qdisc %p (type %d) init dev: %p\n", nq->qdisc, nq->type, dev);
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+	/*
+	 * Currently filter addition is only supported over IFB interfaces.
+	 * Therefore, perform tcf block allocation (which is used for storing
+	 * filter list) only if the input net device is an IFB device.
+	 */
+	if (netif_is_ifb_dev(dev)) {
+		err = tcf_block_get(&nq->block, &nq->filter_list, sch, extack);
+		if (err) {
+			nss_qdisc_error("%px: Unable to initialize tcf_block\n", &nq->block);
+			return -1;
+		}
+	} else {
+		RCU_INIT_POINTER(nq->filter_list, NULL);
+		nq->block = NULL;
+	}
+#endif
+
+	nss_qdisc_info("Qdisc %px (type %d) init dev: %px\n", nq->qdisc, nq->type, dev);
 
 	/*
 	 * Determine if dev is a bridge or not as this determines if we
 	 * interract with an I or B shaper.
 	 */
 	if (dev->priv_flags & IFF_EBRIDGE) {
-		nss_qdisc_info("Qdisc %p (type %d) init qdisc: %p, is bridge\n",
+		nss_qdisc_info("Qdisc %px (type %d) init qdisc: %px, is bridge\n",
 			nq->qdisc, nq->type, nq->qdisc);
 		nq->is_bridge = true;
 	} else {
-		nss_qdisc_info("Qdisc %p (type %d) init qdisc: %p, not bridge\n",
+		nss_qdisc_info("Qdisc %px (type %d) init qdisc: %px, not bridge\n",
 			nq->qdisc, nq->type, nq->qdisc);
 		nq->is_bridge = false;
 	}
 
-	nss_qdisc_info("Qdisc %p (type %d) init root: %p, qos tag: %x, "
-		"parent: %x rootid: %s owner: %p\n", nq->qdisc, nq->type, root,
+	nss_qdisc_info("Qdisc %px (type %d) init root: %px, qos tag: %x, "
+		"parent: %x rootid: %s owner: %px\n", nq->qdisc, nq->type, root,
 		nq->qos_tag, parent, root->ops->id, root->ops->owner);
 
 	/*
@@ -1983,7 +2188,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * This is to prevent mixing NSS and PPE qdisc with linux qdisc.
 	 */
 	if ((parent != TC_H_ROOT) && (root->ops->owner != THIS_MODULE)) {
-		nss_qdisc_warning("NSS qdisc %p (type %d) used along with non-nss qdiscs,"
+		nss_qdisc_warning("NSS qdisc %px (type %d) used along with non-nss qdiscs,"
 			" or the interface is currently down", nq->qdisc, nq->type);
 	}
 
@@ -2004,7 +2209,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	if (!nq->is_root) {
 		struct nss_if_msg nim_alloc;
 
-		nss_qdisc_info("Qdisc %p (type %d) initializing non-root qdisc\n",
+		nss_qdisc_info("Qdisc %px (type %d) initializing non-root qdisc\n",
 				nq->qdisc, nq->type);
 
 		/*
@@ -2015,7 +2220,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		 */
 		nq->nss_interface_number = nss_cmn_get_interface_number(nq->nss_shaping_ctx, dev);
 		if (nq->nss_interface_number < 0) {
-			nss_qdisc_error("Qdisc %p (type %d) net device unknown to "
+			nss_qdisc_error("Qdisc %px (type %d) net device unknown to "
 				"nss driver %s\n", nq->qdisc, nq->type, dev->name);
 			nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 			atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
@@ -2032,7 +2237,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		 * Try initializing PPE Qdisc first.
 		 */
 		if (mode_ppe && nss_qdisc_ppe_init(sch, nq, type, parent) < 0) {
-			nss_qdisc_error("Qdisc %p (type %d) init failed", nq->qdisc, nq->type);
+			nss_qdisc_error("Qdisc %px (type %d) init failed", nq->qdisc, nq->type);
 			nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 			atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
 			goto init_fail;
@@ -2043,7 +2248,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		 * Create a shaper node for requested type.
 		 * Essentially all we need to do is create the shaper node.
 		 */
-		nss_qdisc_info("Qdisc %p (type %d) non-root (child) create\n",
+		nss_qdisc_info("Qdisc %px (type %d) non-root (child) create\n",
 				nq->qdisc, nq->type);
 
 		/*
@@ -2059,7 +2264,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		rc = nss_if_tx_msg(nq->nss_shaping_ctx, &nim_alloc);
 
 		if (rc != NSS_TX_SUCCESS) {
-			nss_qdisc_error("Qdisc %p (type %d) create command "
+			nss_qdisc_error("Qdisc %px (type %d) create command "
 				"failed: %d\n", nq->qdisc, nq->type, rc);
 			nq->pending_final_state = NSS_QDISC_STATE_CHILD_ALLOC_SEND_FAIL;
 			nss_qdisc_child_cleanup_final(nq);
@@ -2076,13 +2281,18 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		}
 
 		state = atomic_read(&nq->state);
-		nss_qdisc_info("Qdisc %p (type %d): initialised with state: %d\n",
+		nss_qdisc_info("Qdisc %px (type %d): initialised with state: %d\n",
 					nq->qdisc, nq->type, state);
 
 		/*
 		 * If state is positive, return success
 		 */
 		if (state > 0) {
+
+			/*
+			 * Qdisc successfully initialized, add it to stats list if its not a class
+			 */
+			nss_qdisc_stats_qdisc_attach(nq);
 			return 0;
 		}
 
@@ -2096,13 +2306,13 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * bridge shaping. Further, when operating on a bridge, we monitor for
 	 * bridge port changes and assign B shapers to the interfaces of the ports.
 	 */
-	nss_qdisc_info("init qdisc type %d : %p, ROOT\n", nq->type, nq->qdisc);
+	nss_qdisc_info("init qdisc type %d : %px, ROOT\n", nq->type, nq->qdisc);
 
 	/*
 	 * Detect if we are operating on a bridge or interface
 	 */
 	if (nq->is_bridge) {
-		nss_qdisc_info("Qdisc %p (type %d): initializing root qdisc on bridge\n",
+		nss_qdisc_info("Qdisc %px (type %d): initializing root qdisc on bridge\n",
 			nq->qdisc, nq->type);
 
 		/*
@@ -2120,13 +2330,13 @@ int nss_qdisc_init(struct Qdisc *sch, st
 			 */
 			nq->virt_if_ctx = nss_virt_if_create_sync(dev);
 			if (!nq->virt_if_ctx) {
-				nss_qdisc_error("Qdisc %p (type %d): cannot create virtual interface\n",
+				nss_qdisc_error("Qdisc %px (type %d): cannot create virtual interface\n",
 					nq->qdisc, nq->type);
 				nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 				atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
 				goto init_fail;
 			}
-			nss_qdisc_info("Qdisc %p (type %d): virtual interface registered in NSS: %p\n",
+			nss_qdisc_info("Qdisc %px (type %d): virtual interface registered in NSS: %px\n",
 				nq->qdisc, nq->type, nq->virt_if_ctx);
 
 			/*
@@ -2139,7 +2349,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 			 * Save the virtual interface number
 			 */
 			nq->nss_interface_number = nss_virt_if_get_interface_num(nq->virt_if_ctx);
-			nss_qdisc_info("Qdisc %p (type %d) virtual interface number: %d\n",
+			nss_qdisc_info("Qdisc %px (type %d) virtual interface number: %d\n",
 					nq->qdisc, nq->type, nq->nss_interface_number);
 		}
 
@@ -2150,10 +2360,19 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		 * register for bridge bouncing as it will be responsible for
 		 * bouncing packets to the NSS for bridge shaping.
 		 */
-		nq->bounce_context = nss_shaper_register_shaper_bounce_bridge(nq->nss_interface_number,
-							nss_qdisc_bounce_callback, nq->qdisc, THIS_MODULE);
+		if (!nss_igs_verify_if_num(nq->nss_interface_number)) {
+			nq->bounce_context = nss_shaper_register_shaper_bounce_bridge(nq->nss_interface_number,
+					nss_qdisc_bounce_callback, nq->qdisc, THIS_MODULE);
+		} else {
+			nss_qdisc_error("Since %d is an IFB device, it cannot"
+					" register for bridge bouncing\n", nq->nss_interface_number);
+			nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
+			atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
+			goto init_fail;
+		}
+
 		if (!nq->bounce_context) {
-			nss_qdisc_error("Qdisc %p (type %d): is root but cannot register "
+			nss_qdisc_error("Qdisc %px (type %d): is root but cannot register "
 					"for bridge bouncing\n", nq->qdisc, nq->type);
 			nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 			atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
@@ -2161,7 +2380,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		}
 
 	} else {
-		nss_qdisc_info("Qdisc %p (type %d): is interface\n", nq->qdisc, nq->type);
+		nss_qdisc_info("Qdisc %px (type %d): is interface\n", nq->qdisc, nq->type);
 
 		/*
 		 * The device we are operational on MUST be recognised as an NSS interface.
@@ -2171,7 +2390,7 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		 */
 		nq->nss_interface_number = nss_cmn_get_interface_number(nq->nss_shaping_ctx, dev);
 		if (nq->nss_interface_number < 0) {
-			nss_qdisc_error("Qdisc %p (type %d): interface unknown to nss driver %s\n",
+			nss_qdisc_error("Qdisc %px (type %d): interface unknown to nss driver %s\n",
 					nq->qdisc, nq->type, dev->name);
 			nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 			atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
@@ -2184,19 +2403,44 @@ int nss_qdisc_init(struct Qdisc *sch, st
 		 */
 		nq->is_virtual = nss_qdisc_interface_is_virtual(nq->nss_shaping_ctx, nq->nss_interface_number);
 		if (!nq->is_virtual) {
-			nss_qdisc_info("Qdisc %p (type %d): interface %u is physical\n",
+			nss_qdisc_info("Qdisc %px (type %d): interface %u is physical\n",
 					nq->qdisc, nq->type, nq->nss_interface_number);
 		} else {
-			nss_qdisc_info("Qdisc %p (type %d): interface %u is virtual\n",
+			nss_qdisc_info("Qdisc %px (type %d): interface %u is virtual\n",
 					nq->qdisc, nq->type, nq->nss_interface_number);
 
 			/*
 			 * Register for interface bounce shaping.
 			 */
-			nq->bounce_context = nss_shaper_register_shaper_bounce_interface(nq->nss_interface_number,
-								nss_qdisc_bounce_callback, nq->qdisc, THIS_MODULE);
+			if (!nss_igs_verify_if_num(nq->nss_interface_number)) {
+				nq->bounce_context = nss_shaper_register_shaper_bounce_interface(nq->nss_interface_number,
+						nss_qdisc_bounce_callback, nq->qdisc, THIS_MODULE);
+			} else {
+
+				/*
+				 * In case of IGS interface, take the reference of IGS module.
+				 */
+				if (!nss_igs_module_get()) {
+					nss_qdisc_error("Module reference failed for IGS interface %d"
+							" , Qdisc %px (type %d)\n", nq->nss_interface_number,
+							nq->qdisc, nq->type);
+					nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
+					atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
+					goto init_fail;
+				}
+
+				/*
+				 * Set the flag to indicate the IGS module reference get is successful.
+				 * This flag will be used to decrement the IGS module reference in case
+				 * of any error conditions.
+				 */
+				igs_put = true;
+				nq->bounce_context = nss_shaper_register_shaper_bounce_interface(nq->nss_interface_number,
+						nss_qdisc_mark_and_schedule, nq->qdisc, THIS_MODULE);
+			}
+
 			if (!nq->bounce_context) {
-				nss_qdisc_error("Qdisc %p (type %d): is root but failed "
+				nss_qdisc_error("Qdisc %px (type %d): is root but failed "
 				"to register for interface bouncing\n", nq->qdisc, nq->type);
 				nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 				atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
@@ -2210,12 +2454,21 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 * Try initializing PPE Qdisc first.
 	 */
 	if (mode_ppe && nss_qdisc_ppe_init(sch, nq, type, parent) < 0) {
-		nss_qdisc_error("Qdisc %p (type %d) init failed", nq->qdisc, nq->type);
+		nss_qdisc_error("Qdisc %px (type %d) init failed", nq->qdisc, nq->type);
 		nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
 		atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
 		goto init_fail;
 	}
 #endif
+	/*
+	 * Initialize the stats management only for root node
+	 */
+	if (!nss_qdisc_stats_sync_many_init(nq)) {
+		nss_qdisc_error("Qdisc %px (type %d) stats sync init failed", nq->qdisc, nq->type);
+		nss_shaper_unregister_shaping(nq->nss_shaping_ctx);
+		atomic_set(&nq->state, NSS_QDISC_STATE_INIT_FAILED);
+		goto init_fail;
+	}
 
 	/*
 	 * Create and send the shaper assign message to the NSS interface
@@ -2239,17 +2492,33 @@ int nss_qdisc_init(struct Qdisc *sch, st
 	 */
 	if (!wait_event_timeout(nq->wait_queue, atomic_read(&nq->state) != NSS_QDISC_STATE_IDLE,
 				NSS_QDISC_COMMAND_TIMEOUT)) {
+		/*
+		 * Decrement the IGS module reference.
+		 */
+		if (igs_put) {
+			nss_igs_module_put();
+		}
 		nss_qdisc_error("init for qdisc %x timedout!\n", nq->qos_tag);
 		return -1;
 	}
 
 	state = atomic_read(&nq->state);
-	nss_qdisc_info("Qdisc %p (type %d): is initialised with state: %d\n",
+	nss_qdisc_info("Qdisc %px (type %d): is initialised with state: %d\n",
 			nq->qdisc, nq->type, state);
 
 	if (state > 0) {
 
 		/*
+		 * Qdisc successfully initialized add it to stats list if its not a class
+		 */
+		nss_qdisc_stats_qdisc_attach(nq);
+
+		/*
+		 * Root node is successfully configured, start stats polling
+		 */
+		nss_qdisc_stats_start_polling(nq);
+
+		/*
 		 * Return if this is not a root qdisc on a bridge interface.
 		 */
 		if (!nq->is_root || !nq->is_bridge) {
@@ -2277,12 +2546,27 @@ int nss_qdisc_init(struct Qdisc *sch, st
 
 init_fail:
 
+	/*
+	 * Decrement the IGS module reference.
+	 */
+	if (igs_put) {
+		nss_igs_module_put();
+	}
+
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (nq->mode == NSS_QDISC_MODE_PPE) {
 		nss_ppe_destroy(nq);
 	}
 #endif
 
+
+	/*
+	 * Clean up stats sync objects if initialized.
+	 */
+	if (nq->stats_wq) {
+		nss_qdisc_stats_sync_many_exit(nq);
+	}
+
 	/*
 	 * Destroy any virtual interfaces created by us before returning a failure.
 	 */
@@ -2293,7 +2577,7 @@ init_fail:
 		 */
 		cmd_status = nss_virt_if_destroy_sync(nq->virt_if_ctx);
 		if (cmd_status != NSS_TX_SUCCESS) {
-			nss_qdisc_error("Qdisc %p virtual interface %p destroy failed: %d\n",
+			nss_qdisc_error("Qdisc %px virtual interface %px destroy failed: %d\n",
 						nq->qdisc, nq->virt_if_ctx, cmd_status);
 		}
 		nq->virt_if_ctx = NULL;
@@ -2303,198 +2587,32 @@ init_fail:
 }
 
 /*
- * nss_qdisc_basic_stats_callback()
- *	Invoked after getting basic stats
- */
-static void nss_qdisc_basic_stats_callback(void *app_data,
-				struct nss_if_msg *nim)
-{
-	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
-	struct Qdisc *qdisc = nq->qdisc;
-	struct gnet_stats_basic_packed *bstats;
-	struct gnet_stats_queue *qstats;
-	struct nss_shaper_node_stats_response *response;
-	atomic_t *refcnt;
-
-	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
-		nss_qdisc_warning("Qdisc %p (type %d): Receive stats FAILED - "
-			"response: type: %d\n", qdisc, nq->type,
-			nim->msg.shaper_configure.config.response_type);
-		atomic_sub(1, &nq->pending_stat_requests);
-		wake_up(&nq->wait_queue);
-		return;
-	}
-
-	response = &nim->msg.shaper_configure.config.msg.shaper_node_stats_get.response;
-
-	/*
-	 * Get the right stats pointers based on whether it is a class
-	 * or a qdisc.
-	 */
-	if (nq->is_class) {
-		bstats = &nq->bstats;
-		qstats = &nq->qstats;
-		refcnt = &nq->refcnt;
-	} else {
-		bstats = &qdisc->bstats;
-		qstats = &qdisc->qstats;
-		refcnt = &qdisc->refcnt;
-		qdisc->q.qlen = response->sn_stats.qlen_packets;
-	}
-
-	/*
-	 * Update qdisc->bstats
-	 */
-	spin_lock_bh(&nq->lock);
-	bstats->bytes += (__u64)response->sn_stats.delta.dequeued_bytes;
-	bstats->packets += response->sn_stats.delta.dequeued_packets;
-
-	/*
-	 * Update qdisc->qstats
-	 */
-	qstats->backlog = response->sn_stats.qlen_bytes;
-
-	qstats->drops += (response->sn_stats.delta.enqueued_packets_dropped +
-				response->sn_stats.delta.dequeued_packets_dropped);
-
-	/*
-	 * Update qdisc->qstats
-	 */
-	qstats->qlen = response->sn_stats.qlen_packets;
-	qstats->requeues = 0;
-	qstats->overlimits += response->sn_stats.delta.queue_overrun;
-	spin_unlock_bh(&nq->lock);
-
-	/*
-	 * Shapers that maintain additional unique statistics will process them
-	 * via a registered callback. So invoke if its been registered.
-	 */
-	if (nq->stats_cb) {
-		nq->stats_cb(nq, response);
-	}
-
-	/*
-	 * All access to nq fields below do not need lock protection. They
-	 * do not get manipulated on different thread contexts.
-	 */
-	if (atomic_read(refcnt) == 0) {
-		atomic_sub(1, &nq->pending_stat_requests);
-		wake_up(&nq->wait_queue);
-		return;
-	}
-
-	/*
-	 * Requests for stats again, after 1 sec.
-	 */
-	nq->stats_get_timer.expires += HZ;
-	if (nq->stats_get_timer.expires <= jiffies) {
-		nss_qdisc_info("losing time %lu, jiffies = %lu\n",
-				nq->stats_get_timer.expires, jiffies);
-		nq->stats_get_timer.expires = jiffies + HZ;
-	}
-	add_timer(&nq->stats_get_timer);
-}
-
-/*
- * nss_qdisc_get_stats_timer_callback()
- *	Invoked periodically to get updated stats
- */
-static void nss_qdisc_get_stats_timer_callback(unsigned long int data)
-{
-	struct nss_qdisc *nq = (struct nss_qdisc *)data;
-	nss_tx_status_t rc;
-	struct nss_if_msg nim;
-	int msg_type;
-
-	/*
-	 * Create and send the shaper configure message to the NSS interface
-	 */
-	msg_type = nss_qdisc_get_interface_msg(nq->is_bridge, NSS_QDISC_IF_SHAPER_CONFIG);
-	nss_qdisc_msg_init(&nim, nq->nss_interface_number, msg_type, sizeof(struct nss_if_shaper_configure),
-				nss_qdisc_basic_stats_callback,
-				nq);
-	nim.msg.shaper_configure.config.request_type = NSS_SHAPER_CONFIG_TYPE_SHAPER_NODE_BASIC_STATS_GET;
-	nim.msg.shaper_configure.config.msg.shaper_node_stats_get.qos_tag = nq->qos_tag;
-	rc = nss_if_tx_msg(nq->nss_shaping_ctx, &nim);
-
-	/*
-	 * Check if we failed to send the stats request to NSS.
-	 */
-	if (rc != NSS_TX_SUCCESS) {
-		nss_qdisc_info("%p: stats fetch request dropped, causing "
-				"delay in stats fetch\n", nq->qdisc);
-
-		/*
-		 * Schedule the timer once again for re-trying. Since this is a
-		 * re-try we schedule it 100ms from now, instead of a whole second.
-		 */
-		nq->stats_get_timer.expires = jiffies + HZ/10;
-		add_timer(&nq->stats_get_timer);
-	}
-}
-
-/*
- * nss_qdisc_start_basic_stats_polling()
- *	Call to initiate the stats polling timer
- */
-void nss_qdisc_start_basic_stats_polling(struct nss_qdisc *nq)
-{
-	/*
-	 * In case the stats polling timer is already
-	 * initiated, return. This can happen only when
-	 * there is a fallback from PPE to NSS qdisc.
-	 */
-	if (atomic_read(&nq->pending_stat_requests)) {
-		return;
-	}
-
-	init_timer(&nq->stats_get_timer);
-	nq->stats_get_timer.function = nss_qdisc_get_stats_timer_callback;
-	nq->stats_get_timer.data = (unsigned long)nq;
-	nq->stats_get_timer.expires = jiffies + HZ;
-	atomic_set(&nq->pending_stat_requests, 1);
-	add_timer(&nq->stats_get_timer);
-}
-
-/*
- * nss_qdisc_stop_basic_stats_polling()
- *	Call to stop polling of basic stats
+ * nss_qdisc_init()
+ *	Initialize nss qdisc based on position of the qdisc
  */
-void nss_qdisc_stop_basic_stats_polling(struct nss_qdisc *nq)
+int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid,
+		uint32_t accel_mode, void *extack)
 {
-	/*
-	 * If the timer was active, then delete timer and return.
-	 */
-	if (del_timer(&nq->stats_get_timer) > 0) {
-		/*
-		 * The timer was still active (counting down) when it was deleted.
-		 * Therefore we are sure that there are no pending stats request
-		 * for which we need to wait for. We can therefore return.
-		 */
-		return;
-	}
-
-	/*
-	 * The timer has already fired, which means we have a pending stat response.
-	 * We will have to wait until we have received the pending response.
-	 */
-	if (!wait_event_timeout(nq->wait_queue, atomic_read(&nq->pending_stat_requests) == 0,
-				NSS_QDISC_COMMAND_TIMEOUT)) {
-		nss_qdisc_error("Stats request command for %x timedout!\n", nq->qos_tag);
-	}
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	return __nss_qdisc_init(sch, nq, type, classid, accel_mode);
+#else
+	return __nss_qdisc_init(sch, nq, type, classid, accel_mode, extack);
+#endif
 }
 
 /*
  * nss_qdisc_gnet_stats_copy_basic()
  *  Wrapper around gnet_stats_copy_basic()
  */
-int nss_qdisc_gnet_stats_copy_basic(struct gnet_dump *d,
+int nss_qdisc_gnet_stats_copy_basic(struct Qdisc *sch, struct gnet_dump *d,
 				struct gnet_stats_basic_packed *b)
 {
 #if (LINUX_VERSION_CODE <= KERNEL_VERSION(3, 18, 0))
 	return gnet_stats_copy_basic(d, b);
-#else
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return gnet_stats_copy_basic(d, NULL, b);
+#else
+	return gnet_stats_copy_basic(qdisc_root_sleeping_running(sch), d, NULL, b);
 #endif
 }
 
@@ -2533,10 +2651,8 @@ static int nss_qdisc_if_event_cb(struct
 
 	switch (event) {
 	case NETDEV_BR_JOIN:
-		nss_qdisc_info("Reveived NETDEV_BR_JOIN on interface %s\n",
-				dev->name);
 	case NETDEV_BR_LEAVE:
-		nss_qdisc_info("Reveived NETDEV_BR_LEAVE on interface %s\n",
+		nss_qdisc_info("Received NETDEV_BR_JOIN/NETDEV_BR_LEAVE on interface %s\n",
 				dev->name);
 		br = nss_qdisc_get_dev_master(dev);
 		if_num = nss_cmn_get_interface_number(nss_qdisc_ctx, dev);
@@ -2592,6 +2708,79 @@ static int nss_qdisc_if_event_cb(struct
 	return NOTIFY_DONE;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+/*
+ * nss_qdisc_tcf_chain()
+ *	Return the filter list of qdisc.
+ */
+struct tcf_proto __rcu **nss_qdisc_tcf_chain(struct Qdisc *sch, unsigned long arg)
+{
+	struct nss_qdisc *nq = qdisc_priv(sch);
+
+	/*
+	 * Currently filter addition is only supported over IFB interfaces.
+	 */
+	if (!nss_igs_verify_if_num(nq->nss_interface_number)) {
+		nss_qdisc_error("%d is not an ifb interface. Filter addition is only"
+				" supported for IFB interfaces.", nq->nss_interface_number);
+		return NULL;
+	}
+
+	/*
+	 * Currently, support is available only for tc filter iterations
+	 * at root qdisc.
+	 */
+	if (nq->is_root) {
+		return &(nq->filter_list);
+	}
+
+	return NULL;
+}
+#else
+/*
+ * nss_qdisc_tcf_block()
+ *	Return the block containing chain of qdisc.
+ */
+struct tcf_block *nss_qdisc_tcf_block(struct Qdisc *sch, unsigned long cl, struct netlink_ext_ack *extack)
+{
+	struct nss_qdisc *nq = qdisc_priv(sch);
+
+	/*
+	 * Currently, support is available only for tc filter iterations
+	 * at root qdisc.
+	 */
+	if (nq->is_root) {
+		return nq->block;
+	}
+
+	return NULL;
+}
+#endif
+
+/*
+ * nss_qdisc_tcf_bind()
+ *	Bind the filter to the qdisc.
+ *
+ * This is an empty callback, because, currently, tc filter iteration support
+ * is not present at class of a qdisc.
+ */
+unsigned long nss_qdisc_tcf_bind(struct Qdisc *sch, unsigned long parent, u32 classid)
+{
+	return (unsigned long)NULL;
+}
+
+/*
+ * nss_qdisc_tcf_unbind()
+ *	Unbind the filter from the qdisc.
+ *
+ * This is an empty callback, because, currently, tc filter iteration support
+ * is not present at class of a qdisc.
+ */
+void nss_qdisc_tcf_unbind(struct Qdisc *sch, unsigned long arg)
+{
+	return;
+}
+
 static struct notifier_block nss_qdisc_device_notifier = {
 		.notifier_call = nss_qdisc_if_event_cb };
 
@@ -2687,6 +2876,10 @@ static int __init nss_qdisc_module_init(
 		return ret;
 	nss_qdisc_info("nss qdisc device notifiers registered\n");
 
+	if (!nss_qdisc_stats_work_queue_init()) {
+		nss_qdisc_error("Failed to initialized stats workqueue thread\n");
+	}
+
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	nss_ppe_port_res_alloc();
 	nss_qdisc_info("nss ppe qdsic configured");
@@ -2706,6 +2899,8 @@ static void __exit nss_qdisc_module_exit
 	}
 #endif
 
+	nss_qdisc_stats_work_queue_exit();
+
 	unregister_qdisc(&nss_pfifo_qdisc_ops);
 	nss_qdisc_info("nsspfifo unregistered\n");
 
diff -uprN nss-clients-old/nss_qdisc/nss_qdisc.h nss-clients/nss_qdisc/nss_qdisc.h
--- nss-clients-old/nss_qdisc/nss_qdisc.h	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_qdisc.h	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2018 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2018, 2020-2021 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -20,6 +20,7 @@
 #include <linux/kernel.h>
 #include <linux/skbuff.h>
 #include <net/pkt_sched.h>
+#include <net/pkt_cls.h>
 #include <net/inet_ecn.h>
 #include <net/netfilter/nf_conntrack.h>
 #include <linux/if_bridge.h>
@@ -27,16 +28,24 @@
 #include <linux/version.h>
 #include <br_private.h>
 #include <nss_api_if.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+#include <linux/netlink.h>
+#endif
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 #include "nss_ppe.h"
 #endif
+#include "nss_qdisc_stats.h"
+#include "nss_qdisc_htable.h"
 
 #define NSS_QDISC_DEBUG_LEVEL_ERROR 1
 #define NSS_QDISC_DEBUG_LEVEL_WARN 2
 #define NSS_QDISC_DEBUG_LEVEL_INFO 3
 #define NSS_QDISC_DEBUG_LEVEL_TRACE 4
 
+#define NSS_QDISC_COMMAND_TIMEOUT (10*HZ) /* We set 10sec to be the command */
+					   /* timeout value for messages */
+
 /*
  * Debug message for module init and exit
  */
@@ -83,6 +92,9 @@
 #endif
 #endif
 
+#define NSS_QDISC_STATS_SYNC_MANY_PERIOD msecs_to_jiffies(1000)
+#define NSS_QDISC_STATS_SYNC_MANY_UDELAY 5000     /* Delay for 5 ms */
+
 /*
  * State values
  */
@@ -132,6 +144,27 @@ struct nss_qdisc;
 typedef void (*nss_qdisc_stats_callback_t)(struct nss_qdisc *nq, struct nss_shaper_node_stats_response *response);
 typedef void (*nss_qdisc_configure_callback_t)(struct nss_qdisc *nq, struct nss_shaper_configure *response);
 
+
+/*
+ * Qdisc stats sync info object
+ */
+struct nss_qdisc_stats_wq {
+	struct nss_qdisc *nq;			/* Pointer to root nss_qdisc */
+	struct list_head stats_list;		/* List head stats sync management work */
+	struct nss_if_msg stats_sync_req_msg;	/* FW sync message */
+	struct timer_list stats_get_timer;	/* Timer used to start fresh iter */
+	unsigned long int next_req_time;	/* Time at which next sync iteration starts */
+	unsigned long int stats_request_success;	/* Number of success stats request */
+	unsigned long int stats_request_fail;		/* Number of failed stats request */
+	unsigned long int stats_request_nack;		/* Number of NACK'd stats request */
+	atomic_t pending_stat_work;		/* Pending work queue status */
+	atomic_t pending_stat_resp;		/* Pending statistics response from FW */
+	bool stats_polling_stopped;		/* True when polling is stopped due to qdisc delete */
+	wait_queue_head_t stats_work_waitqueue;	/* Wait queue to wait on work queue processing */
+	wait_queue_head_t stats_resp_waitqueue;	/* Wait queue used to wait on response from the NSS */
+	struct nss_qdisc_htable nqt;		/* Struct to manage hash table of Qdiscs for stats */
+};
+
 struct nss_qdisc {
 	struct Qdisc *qdisc;			/* Handy pointer back to containing qdisc */
 	struct nss_qdisc *parent;		/* Pointer to parent nss qdisc */
@@ -145,6 +178,7 @@ struct nss_qdisc {
 						 * the NSS e.g. perhaps operating on a wifi interface
 						 * or bridge.
 						 */
+	bool needs_ppe_loopback;		/* True when qdisc is on bridge or igs */
 	bool destroy_virtual_interface;		/* Set if the interface is first registered in NSS by
 						 * us. This means it needs to be un-regisreted when the
 						 * module goes down.
@@ -185,9 +219,15 @@ struct nss_qdisc {
 						 */
 	struct gnet_stats_basic_packed bstats;	/* Basic class statistics */
 	struct gnet_stats_queue qstats;		/* Qstats for use by classes */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
 	atomic_t refcnt;			/* Reference count for class use */
+#else
+	refcount_t refcnt;			/* Reference count for class use */
+#endif
 	struct timer_list stats_get_timer;	/* Timer used to poll for stats */
 	atomic_t pending_stat_requests;		/* Number of pending stats responses */
+	struct nss_qdisc_stats_wq *stats_wq;	/* Stats info and state work object */
+	struct hlist_node hlist;		/* Hlist node for managing stats hash list */
 	wait_queue_head_t wait_queue;		/* Wait queue used to wait on responses from the NSS */
 	spinlock_t lock;			/* Lock to protect the nss qdisc structure */
 	uint16_t mode;				/* Mode of Qdisc/class */
@@ -199,6 +239,10 @@ struct nss_qdisc {
 						 * is attached to PPE qdisc in the tree.
 						 */
 #endif
+	struct tcf_proto __rcu *filter_list;	/* Filter list */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0))
+	struct tcf_block *block;
+#endif
 };
 
 /*
@@ -236,11 +280,81 @@ enum nss_qdisc_hybrid_mode {
 };
 
 /*
+ * nss_qdisc_nla_nest_start()
+ *	Returns the container attribute
+ */
+static inline struct nlattr * nss_qdisc_nla_nest_start(struct sk_buff *skb, int attrtype)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	return nla_nest_start(skb, TCA_OPTIONS);
+#else
+	return nla_nest_start_noflag(skb, TCA_OPTIONS);
+#endif
+}
+
+/*
+ * nss_qdisc_atomic_sub()
+ *	Atomically decrements the ref count by 1
+ */
+static inline void nss_qdisc_atomic_sub(struct nss_qdisc *nq)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	atomic_sub(1, &nq->refcnt);
+#else
+	atomic_sub(1, &nq->refcnt.refs);
+#endif
+}
+
+/*
+ * nss_qdisc_atomic_sub_return()
+ *	Atomically decrements the ref count by 1 and return ref count
+ */
+static inline int nss_qdisc_atomic_sub_return(struct nss_qdisc *nq)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	return atomic_sub_return(1, &nq->refcnt);
+#else
+	return atomic_sub_return(1, &nq->refcnt.refs);
+#endif
+}
+
+/*
+ * nss_qdisc_atomic_set()
+ *	Atomically sets the ref count by 1
+ */
+static inline void nss_qdisc_atomic_set(struct nss_qdisc *nq)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	atomic_set(&nq->refcnt, 1);
+#else
+	refcount_set(&nq->refcnt, 1);
+#endif
+}
+
+/*
+ * nss_qdisc_put()
+ *	Destroy the qdisc
+ */
+static inline void nss_qdisc_put(struct Qdisc *sch)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0))
+	qdisc_destroy(sch);
+#else
+	qdisc_put(sch);
+#endif
+}
+
+/*
  * nss_qdisc_qopt_get()
  *	Extracts qopt from opt.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 extern void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
-				uint32_t tca_max, uint32_t tca_params);
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params);
+#else
+extern void *nss_qdisc_qopt_get(struct nlattr *opt, struct nla_policy *policy,
+				struct nlattr *tb[], uint32_t tca_max, uint32_t tca_params, struct netlink_ext_ack *extack);
+#endif
 
 /*
  * nss_qdisc_mode_get()
@@ -254,11 +368,13 @@ extern uint8_t nss_qdisc_accel_mode_get(
  */
 extern struct sk_buff *nss_qdisc_peek(struct Qdisc *sch);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_qdisc_drop()
  *	Called to drop the packet at the head of queue
  */
 extern unsigned int nss_qdisc_drop(struct Qdisc *sch);
+#endif
 
 /*
  * nss_qdisc_reset()
@@ -270,7 +386,11 @@ extern void nss_qdisc_reset(struct Qdisc
  * nss_qdisc_enqueue()
  *	Generic enqueue call for enqueuing packets into NSS for shaping
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch);
+#else
+extern int nss_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free);
+#endif
 
 /*
  * nss_qdisc_dequeue()
@@ -336,26 +456,15 @@ extern void nss_qdisc_destroy(struct nss
  *	Initializes a shaper in NSS, based on the position of this qdisc (child or root)
  *	and if its a normal interface or a bridge interface.
  */
-extern int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode);
-
-/*
- * nss_qdisc_start_basic_stats_polling()
- *	Call to initiate the stats polling timer
- */
-extern void nss_qdisc_start_basic_stats_polling(struct nss_qdisc *nq);
-
-/*
- * nss_qdisc_stop_basic_stats_polling()
- *	Call to stop polling of basic stats
- */
-extern void nss_qdisc_stop_basic_stats_polling(struct nss_qdisc *nq);
+extern int nss_qdisc_init(struct Qdisc *sch, struct nss_qdisc *nq, nss_shaper_node_type_t type, uint32_t classid, uint32_t accel_mode,
+		void *extack);
 
 /*
  * nss_qdisc_gnet_stats_copy_basic()
  *  Wrapper around gnet_stats_copy_basic()
  */
-extern int nss_qdisc_gnet_stats_copy_basic(struct gnet_dump *d,
-				struct gnet_stats_basic_packed *b);
+extern int nss_qdisc_gnet_stats_copy_basic(struct Qdisc *sch,
+				struct gnet_dump *d, struct gnet_stats_basic_packed *b);
 
 /*
  * nss_qdisc_gnet_stats_copy_queue()
@@ -370,3 +479,41 @@ extern int nss_qdisc_gnet_stats_copy_que
  */
 extern struct Qdisc *nss_qdisc_replace(struct Qdisc *sch, struct Qdisc *new,
 					struct Qdisc **pold);
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+/*
+ * nss_qdisc_tcf_chain()
+ *	Return the filter list of qdisc.
+ */
+extern struct tcf_proto __rcu **nss_qdisc_tcf_chain(struct Qdisc *sch, unsigned long arg);
+#else
+/*
+ * nss_qdisc_tcf_block()
+ *	Return the block containing chain of qdisc.
+ */
+extern struct tcf_block *nss_qdisc_tcf_block(struct Qdisc *sch, unsigned long cl, struct netlink_ext_ack *extack);
+#endif
+
+/*
+ * nss_qdisc_tcf_bind()
+ *	Bind the filter to the qdisc.
+ */
+extern unsigned long nss_qdisc_tcf_bind(struct Qdisc *sch, unsigned long parent, u32 classid);
+
+/*
+ * nss_qdisc_tcf_unbind()
+ *	Unbind the filter from the qdisc.
+ */
+extern void nss_qdisc_tcf_unbind(struct Qdisc *sch, unsigned long arg);
+
+/*
+ * nss_qdisc_get_interface_msg()
+ *	Returns the correct message that needs to be sent down to the NSS interface.
+ */
+extern int nss_qdisc_get_interface_msg(bool is_bridge, uint32_t msg_type);
+
+/*
+ * nss_qdisc_msg_init()
+ *      Initialize the qdisc specific message
+ */
+extern void nss_qdisc_msg_init(struct nss_if_msg *nim, uint16_t if_num, uint32_t msg_type, uint32_t len, nss_if_msg_callback_t cb, void *app_data);
diff -uprN nss-clients-old/nss_qdisc/nss_qdisc_htable.c nss-clients/nss_qdisc/nss_qdisc_htable.c
--- nss-clients-old/nss_qdisc/nss_qdisc_htable.c	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/nss_qdisc_htable.c	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,239 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2021, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#include "nss_qdisc.h"
+
+/*
+ * Note: The table size 1024 ensures atleast page size memory is allocated for 32 bit binary.
+ */
+#define NSS_QDISC_LIST_TABLE_INIT_SIZE 1024
+
+/*
+ * nss_qdisc_htable_entry_compute_hash()
+ * 	Calculate hash for given qos_tag
+ */
+static inline uint32_t nss_qdisc_htable_entry_compute_hash(uint32_t qos_tag, uint32_t mask)
+{
+	/*
+	 * Since this list is for qdiscs and not classes the lower 16bits
+	 * are ignored for computing hash.
+	 */
+	return ((qos_tag >> 16) ^ (qos_tag >> 24)) & mask;
+}
+
+/*
+ * nss_qdisc_htable_entry_lookup()
+ * 	Get nss_qdisc corresponding to qos_tag from hash table
+ */
+struct nss_qdisc *nss_qdisc_htable_entry_lookup(struct nss_qdisc_htable *nqt, uint32_t qos_tag)
+{
+	struct nss_qdisc *nq;
+	uint32_t slot = nss_qdisc_htable_entry_compute_hash(qos_tag, nqt->htsize - 1);
+
+	spin_lock_bh(&nqt->lock);
+	hlist_for_each_entry(nq, &nqt->htable[slot], hlist) {
+		if (nq->qos_tag != qos_tag) {
+			continue;
+		}
+		spin_unlock_bh(&nqt->lock);
+		return nq;
+	}
+	spin_unlock_bh(&nqt->lock);
+	return NULL;
+}
+
+/*
+ * nss_qdisc_htable_entry_del()
+ * 	Del nss_qdisc from hash table
+ */
+void nss_qdisc_htable_entry_del(struct nss_qdisc_htable *nqt, struct nss_qdisc *nq)
+{
+	spin_lock_bh(&nqt->lock);
+	nqt->count--;
+	hlist_del(&nq->hlist);
+	spin_unlock_bh(&nqt->lock);
+}
+
+/*
+ * nss_qdisc_htable_entry_add()
+ * 	Add nss_qdisc to hash table
+ */
+void nss_qdisc_htable_entry_add(struct nss_qdisc_htable *nqt, struct nss_qdisc *nq)
+{
+	uint32_t hslot = nss_qdisc_htable_entry_compute_hash(nq->qos_tag, nqt->htsize - 1);
+	INIT_HLIST_NODE(&nq->hlist);
+
+	spin_lock_bh(&nqt->lock);
+	nqt->count++;
+	hlist_add_head(&nq->hlist, &nqt->htable[hslot]);
+	spin_unlock_bh(&nqt->lock);
+}
+
+/*
+ * nss_qdisc_htable_hlist_init()
+ * 	Initialize list head of each slot of allocated table
+ */
+static inline void nss_qdisc_htable_hlist_init(struct hlist_head *hlh, uint32_t size)
+{
+	/*
+	 * Initialize list head of each slot
+	 */
+	while (size) {
+		INIT_HLIST_HEAD(&hlh[--size]);
+	}
+}
+
+/*
+ * nss_qdisc_htable_alloc()
+ * 	Allocate hash table
+ */
+static struct hlist_head *nss_qdisc_htable_alloc(struct nss_qdisc_htable *nqt, uint32_t size)
+{
+	struct hlist_head *hlh;
+	uint32_t msize = size * sizeof(struct hlist_head);
+
+	hlh = (struct hlist_head *)__get_free_pages(GFP_KERNEL, get_order(msize));
+	if (!hlh) {
+		nss_qdisc_warning("%p: Qdisc list hash table memory allocation failed, size: %u\n", nqt, msize);
+		return NULL;
+	}
+
+	nqt->htsize = size;
+	nss_qdisc_info("%p: Qdisc list hash table memory allocation of size %u sucessful, for %u members\n", nqt, msize, size);
+
+	return hlh;
+}
+
+/*
+ * nss_qdisc_htable_free()
+ * 	Free hash table. The caller should take the lock on the table
+ */
+static void nss_qdisc_htable_free(struct nss_qdisc_htable *nqt, struct hlist_head *hlh, uint32_t size)
+{
+	uint32_t msize = size * sizeof(struct hlist_head);
+
+	if (!hlh) {
+		nss_qdisc_warning("%p: Freeing invalid memory \n", nqt);
+		return;
+	}
+
+	free_pages((unsigned long)hlh, get_order(msize));
+}
+
+/*
+ * nss_qdisc_htable_resize_needed()
+ *	Check if table needs resize
+ */
+static uint32_t nss_qdisc_htable_resize_needed(struct nss_qdisc_htable *nqt)
+{
+	/*
+	 * Check if we have our table almost full,
+	 * allocate a new htable if so.
+	 */
+	if (nqt->htsize * 4 > nqt->count * 5) {
+		return 0;
+	}
+
+	/*
+	 * Double the hash table size
+	 */
+	return nqt->htsize * 2;
+}
+
+/*
+ * nss_qdisc_htable_resize()
+ *	Check and grow the hash table size if needed
+ */
+void nss_qdisc_htable_resize(struct Qdisc *sch, struct nss_qdisc_htable *nqt)
+{
+	struct nss_qdisc *nq;
+	uint32_t prev_htsize, new_htsize, new_mask, new_slot;
+	uint32_t slot = prev_htsize = nqt->htsize;
+	struct hlist_head *hlh, *nhlh;
+	struct hlist_node *tmp;
+
+	new_htsize = nss_qdisc_htable_resize_needed(nqt);
+	if (!new_htsize) {
+		return;
+	}
+
+	hlh = nqt->htable;
+	nhlh = nss_qdisc_htable_alloc(nqt, new_htsize);
+	if (!nhlh) {
+		nss_qdisc_info("%p: nss_qdisc failed to allocate new htable for size %u\n", nqt, new_htsize);
+		return;
+	}
+
+	nss_qdisc_htable_hlist_init(nhlh, new_htsize);
+	new_mask = new_htsize - 1;
+	spin_lock_bh(&nqt->lock);
+	while (slot) {
+		/*
+		 * Populate new table
+		 */
+		hlist_for_each_entry_safe(nq, tmp, &hlh[--slot], hlist) {
+			new_slot = nss_qdisc_htable_entry_compute_hash(nq->qos_tag, new_mask);
+			hlist_add_head(&nq->hlist, &nhlh[new_slot]);
+		}
+	}
+
+	/*
+	 * Free the old table
+	 */
+	nss_qdisc_htable_free(nqt, hlh, prev_htsize);
+
+	/*
+	 * Attach the new table
+	 */
+	nqt->htable = nhlh;
+	spin_unlock_bh(&nqt->lock);
+}
+
+/*
+ * nss_qdisc_htable_init()
+ *	Allocate and initialise the hash table
+ */
+bool nss_qdisc_htable_init(struct nss_qdisc_htable *nqt)
+{
+	/*
+	 * Initialize table for eight qdisc nodes, it will grown if
+	 * needed as the number of nodes increase
+	 */
+	nqt->htable = nss_qdisc_htable_alloc(nqt, NSS_QDISC_LIST_TABLE_INIT_SIZE);
+	if (!nqt->htable) {
+		nss_qdisc_warning(" %p: nss_qdisc table init failed \n", nqt);
+		return false;
+	}
+
+	nqt->count = 0;
+	nss_qdisc_htable_hlist_init(nqt->htable, NSS_QDISC_LIST_TABLE_INIT_SIZE);
+	return true;
+}
+
+/*
+ * nss_qdisc_htable_dealloc()
+ *	Destroy the hash table. The entries in the hash table are
+ *	expected to be freed prior to this
+ */
+void nss_qdisc_htable_dealloc(struct nss_qdisc_htable *nqt)
+{
+	spin_lock_bh(&nqt->lock);
+	nss_qdisc_htable_free(nqt, nqt->htable, nqt->htsize);
+	spin_unlock_bh(&nqt->lock);
+}
+
diff -uprN nss-clients-old/nss_qdisc/nss_qdisc_htable.h nss-clients/nss_qdisc/nss_qdisc_htable.h
--- nss-clients-old/nss_qdisc/nss_qdisc_htable.h	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/nss_qdisc_htable.h	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,37 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2021, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+struct hlist_head;
+struct nss_qdisc;
+
+/*
+ * struct nss_qdisc_htable
+ */
+struct nss_qdisc_htable {
+	struct hlist_head *htable;
+	uint32_t count;
+	uint32_t htsize;
+	spinlock_t lock;
+};
+
+void nss_qdisc_htable_resize(struct Qdisc *sch, struct nss_qdisc_htable *nqt);
+bool nss_qdisc_htable_init(struct nss_qdisc_htable *nqt);
+void nss_qdisc_htable_dealloc(struct nss_qdisc_htable *nqt);
+void nss_qdisc_htable_entry_add(struct nss_qdisc_htable *nqt, struct nss_qdisc *nq);
+void nss_qdisc_htable_entry_del(struct nss_qdisc_htable *nqt, struct nss_qdisc *nq);
+struct nss_qdisc *nss_qdisc_htable_entry_lookup(struct nss_qdisc_htable *nqt, u32 qos_tag);
diff -uprN nss-clients-old/nss_qdisc/nss_qdisc_stats.c nss-clients/nss_qdisc/nss_qdisc_stats.c
--- nss-clients-old/nss_qdisc/nss_qdisc_stats.c	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/nss_qdisc_stats.c	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,687 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2021, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+
+#include "nss_qdisc.h"
+
+static LIST_HEAD(nss_qdisc_stats_list);			/* List of stats request nodes */
+static DEFINE_SPINLOCK(nss_qdisc_stats_list_lock);	/* Lock for the stats list */
+static struct workqueue_struct *nss_qdisc_stats_workqueue;
+static struct delayed_work nss_qdisc_stats_dwork;
+
+/*
+ * nss_qdisc_stats_queue_delayed_work()
+ *	Work function, adds stats struct to the stats work list, nq is a root node
+ */
+static inline void nss_qdisc_stats_queue_delayed_work(struct nss_qdisc *nq)
+{
+	struct nss_qdisc_stats_wq *nqsw = nq->stats_wq;
+	bool restart_work = false;
+
+	spin_lock_bh(&nss_qdisc_stats_list_lock);
+
+	/*
+	 * Stats message is processed
+	 */
+	atomic_sub(1, &nqsw->pending_stat_work);
+
+	/*
+	 * If this qdisc's stats polling is stopped don't enqueue to work
+	 */
+	if (nqsw->stats_polling_stopped) {
+		spin_unlock_bh(&nss_qdisc_stats_list_lock);
+		wake_up(&nqsw->stats_work_waitqueue);
+		return;
+	}
+
+	if (list_empty(&nss_qdisc_stats_list)) {
+		/*
+		 * The list is empty, so we need to restart the delayed work queue
+		 */
+		restart_work = true;
+	}
+
+	/*
+	 * Add the work for this root node to the tail of the queue
+	 */
+	list_add_tail(&nqsw->stats_list, &nss_qdisc_stats_list);
+	spin_unlock_bh(&nss_qdisc_stats_list_lock);
+
+	if (restart_work) {
+		queue_delayed_work(nss_qdisc_stats_workqueue, &nss_qdisc_stats_dwork, 0);
+	}
+
+	nss_qdisc_info("qdisc:%p nq:%p,queued work ", nq->qdisc, nq);
+}
+
+/*
+ * nss_qdisc_stats_sync_restart()
+ *	Invoked by timer to begin a new stats fetch
+ */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0))
+static void nss_qdisc_stats_sync_restart(unsigned long int data)
+#else
+static void nss_qdisc_stats_sync_restart(struct timer_list *tm)
+#endif
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0))
+	struct nss_qdisc *nq = (struct nss_qdisc *)data;
+#else
+	struct nss_qdisc_stats_wq *nqsw = from_timer(nqsw, tm, stats_get_timer);
+	struct nss_qdisc *nq = nqsw->nq;
+#endif
+
+	nss_qdisc_stats_queue_delayed_work(nq);
+}
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
+/*
+ * nss_qdisc_stats_put_class_nq()
+ *	Call to put class, followed by get class
+ */
+static inline void nss_qdisc_stats_put_class_nq(struct nss_qdisc *nq)
+{
+	const struct Qdisc_class_ops *clops;
+	clops = nq->qdisc->ops->cl_ops;
+	clops->put(nq->qdisc, (unsigned long)nq);
+}
+
+/*
+ * nss_qdisc_stats_get_class_nq()
+ *	Get struct nss_qdisc of corresponding class
+ */
+static inline struct nss_qdisc *nss_qdisc_stats_get_class_nq(struct nss_qdisc *nqp,
+		uint32_t classid)
+{
+
+	const struct Qdisc_class_ops *clops;
+	struct nss_qdisc *nq;
+	clops = nqp->qdisc->ops->cl_ops;
+	if (!clops) {
+		nss_qdisc_warning("Classid %u for unsupported qdisc %p\n", classid, nqp);
+		return NULL;
+	}
+
+	nq = (struct nss_qdisc *)clops->get(nqp->qdisc, classid);
+	if (!nq) {
+		nss_qdisc_info("Class %u not found for qdisc %p\n", classid, nqp);
+		return NULL;
+	}
+
+	return nq;
+}
+#else
+/*
+ * nss_qdisc_stats_find_class_nq()
+ *	Get struct nss_qdisc of corresponding class
+ */
+static inline struct nss_qdisc *nss_qdisc_stats_find_class_nq(struct nss_qdisc *nqp,
+		uint32_t classid)
+{
+
+	const struct Qdisc_class_ops *clops;
+	struct nss_qdisc *nq;
+	clops = nqp->qdisc->ops->cl_ops;
+	if (!clops) {
+		nss_qdisc_warning("Classid %u for unsupported qdisc %p\n", classid, nqp);
+		return NULL;
+	}
+
+	nq = (struct nss_qdisc *)clops->find(nqp->qdisc, classid);
+	if (!nq) {
+		nss_qdisc_info("Class %u not found for qdisc %p\n", classid, nqp);
+		return NULL;
+	}
+
+	return nq;
+}
+#endif
+
+/*
+ * nss_qdisc_stats_process_node_stats()
+ *	Look up the hash table for the Qdisc using the qos_tag and update the statistics
+ */
+static void nss_qdisc_stats_process_node_stats(struct nss_qdisc *nqr,
+		struct nss_shaper_node_stats_response *response)
+{
+	struct Qdisc *qdisc;
+	struct nss_qdisc *nq;
+	struct gnet_stats_basic_packed *bstats;
+	struct gnet_stats_queue *qstats;
+	uint32_t qos_tag = response->qos_tag;
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0))
+	atomic_t *refcnt;
+#else
+	refcount_t *refcnt;
+#endif
+	/*
+	 * Find the Qdisc for this qos_tag from the hash table
+	 */
+	nq = nss_qdisc_htable_entry_lookup(&nqr->stats_wq->nqt, TC_H_MAJ(qos_tag));
+	if (!nq) {
+		nss_qdisc_info("qdisc %p (qos_tag %x): node not found - \n", nq, qos_tag);
+		return;
+	}
+
+	qdisc = nq->qdisc;
+	if (TC_H_MIN(qos_tag)) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
+		nq = nss_qdisc_stats_get_class_nq(nq, qos_tag);
+#else
+		spinlock_t *root_lock = qdisc_lock(nqr->qdisc);
+		spin_lock(root_lock);
+		nq = nss_qdisc_stats_find_class_nq(nq, qos_tag);
+#endif
+		if (!nq) {
+			nss_qdisc_info("Qdisc %p (qos_tag %x): class node not found - \n", nq, qos_tag);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0))
+			spin_unlock(root_lock);
+#endif
+			return;
+		}
+	}
+
+	/*
+	 * Get the right stats pointers based on whether it is a class
+	 * or a qdisc.
+	 */
+	if (nq->is_class) {
+		bstats = &nq->bstats;
+		qstats = &nq->qstats;
+		refcnt = &nq->refcnt;
+	} else {
+		bstats = &qdisc->bstats;
+		qstats = &qdisc->qstats;
+		refcnt = &qdisc->refcnt;
+		qdisc->q.qlen = response->sn_stats.qlen_packets;
+	}
+
+	/*
+	 * Update qdisc->bstats
+	 */
+	spin_lock_bh(&nq->lock);
+	bstats->bytes += (__u64)response->sn_stats.delta.dequeued_bytes;
+	bstats->packets += response->sn_stats.delta.dequeued_packets;
+
+	/*
+	 * Update qdisc->qstats
+	 */
+	qstats->backlog = response->sn_stats.qlen_bytes;
+
+	qstats->drops += (response->sn_stats.delta.enqueued_packets_dropped +
+			response->sn_stats.delta.dequeued_packets_dropped);
+
+	/*
+	 * Update qdisc->qstats
+	 */
+	qstats->qlen = response->sn_stats.qlen_packets;
+	qstats->requeues = 0;
+	qstats->overlimits += response->sn_stats.delta.queue_overrun;
+	spin_unlock_bh(&nq->lock);
+
+	/*
+	 * Shapers that maintain additional unique statistics will process them
+	 * via a registered callback. So invoke if its been registered.
+	 * NOTE: Please ensure the callback donot take qdisc root_lock.
+	 */
+	if (nq->stats_cb) {
+		nq->stats_cb(nq, response);
+	}
+
+	if (TC_H_MIN(qos_tag)) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
+		nss_qdisc_stats_put_class_nq(nq);
+#else
+		spinlock_t *root_lock = qdisc_lock(nqr->qdisc);
+		spin_unlock(root_lock);
+#endif
+	}
+}
+
+/*
+ * nss_qdisc_stats_sync_many_callback()
+ *	Command response callback. Update the statistics using the hash table and
+ *	schedule the next delayed sync for this root node as necessary
+ */
+static void nss_qdisc_stats_sync_many_callback(void *app_data,
+		struct nss_if_msg *nim)
+{
+	struct nss_qdisc *nq = (struct nss_qdisc *)app_data;
+	struct nss_qdisc_stats_wq *nqsw = nq->stats_wq;
+	struct Qdisc *qdisc = nq->qdisc;
+	struct nss_shaper_node_stats_sync_many *nsnsm = &nim->msg.shaper_configure.config.msg.stats_get;
+	struct nss_shaper_node_stats_sync_many *nqsw_nsnsm = &nqsw->stats_sync_req_msg.msg.shaper_configure.config.msg.stats_get;
+	unsigned long int current_jiffies;
+	int i;
+
+	/*
+	 * FW stats response received
+	 */
+	atomic_set(&nqsw->pending_stat_resp, 0);
+	wake_up(&nqsw->stats_resp_waitqueue);
+
+	if (nim->cm.response == NSS_CMN_RESPONSE_ACK) {
+		for (i = 0; i < nsnsm->count; i++) {
+			nss_qdisc_stats_process_node_stats(nq, &nsnsm->stats_sync[i]);
+		}
+		nss_qdisc_info("%p, last_qos_tag :%x, update last_qos_tag:%x, count:%d \n", nq, nqsw_nsnsm->last_qos_tag, nsnsm->last_qos_tag, nsnsm->count);
+		nqsw_nsnsm->last_qos_tag = nsnsm->last_qos_tag;
+
+		/*
+		 * If stats sync for all nodes for this root node is done, we delay the next
+		 * sync by one second for this root node
+		 */
+		if (nqsw_nsnsm->last_qos_tag == 0) {
+			current_jiffies = jiffies;
+			if (time_after(nqsw->next_req_time, current_jiffies)) {
+				/*
+				 * If one second has not expired yet from the beginning of the
+				 * previous sync iteration for this root node, then program the
+				 * timer accordingly.
+				 */
+				nqsw->stats_get_timer.expires = jiffies + nqsw->next_req_time - current_jiffies;
+				add_timer(&nqsw->stats_get_timer);
+				nqsw->next_req_time += NSS_QDISC_STATS_SYNC_MANY_PERIOD;
+				nss_qdisc_info("qdisc:%p nq:%p,nqsw->next_req_time :%lu\n", nq->qdisc, nq, nqsw->next_req_time);
+				return;
+			}
+			/*
+			 * Program the timer for one second from now for the next sync iteration
+			 * for this root node
+			 */
+			nqsw->next_req_time = jiffies + NSS_QDISC_STATS_SYNC_MANY_PERIOD;
+			nss_qdisc_info("qdisc:%p nq:%p,nqsw->next_req_time :%lu\n", nq->qdisc, nq, nqsw->next_req_time);
+		}
+		/*
+		 * We have more nodes to sync stats for in this root node hierarchy. Continue
+		 * with the next sync with a 5 ms delay
+		 */
+		nss_qdisc_stats_queue_delayed_work(nq);
+		return;
+	}
+	/*
+	 * We get a NACK from FW, which should not happen, restart the request
+	 */
+	nss_qdisc_warning("Qdisc %px (type %d): Receive stats FAILED - "
+			"response: type: %d\n", qdisc, nq->type,
+			nim->msg.shaper_configure.config.response_type);
+	nqsw->stats_request_fail++;
+	nqsw_nsnsm->last_qos_tag = 0;
+	nss_qdisc_stats_queue_delayed_work(nq);
+}
+
+/*
+ * nss_qdisc_stats_sync_msg_tx()
+ *	Send the statistics sync request message to NSS. The command response handler
+ *	will schedule the next delayed work
+ */
+static void nss_qdisc_stats_sync_msg_tx(struct nss_qdisc_stats_wq *nqsw)
+{
+
+	struct nss_qdisc *nq = nqsw->nq;
+	struct nss_if_msg *nim = &nqsw->stats_sync_req_msg;
+
+	/*
+	 * Prepare a SYNC_MANY request
+	 */
+	struct nss_shaper_node_stats_sync_many *nsnsm = &nim->msg.shaper_configure.config.msg.stats_get;
+	nss_tx_status_t nss_tx_status;
+	int retry = 3;
+
+	while (retry) {
+		atomic_set(&nqsw->pending_stat_resp, 1);
+		nss_tx_status = nss_if_tx_msg_with_size(nq->nss_shaping_ctx, nim, PAGE_SIZE);
+		if (nss_tx_status != NSS_TX_SUCCESS) {
+			atomic_set(&nqsw->pending_stat_resp, 0);
+			nqsw->stats_request_fail++;
+			retry--;
+			nss_qdisc_info("TX_NOT_OKAY, try again later\n");
+			usleep_range(100, 200);
+			continue;
+		}
+
+		nqsw->stats_request_success++;
+
+		/*
+		 * Wait on this thread until response is received by fw.
+		 */
+		if (!wait_event_timeout(nqsw->stats_resp_waitqueue, atomic_read(&nqsw->pending_stat_resp) == 0,
+					NSS_QDISC_COMMAND_TIMEOUT)) {
+			nss_qdisc_error("Stats request command for %x timedout!\n", nq->qos_tag);
+		} else {
+
+			nss_qdisc_info("Qdisc %px nq:%p no more pending stat response  %d", nq->qdisc,
+					nq, atomic_read(&nqsw->pending_stat_resp));
+			return;
+		}
+	}
+
+	/*
+	 * TX failed after retries, reschedule ourselves with fresh start
+	 */
+	nsnsm->count = 0;
+	nsnsm->last_qos_tag = 0;
+	nss_qdisc_stats_queue_delayed_work(nq);
+}
+
+
+/*
+ * nss_qdisc_stats_sync_process_work()
+ *	Schedule delayed work to process connection stats and request next sync
+ */
+static void nss_qdisc_stats_sync_process_work(struct work_struct *work)
+{
+	struct nss_qdisc_stats_wq *nqsw;
+
+	/*
+	 * Delay the next sync request by the configured delay. This will help
+	 * to space the sync command requests to NSS and also ease the workload
+	 * on the CPU
+	 */
+	usleep_range(NSS_QDISC_STATS_SYNC_MANY_UDELAY - 100, NSS_QDISC_STATS_SYNC_MANY_UDELAY);
+
+	spin_lock_bh(&nss_qdisc_stats_list_lock);
+	if (list_empty(&nss_qdisc_stats_list)) {
+		spin_unlock_bh(&nss_qdisc_stats_list_lock);
+		return;
+	}
+	/*
+	 * Dequeue the work from the head of the list and process the statistics sync for it
+	 */
+	nqsw = list_first_entry(&nss_qdisc_stats_list, struct nss_qdisc_stats_wq, stats_list);
+	list_del(&nqsw->stats_list);
+	atomic_add(1, &nqsw->pending_stat_work);
+	spin_unlock_bh(&nss_qdisc_stats_list_lock);
+
+	nss_qdisc_stats_sync_msg_tx(nqsw);
+
+	/*
+	 * Schedule work again for processing next stats request
+	 */
+	queue_delayed_work(nss_qdisc_stats_workqueue, &nss_qdisc_stats_dwork, 0);
+}
+
+/*
+ * nss_qdisc_stats_work_queue_exit()
+ * 	Stop work and release the work queue thread
+ */
+void nss_qdisc_stats_work_queue_exit(void)
+{
+	cancel_delayed_work_sync(&nss_qdisc_stats_dwork);
+	destroy_workqueue(nss_qdisc_stats_workqueue);
+}
+
+/*
+ * nss_qdisc_stats_work_queue_init()
+ * 	Initialize the work queue resources
+ */
+bool nss_qdisc_stats_work_queue_init(void)
+{
+
+	nss_qdisc_stats_workqueue = create_singlethread_workqueue("nss_qdisc_stats_workqueue");
+	if (!nss_qdisc_stats_workqueue) {
+		return false;
+	}
+
+	INIT_DELAYED_WORK(&nss_qdisc_stats_dwork, nss_qdisc_stats_sync_process_work);
+	nss_qdisc_info("nss_qdisc_stats_workqueue thread created :%p", nss_qdisc_stats_workqueue);
+
+	return true;
+}
+
+/*
+ * nss_qdisc_stats_sync_many_exit()
+ * 	Stop and cleanup the stats sync framework for this root node
+ */
+void nss_qdisc_stats_sync_many_exit(struct nss_qdisc *nq)
+{
+	struct nss_qdisc_stats_wq *nqsw = nq->stats_wq;
+	struct nss_qdisc_stats_wq *cursor, *next;
+
+	spin_lock_bh(&nss_qdisc_stats_list_lock);
+
+	/*
+	 * Stop further queuing to work function
+	 */
+	nqsw->stats_polling_stopped = true;
+
+	/*
+	 * if list is already empty then stats sync message may be in progress,
+	 * wait for pending stats processing.
+	 */
+	if (list_empty(&nss_qdisc_stats_list)) {
+		spin_unlock_bh(&nss_qdisc_stats_list_lock);
+		nss_qdisc_info("Qdisc %px nq:%p list is empty", nq->qdisc, nq);
+		goto cleanup;
+	}
+
+	/*
+	 * Check if stats sync for this root node is queued in the list. If so,
+	 * remove it from the list.
+	 */
+	list_for_each_entry_safe(cursor, next, &nss_qdisc_stats_list, stats_list) {
+		if (nqsw == cursor) {
+			list_del(&nqsw->stats_list);
+			spin_unlock_bh(&nss_qdisc_stats_list_lock);
+			nss_qdisc_info("Qdisc %px nq:%p found work queue %p", nq->qdisc, nq, nqsw);
+			goto free_mem;
+		}
+	}
+
+	spin_unlock_bh(&nss_qdisc_stats_list_lock);
+
+	/*
+	 * The timer has already fired, which means we have a pending stat response.
+	 * We will have to wait until we have received the pending response.
+	 */
+cleanup:
+	if (del_timer(&nqsw->stats_get_timer) > 0) {
+		/*
+		 * The timer was still active (counting down) when it was deleted.
+		 * Therefore we are sure that there are no pending stats request
+		 * for which we need to wait for. We can therefore return.
+		 */
+		goto free_mem;
+	}
+
+	nss_qdisc_info("Qdisc %px nq:%p waiting for nqsw->pending_stat_work to be zero %d", nq->qdisc, nq, atomic_read(&nqsw->pending_stat_work));
+
+	/*
+	 * A sync is in progress. Make sure we wait for the completion before cleaning
+	 * up the stats sync framework
+	 */
+	if (!wait_event_timeout(nqsw->stats_work_waitqueue, atomic_read(&nqsw->pending_stat_work) == 0,
+				NSS_QDISC_COMMAND_TIMEOUT)) {
+		nss_qdisc_error("Stats request command for %x timedout!\n", nq->qos_tag);
+	}
+
+	nss_qdisc_info("Qdisc %px nq:%p no more pending_stat_work  %d", nq->qdisc, nq, atomic_read(&nqsw->pending_stat_work));
+
+free_mem:
+	/*
+	 * Free the qdisc stats hash table for this root node
+	 */
+	nss_qdisc_htable_dealloc(&nqsw->nqt);
+	nq->stats_wq = NULL;
+	kfree(nqsw);
+}
+
+/*
+ * nss_qdisc_stats_sync_many_init()
+ * 	Initialize stats sync framework for this root node
+ */
+bool nss_qdisc_stats_sync_many_init(struct nss_qdisc *nq)
+{
+	struct nss_shaper_node_stats_sync_many *nsnsm = NULL;
+	struct nss_if_msg *nim = NULL;
+	struct nss_qdisc_stats_wq *nqsw = NULL;
+	int msg_type;
+
+	nqsw = kzalloc(sizeof(struct nss_qdisc_stats_wq), GFP_KERNEL);
+	if (!nqsw) {
+		nss_qdisc_error("%p Failed to allocate mem for stats struct nss_qdisc_stats_wq \n", nq);
+		return false;
+	}
+
+	/*
+	 * Allocate the memory for the hash table for the qdisc stats. The hash table helps to
+	 * optimize the look up time based on qos_tag during statistics update
+	 */
+	if (!nss_qdisc_htable_init(&nqsw->nqt)) {
+		nss_qdisc_error("%p Failed to allocate mem for stats hash \n", nq);
+		kfree(nqsw);
+		return false;
+	}
+	nq->stats_wq = nqsw;
+	nqsw->nq = nq;
+	init_waitqueue_head(&nqsw->stats_work_waitqueue);
+	init_waitqueue_head(&nqsw->stats_resp_waitqueue);
+
+	/*
+	 * Create the shaper configure message to the NSS interface
+	 */
+	nim = &nqsw->stats_sync_req_msg;
+	msg_type = nss_qdisc_get_interface_msg(nq->is_bridge, NSS_QDISC_IF_SHAPER_CONFIG);
+	nss_qdisc_msg_init(nim, nq->nss_interface_number, msg_type, sizeof(struct nss_if_shaper_configure),
+			nss_qdisc_stats_sync_many_callback,
+			nq);
+	nim->msg.shaper_configure.config.request_type = NSS_SHAPER_CONFIG_TYPE_SHAPER_NODE_STATS_SYNC_MANY;
+
+	nsnsm = &nim->msg.shaper_configure.config.msg.stats_get;
+
+	/*
+	 * Start with last_qos_tag 0
+	 */
+	nsnsm->last_qos_tag = 0;
+	nsnsm->size = PAGE_SIZE;
+
+	/*
+	 * Initialize the timer that restarts the polling loop
+	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0))
+	init_timer(&nqsw->stats_get_timer);
+	nqsw->stats_get_timer.function = nss_qdisc_stats_sync_restart;
+	nqsw->stats_get_timer.data = (unsigned long)nq;
+#else
+	timer_setup(&nqsw->stats_get_timer, nss_qdisc_stats_sync_restart, 0);
+#endif
+
+	nss_qdisc_info("Qdisc %px stats sync message initialized for nq:%p", nq->qdisc, nq);
+	return true;
+}
+
+/*
+ * nss_qdisc_stats_stop_polling()
+ *	Stop polling on the root node
+ */
+void nss_qdisc_stats_stop_polling(struct nss_qdisc *nq)
+{
+	nss_qdisc_assert(nq->is_root, "Stats polling stop request received on non-root qdisc:%p with qos_tag%x", nq, nq->qos_tag);
+
+	nss_qdisc_stats_sync_many_exit(nq);
+	nss_qdisc_info(" %p stopped delayed work queue for root %x\n", nq, nq->qos_tag);
+}
+
+/*
+ * nss_qdisc_stats_start_polling()
+ *	Initiate polling on root node
+ */
+void nss_qdisc_stats_start_polling(struct nss_qdisc *nq)
+{
+	nss_qdisc_assert(nq->is_root, "Stats polling started on non-root qdisc:%p with qos_tag%x", nq, nq->qos_tag);
+
+	atomic_set(&nq->stats_wq->pending_stat_work, 1);
+	nss_qdisc_stats_queue_delayed_work(nq);
+	nss_qdisc_info("%p Started delayed work queue for root %x\n", nq, nq->qos_tag);
+}
+
+/*
+ * nss_qdisc_stats_get_root_qdisc()
+ *	Get root scheduler
+ */
+static inline struct Qdisc *nss_qdisc_stats_get_root_qdisc(struct nss_qdisc *nq)
+{
+	return nq->is_root ? nq->qdisc : qdisc_dev(nq->qdisc)->qdisc;
+}
+
+/*
+ * nss_qdisc_stats_qdisc_attach()
+ *	Attach node to qdisc stats hash table in the root node
+ */
+void nss_qdisc_stats_qdisc_attach(struct nss_qdisc *nq)
+{
+	struct Qdisc *rqdisc;
+	struct nss_qdisc *rnq;
+
+	if (nq->is_class) {
+		/* List is needed only for qdiscs and not classes,
+		 * kernel already has list of classes of given parent.
+		 */
+		return;
+	}
+
+	/*
+	 * Get root qdisc of this hierarchy, and get the stats management struct
+	 */
+	rqdisc = nss_qdisc_stats_get_root_qdisc(nq);
+	if (!rqdisc) {
+		nss_qdisc_warning("Root qdisc not found for nq:%p with qos_tag:%x\n", nq, nq->qos_tag);
+		return;
+	}
+
+	rnq = qdisc_priv(rqdisc);
+	if (!rnq || !rnq->stats_wq) {
+		nss_qdisc_warning(" Error, stats wq should be initialized by now for root qdisc:%x\n", rnq?rnq->qos_tag:0);
+		return;
+	}
+
+	nss_qdisc_htable_entry_add(&rnq->stats_wq->nqt, nq);
+
+	/*
+	 * Resize the hash table if needed
+	 */
+	nss_qdisc_htable_resize(rqdisc, &rnq->stats_wq->nqt);
+}
+
+/*
+ * nss_qdisc_stats_qdisc_detach()
+ *	Detach node from qdisc stats hash table in the root node
+ */
+void nss_qdisc_stats_qdisc_detach(struct nss_qdisc *nq)
+{
+	struct Qdisc *rqdisc;
+	struct nss_qdisc *rnq;
+
+	if (nq->is_class) {
+		return;
+	}
+
+	rqdisc = nss_qdisc_stats_get_root_qdisc(nq);
+	if (!rqdisc) {
+		nss_qdisc_warning("Root qdisc not found for nq:%p with qos_tag:%x\n", nq, nq->qos_tag);
+		return;
+	}
+
+	rnq = qdisc_priv(rqdisc);
+	if (!rnq || !rnq->stats_wq) {
+		nss_qdisc_warning(" Error, stats wq should be initialized by now for root qdisc:%x\n", rnq?rnq->qos_tag:0);
+		return;
+	}
+
+	nss_qdisc_htable_entry_del(&rnq->stats_wq->nqt, nq);
+}
+
diff -uprN nss-clients-old/nss_qdisc/nss_qdisc_stats.h nss-clients/nss_qdisc/nss_qdisc_stats.h
--- nss-clients-old/nss_qdisc/nss_qdisc_stats.h	1970-01-01 09:00:00.000000000 +0900
+++ nss-clients/nss_qdisc/nss_qdisc_stats.h	2022-09-03 10:42:47.580000000 +0900
@@ -0,0 +1,28 @@
+/*
+ **************************************************************************
+ * Copyright (c) 2021, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ **************************************************************************
+ */
+struct nss_qdisc;
+struct nss_qdisc_stats_wq;
+
+void nss_qdisc_stats_work_queue_exit(void);
+bool nss_qdisc_stats_work_queue_init(void);
+void nss_qdisc_stats_sync_many_exit(struct nss_qdisc *nq);
+bool nss_qdisc_stats_sync_many_init(struct nss_qdisc *nq);
+void nss_qdisc_stats_stop_polling(struct nss_qdisc *nq);
+void nss_qdisc_stats_start_polling(struct nss_qdisc *nq);
+void nss_qdisc_stats_qdisc_detach(struct nss_qdisc *nq);
+void nss_qdisc_stats_qdisc_attach(struct nss_qdisc *nq);
diff -uprN nss-clients-old/nss_qdisc/nss_tbl.c nss-clients/nss_qdisc/nss_tbl.c
--- nss-clients-old/nss_qdisc/nss_tbl.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_tbl.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2017 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2017, 2019-2021, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -29,9 +29,18 @@ static struct nla_policy nss_tbl_policy[
 	[TCA_NSSTBL_PARMS] = { .len = sizeof(struct tc_nsstbl_qopt) },
 };
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_tbl_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_tbl_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 static struct sk_buff *nss_tbl_dequeue(struct Qdisc *sch)
@@ -39,10 +48,12 @@ static struct sk_buff *nss_tbl_dequeue(s
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static unsigned int nss_tbl_drop(struct Qdisc *sch)
 {
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 static struct sk_buff *nss_tbl_peek(struct Qdisc *sch)
 {
@@ -77,17 +88,16 @@ static void nss_tbl_destroy(struct Qdisc
 	/*
 	 * Now we can destroy our child qdisc
 	 */
-	qdisc_destroy(q->qdisc);
-
-	/*
-	 * Stop the polling of basic stats and destroy qdisc.
-	 */
-	nss_qdisc_stop_basic_stats_polling(&q->nq);
+	nss_qdisc_put(q->qdisc);
 	nss_qdisc_destroy(&q->nq);
 }
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_ppe_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_tbl_ppe_change(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
@@ -123,8 +133,12 @@ fail:
 	/*
 	 * PPE qdisc config failed, try to initialize in NSS.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_ppe_fallback_to_nss(nq, opt)) {
-		nss_qdisc_warning("nss_tbl %x fallback to nss failed\n", sch->handle);
+#else
+	if (nss_ppe_fallback_to_nss(nq, opt, extack)) {
+#endif
+	nss_qdisc_warning("nss_tbl %x fallback to nss failed\n", sch->handle);
 		return -EINVAL;
 	}
 
@@ -132,9 +146,15 @@ fail:
 }
 #endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_tbl_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSTBL_MAX + 1];
 	struct tc_nsstbl_qopt *qopt;
 	struct nss_if_msg nim;
 	struct net_device *dev = qdisc_dev(sch);
@@ -143,7 +163,11 @@ static int nss_tbl_change(struct Qdisc *
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -178,7 +202,11 @@ static int nss_tbl_change(struct Qdisc *
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (q->nq.mode == NSS_QDISC_MODE_PPE) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 		if (nss_tbl_ppe_change(sch, opt) < 0) {
+#else
+		if (nss_tbl_ppe_change(sch, opt, extack) < 0) {
+#endif
 			nss_qdisc_warning("nss_tbl %x SSDK scheduler config failed\n", sch->handle);
 			return -EINVAL;
 		}
@@ -216,9 +244,17 @@ static int nss_tbl_change(struct Qdisc *
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_tbl_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSTBL_MAX + 1];
 	struct tc_nsstbl_qopt *qopt;
 
 	if (!opt) {
@@ -227,25 +263,30 @@ static int nss_tbl_init(struct Qdisc *sc
 
 	q->qdisc = &noop_qdisc;
 
-	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_tbl_policy, tb, TCA_NSSTBL_MAX, TCA_NSSTBL_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
 
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_TBL, 0, qopt->accel_mode) < 0)
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_TBL, 0, qopt->accel_mode, extack) < 0)
+	{
 		return -EINVAL;
+	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_tbl_change(sch, opt) < 0) {
+#else
+	if (nss_tbl_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_info("Failed to configure tbl\n");
 		nss_qdisc_destroy(&q->nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(&q->nq);
-
 	return 0;
 }
 
@@ -262,7 +303,8 @@ static int nss_tbl_dump(struct Qdisc *sc
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
 	nss_qdisc_info("Nsstbl dumping");
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSTBL_PARMS, sizeof(opt), &opt)) {
 		goto nla_put_failure;
 	}
@@ -286,8 +328,13 @@ static int nss_tbl_dump_class(struct Qdi
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_tbl_graft(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
 			struct Qdisc **old)
+#else
+static int nss_tbl_graft(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
+			struct Qdisc **old, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_tbl_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq_new = (struct nss_qdisc *)qdisc_priv(new);
@@ -301,10 +348,10 @@ static int nss_tbl_graft(struct Qdisc *s
 	*old = q->qdisc;
 	sch_tree_unlock(sch);
 
-	nss_qdisc_info("Grafting old: %p with new: %p\n", *old, new);
+	nss_qdisc_info("Grafting old: %px with new: %px\n", *old, new);
 	if (*old != &noop_qdisc) {
 		struct nss_qdisc *nq_old = (struct nss_qdisc *)qdisc_priv(*old);
-		nss_qdisc_info("Detaching old: %p\n", *old);
+		nss_qdisc_info("Detaching old: %px\n", *old);
 		nim_detach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = q->nq.qos_tag;
 		if (nss_qdisc_node_detach(&q->nq, nq_old, &nim_detach,
 				NSS_SHAPER_CONFIG_TYPE_SHAPER_NODE_DETACH) < 0) {
@@ -313,7 +360,7 @@ static int nss_tbl_graft(struct Qdisc *s
 	}
 
 	if (new != &noop_qdisc) {
-		nss_qdisc_info("Attaching new: %p\n", new);
+		nss_qdisc_info("Attaching new: %px\n", new);
 		nim_attach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = q->nq.qos_tag;
 		nim_attach.msg.shaper_configure.config.msg.shaper_node_config.snc.tbl_attach.child_qos_tag = nq_new->qos_tag;
 		if (nss_qdisc_node_attach(&q->nq, nq_new, &nim_attach,
@@ -339,6 +386,7 @@ static struct Qdisc *nss_tbl_leaf(struct
 	return q->qdisc;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 static unsigned long nss_tbl_get(struct Qdisc *sch, u32 classid)
 {
 	return 1;
@@ -347,6 +395,12 @@ static unsigned long nss_tbl_get(struct
 static void nss_tbl_put(struct Qdisc *sch, unsigned long arg)
 {
 }
+#else
+static unsigned long nss_tbl_search(struct Qdisc *sch, u32 classid)
+{
+	return 1;
+}
+#endif
 
 static void nss_tbl_walk(struct Qdisc *sch, struct qdisc_walker *walker)
 {
@@ -364,8 +418,19 @@ static void nss_tbl_walk(struct Qdisc *s
 const struct Qdisc_class_ops nss_tbl_class_ops = {
 	.graft		=	nss_tbl_graft,
 	.leaf		=	nss_tbl_leaf,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		=	nss_tbl_get,
 	.put		=	nss_tbl_put,
+#else
+	.find       =   nss_tbl_search,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.tcf_chain	=	nss_qdisc_tcf_chain,
+#else
+	.tcf_block	=	nss_qdisc_tcf_block,
+#endif
+	.bind_tcf	=	nss_qdisc_tcf_bind,
+	.unbind_tcf	=	nss_qdisc_tcf_unbind,
 	.walk		=	nss_tbl_walk,
 	.dump		=	nss_tbl_dump_class,
 };
@@ -378,7 +443,9 @@ struct Qdisc_ops nss_tbl_qdisc_ops __rea
 	.enqueue	=	nss_tbl_enqueue,
 	.dequeue	=	nss_tbl_dequeue,
 	.peek		=	nss_tbl_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_tbl_drop,
+#endif
 	.init		=	nss_tbl_init,
 	.reset		=	nss_tbl_reset,
 	.destroy	=	nss_tbl_destroy,
@@ -386,4 +453,3 @@ struct Qdisc_ops nss_tbl_qdisc_ops __rea
 	.dump		=	nss_tbl_dump,
 	.owner		=	THIS_MODULE,
 };
-
diff -uprN nss-clients-old/nss_qdisc/nss_wred.c nss-clients/nss_qdisc/nss_wred.c
--- nss-clients-old/nss_qdisc/nss_wred.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_wred.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2017 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2017, 2020-2021 The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -55,9 +55,18 @@ static struct nla_policy nss_wred_policy
  * nss_wred_enqueue()
  *	Enqueue API for nsswred qdisc
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_wred_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_wred_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 /*
@@ -69,6 +78,7 @@ static struct sk_buff *nss_wred_dequeue(
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 /*
  * nss_wred_drop()
  *	Drops a packet from HLOS queue.
@@ -78,6 +88,7 @@ static unsigned int nss_wred_drop(struct
 	nss_qdisc_info("nsswred dropping");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 /*
  * nss_wred_reset()
@@ -97,11 +108,6 @@ static void nss_wred_destroy(struct Qdis
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)qdisc_priv(sch);
 
-	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(nq);
-
 	nss_qdisc_destroy(nq);
 	nss_qdisc_info("nsswred destroyed");
 }
@@ -111,7 +117,11 @@ static void nss_wred_destroy(struct Qdis
  * nss_wred_ppe_change()
  *	Function call to configure the nssred parameters for ppe qdisc.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wred_ppe_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_wred_ppe_change(struct Qdisc *sch, struct nlattr *opt, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_wred_sched_data *q = qdisc_priv(sch);
 	struct nss_qdisc *nq = &q->nq;
@@ -159,8 +169,12 @@ fail:
 	/*
 	 * Fallback to nss qdisc if PPE Qdisc configuration failed at init time.
 	 */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_ppe_fallback_to_nss(&q->nq, opt) < 0) {
-		nss_qdisc_warning("nss_wred %x fallback to nss failed\n", sch->handle);
+#else
+	if (nss_ppe_fallback_to_nss(&q->nq, opt, extack) < 0) {
+#endif
+	nss_qdisc_warning("nss_wred %x fallback to nss failed\n", sch->handle);
 		return -EINVAL;
 	}
 	return 0;
@@ -171,9 +185,15 @@ fail:
  * nss_wred_change()
  *	Function call to configure the nsswred parameters
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wred_change(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_wred_change(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_wred_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSWRED_MAX + 1];
 	struct tc_nsswred_qopt *qopt;
 	struct nss_if_msg nim;
 
@@ -181,7 +201,11 @@ static int nss_wred_change(struct Qdisc
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -253,8 +277,12 @@ static int nss_wred_change(struct Qdisc
 
 #if defined(NSS_QDISC_PPE_SUPPORT)
 	if (q->nq.mode == NSS_QDISC_MODE_PPE) {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 		if (nss_wred_ppe_change(sch, opt) < 0) {
-			nss_qdisc_warning("nss_wred %p params validate and save failed\n", sch);
+#else
+		if (nss_wred_ppe_change(sch, opt, extack) < 0) {
+#endif
+			nss_qdisc_warning("nss_wred %px params validate and save failed\n", sch);
 			return -EINVAL;
 		}
 		return 0;
@@ -298,16 +326,28 @@ static int nss_wred_change(struct Qdisc
  * nss_wred_init()
  *	Init the nsswred qdisc
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wred_init(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_wred_init(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_qdisc *nq = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSWRED_MAX + 1];
 	struct tc_nsswred_qopt *qopt;
 
 	if (opt == NULL) {
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wred_policy, tb, TCA_NSSWRED_MAX, TCA_NSSWRED_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -315,20 +355,21 @@ static int nss_wred_init(struct Qdisc *s
 	nss_qdisc_info("Initializing Wred - type %d\n", NSS_SHAPER_NODE_TYPE_WRED);
 	nss_wred_reset(sch);
 
-	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_WRED, 0, qopt->accel_mode) < 0)
+	if (nss_qdisc_init(sch, nq, NSS_SHAPER_NODE_TYPE_WRED, 0, qopt->accel_mode, extack) < 0)
+	{
 		return -EINVAL;
+	}
 
 	nss_qdisc_info("NSS wred initialized - handle %x parent %x\n", sch->handle, sch->parent);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_wred_change(sch, opt) < 0) {
+#else
+	if (nss_wred_change(sch, opt, extack) < 0) {
+#endif
 		nss_qdisc_destroy(nq);
 		return -EINVAL;
 	}
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(nq);
-
 	return 0;
 }
 
@@ -374,7 +415,7 @@ static int nss_wred_dump(struct Qdisc *s
 	opt.set_default = q->set_default;
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSWRED_PARMS, sizeof(opt), &opt)) {
 		goto nla_put_failure;
 	}
@@ -405,7 +446,9 @@ struct Qdisc_ops nss_red_qdisc_ops __rea
 	.enqueue	=	nss_wred_enqueue,
 	.dequeue	=	nss_wred_dequeue,
 	.peek		=	nss_wred_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_wred_drop,
+#endif
 	.init		=	nss_wred_init,
 	.reset		=	nss_wred_reset,
 	.destroy	=	nss_wred_destroy,
@@ -423,7 +466,9 @@ struct Qdisc_ops nss_wred_qdisc_ops __re
 	.enqueue	=	nss_wred_enqueue,
 	.dequeue	=	nss_wred_dequeue,
 	.peek		=	nss_wred_peek,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		=	nss_wred_drop,
+#endif
 	.init		=	nss_wred_init,
 	.reset		=	nss_wred_reset,
 	.destroy	=	nss_wred_destroy,
diff -uprN nss-clients-old/nss_qdisc/nss_wrr.c nss-clients/nss_qdisc/nss_wrr.c
--- nss-clients-old/nss_qdisc/nss_wrr.c	2019-08-28 07:51:13.000000000 +0900
+++ nss-clients/nss_qdisc/nss_wrr.c	2022-09-03 10:42:47.580000000 +0900
@@ -1,6 +1,6 @@
 /*
  **************************************************************************
- * Copyright (c) 2014-2017 The Linux Foundation. All rights reserved.
+ * Copyright (c) 2014-2017, 2019-2021, The Linux Foundation. All rights reserved.
  * Permission to use, copy, modify, and/or distribute this software for
  * any purpose with or without fee is hereby granted, provided that the
  * above copyright notice and this permission notice appear in all copies.
@@ -42,7 +42,7 @@ static inline struct nss_wrr_class_data
 	struct Qdisc_class_common *clc;
 	clc = qdisc_class_find(&q->clhash, classid);
 	if (clc == NULL) {
-		nss_qdisc_info("Cannot find class with classid %u in qdisc %p hash table %p\n", classid, sch, &q->clhash);
+		nss_qdisc_info("Cannot find class with classid %u in qdisc %px hash table %px\n", classid, sch, &q->clhash);
 		return NULL;
 	}
 	return container_of(clc, struct nss_wrr_class_data, cl_common);
@@ -53,7 +53,7 @@ static void nss_wrr_destroy_class(struct
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
 	struct nss_if_msg nim;
 
-	nss_qdisc_info("Destroying nss_wrr class %p from qdisc %p\n", cl, sch);
+	nss_qdisc_info("Destroying nss_wrr class %px from qdisc %px\n", cl, sch);
 
 	/*
 	 * Note, this function gets called even for NSSWRR and not just for NSSWRR_GROUP.
@@ -62,8 +62,8 @@ static void nss_wrr_destroy_class(struct
 	 * only for the root qdisc.
 	 */
 	if (cl == &q->root) {
-		nss_qdisc_info("We do not destroy nss_wrr class %p here since this is "
-				"the qdisc %p\n", cl, sch);
+		nss_qdisc_info("We do not destroy nss_wrr class %px here since this is "
+				"the qdisc %px\n", cl, sch);
 		return;
 	}
 
@@ -84,12 +84,7 @@ static void nss_wrr_destroy_class(struct
 	/*
 	 * And now we destroy the child.
 	 */
-	qdisc_destroy(cl->qdisc);
-
-	/*
-	 * Stop the stats polling timer and free class
-	 */
-	nss_qdisc_stop_basic_stats_polling(&cl->nq);
+	 nss_qdisc_put(cl->qdisc);
 
 	/*
 	 * Destroy the shaper in NSS
@@ -106,9 +101,15 @@ static void nss_wrr_destroy_class(struct
  * nss_wrr_class_params_validate_and_save()
  *	Validates and saves the class configuration parameters.
  */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
 					uint32_t *quantum)
+#else
+static int nss_wrr_class_params_validate_and_save(struct Qdisc *sch, struct nlattr **tca,
+					uint32_t *quantum, struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSWRR_MAX + 1];
 	struct nlattr *opt = tca[TCA_OPTIONS];
 	struct tc_nsswrr_class_qopt *qopt;
 	struct net_device *dev = qdisc_dev(sch);
@@ -123,7 +124,11 @@ static int nss_wrr_class_params_validate
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, TCA_NSSWRR_MAX, TCA_NSSWRR_CLASS_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_CLASS_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_CLASS_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -218,9 +223,16 @@ static int nss_wrr_ppe_change_class(stru
 }
 #endif
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
 		  struct nlattr **tca, unsigned long *arg)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_wrr_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
+		  struct nlattr **tca, unsigned long *arg, struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)*arg;
 	struct nss_if_msg nim_config;
@@ -230,7 +242,11 @@ static int nss_wrr_change_class(struct Q
 
 	nss_qdisc_info("Changing nss_wrr class %u\n", classid);
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 	if (nss_wrr_class_params_validate_and_save(sch, tca, &quantum) < 0) {
+#else
+	if (nss_wrr_class_params_validate_and_save(sch, tca, &quantum, extack) < 0) {
+#endif
 		nss_qdisc_warning("validation of configuration parameters for wrr class %x failed\n",
 					sch->handle);
 		return -EINVAL;
@@ -266,7 +282,7 @@ static int nss_wrr_change_class(struct Q
 			return -EINVAL;
 		}
 
-		nss_qdisc_info("NSS_wrr class %u allocated %p\n", classid, cl);
+		nss_qdisc_info("NSS_wrr class %u allocated %px\n", classid, cl);
 		cl->cl_common.classid = classid;
 
 		/*
@@ -275,10 +291,10 @@ static int nss_wrr_change_class(struct Q
 		 * reference count should not be 0.
 		 */
 		cl->qdisc = &noop_qdisc;
-		atomic_set(&cl->nq.refcnt, 1);
+		nss_qdisc_atomic_set(&cl->nq);
 		*arg = (unsigned long)cl;
 
-		nss_qdisc_info("Adding classid %u to qdisc %p hash queue %p\n", classid, sch, &q->clhash);
+		nss_qdisc_info("Adding classid %u to qdisc %px hash queue %px\n", classid, sch, &q->clhash);
 
 		/*
 		 * This is where a class gets initialized. Classes do not have a init function
@@ -286,7 +302,8 @@ static int nss_wrr_change_class(struct Q
 		 * here.
 		 */
 		cl->nq.parent = &q->nq;
-		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_WRR_GROUP, classid, accel_mode) < 0) {
+		if (nss_qdisc_init(sch, &cl->nq, NSS_SHAPER_NODE_TYPE_WRR_GROUP, classid, accel_mode, extack) < 0)
+		{
 			nss_qdisc_error("Nss init for class %u failed\n", classid);
 			return -EINVAL;
 		}
@@ -330,11 +347,6 @@ static int nss_wrr_change_class(struct Q
 		 */
 		qdisc_class_hash_grow(sch, &q->clhash);
 
-		/*
-		 * Start the stats polling timer
-		 */
-		nss_qdisc_start_basic_stats_polling(&cl->nq);
-
 		nss_qdisc_info("Class %u successfully allocated\n", classid);
 	}
 
@@ -401,7 +413,7 @@ static int nss_wrr_delete_class(struct Q
 	/*
 	 * The message to NSS should be sent to the parent of this class
 	 */
-	nss_qdisc_info("Detaching nss_wrr class: %p\n", cl);
+	nss_qdisc_info("Detaching nss_wrr class: %px\n", cl);
 	nim.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = q->nq.qos_tag;
 	nim.msg.shaper_configure.config.msg.shaper_node_config.snc.wrr_detach.child_qos_tag = cl->nq.qos_tag;
 	if (nss_qdisc_node_detach(&q->nq, &cl->nq, &nim,
@@ -412,17 +424,33 @@ static int nss_wrr_delete_class(struct Q
 	sch_tree_lock(sch);
 	qdisc_reset(cl->qdisc);
 	qdisc_class_hash_remove(&q->clhash, &cl->cl_common);
-	refcnt = atomic_sub_return(1, &cl->nq.refcnt);
+
+	refcnt = nss_qdisc_atomic_sub_return(&cl->nq);
+
 	sch_tree_unlock(sch);
+
+	/*
+	 * For 5.4 and above kernels, calling nss_htb_destroy_class
+	 * explicitly as there is no put_class which would have called
+	 * nss_wrr_destroy_class when refcnt becomes zero.
+	 */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0))
+	nss_wrr_destroy_class(sch, cl);
+#else
 	if (!refcnt) {
-		nss_qdisc_error("Reference count should not be zero for class %p\n", cl);
+		nss_qdisc_error("Reference count should not be zero for class %px\n", cl);
 	}
-
+#endif
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
 								 struct Qdisc **old)
+#else
+static int nss_wrr_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,
+								 struct Qdisc **old, struct netlink_ext_ack *extack)
+#endif
 {
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)arg;
@@ -430,10 +458,10 @@ static int nss_wrr_graft_class(struct Qd
 	struct nss_if_msg nim_attach;
 	struct nss_qdisc *nq_new = qdisc_priv(new);
 
-	nss_qdisc_info("Grafting class %p\n", sch);
+	nss_qdisc_info("Grafting class %px\n", sch);
 
 	if (cl == &q->root) {
-		nss_qdisc_error("Can't graft root class %p\n", cl);
+		nss_qdisc_error("Can't graft root class %px\n", cl);
 		return -EINVAL;
 	}
 
@@ -448,10 +476,10 @@ static int nss_wrr_graft_class(struct Qd
 	 * Since we initially attached a noop qdisc as child (in Linux),
 	 * we do not perform a detach in the NSS if its a noop qdisc.
 	 */
-	nss_qdisc_info("Grafting old: %p with new: %p\n", *old, new);
+	nss_qdisc_info("Grafting old: %px with new: %px\n", *old, new);
 	if (*old != &noop_qdisc) {
 		struct nss_qdisc *nq_child = qdisc_priv(*old);
-		nss_qdisc_info("Detaching old: %p\n", *old);
+		nss_qdisc_info("Detaching old: %px\n", *old);
 		nim_detach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = cl->nq.qos_tag;
 		if (nss_qdisc_node_detach(&cl->nq, nq_child, &nim_detach,
 				NSS_SHAPER_CONFIG_TYPE_SHAPER_NODE_DETACH) < 0) {
@@ -464,7 +492,7 @@ static int nss_wrr_graft_class(struct Qd
 	 * to the NSS.
 	 */
 	if (new != &noop_qdisc) {
-		nss_qdisc_info("Attaching new: %p\n", new);
+		nss_qdisc_info("Attaching new: %px\n", new);
 		nim_attach.msg.shaper_configure.config.msg.shaper_node_config.qos_tag = cl->nq.qos_tag;
 		nim_attach.msg.shaper_configure.config.msg.shaper_node_config.snc.wrr_group_attach.child_qos_tag = nq_new->qos_tag;
 		if (nss_qdisc_node_attach(&cl->nq, nq_new, &nim_attach,
@@ -486,7 +514,7 @@ static int nss_wrr_graft_class(struct Qd
 static struct Qdisc *nss_wrr_leaf_class(struct Qdisc *sch, unsigned long arg)
 {
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)arg;
-	nss_qdisc_info("nss_wrr class leaf %p\n", cl);
+	nss_qdisc_info("nss_wrr class leaf %px\n", cl);
 
 	/*
 	 * Since all nss_wrr groups are leaf nodes, we can always
@@ -497,18 +525,19 @@ static struct Qdisc *nss_wrr_leaf_class(
 
 static void nss_wrr_qlen_notify(struct Qdisc *sch, unsigned long arg)
 {
-	nss_qdisc_info("nss_wrr qlen notify %p\n", sch);
+	nss_qdisc_info("nss_wrr qlen notify %px\n", sch);
 	/*
 	 * Gets called when qlen of child changes (Useful for deactivating)
 	 * Not useful for us here.
 	 */
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 static unsigned long nss_wrr_get_class(struct Qdisc *sch, u32 classid)
 {
 	struct nss_wrr_class_data *cl = nss_wrr_find_class(classid, sch);
 
-	nss_qdisc_info("Get nss_wrr class %p - class match = %p\n", sch, cl);
+	nss_qdisc_info("Get nss_wrr class %px - class match = %px\n", sch, cl);
 
 	if (cl != NULL) {
 		atomic_add(1, &cl->nq.refcnt);
@@ -520,16 +549,30 @@ static unsigned long nss_wrr_get_class(s
 static void nss_wrr_put_class(struct Qdisc *sch, unsigned long arg)
 {
 	struct nss_wrr_class_data *cl = (struct nss_wrr_class_data *)arg;
-	nss_qdisc_info("nss_wrr put class for %p\n", cl);
+	nss_qdisc_info("nss_wrr put class for %px\n", cl);
 
 	/*
 	 * We are safe to destroy the qdisc if the reference count
 	 * goes down to 0.
 	 */
-	if (atomic_sub_return(1, &cl->nq.refcnt) == 0) {
+	if (nss_qdisc_atomic_sub_return(&cl->nq) == 0) {
 		nss_wrr_destroy_class(sch, cl);
 	}
 }
+#else
+static unsigned long nss_wrr_search_class(struct Qdisc *sch, u32 classid)
+{
+	struct nss_wrr_class_data *cl = nss_wrr_find_class(classid, sch);
+
+	nss_qdisc_info("Get nss_wrr class %px - class match = %px\n", sch, cl);
+
+	if (cl != NULL) {
+		atomic_add(1, &cl->nq.refcnt.refs);
+	}
+
+	return (unsigned long)cl;
+}
+#endif
 
 static int nss_wrr_dump_class(struct Qdisc *sch, unsigned long arg, struct sk_buff *skb,
 		struct tcmsg *tcm)
@@ -538,7 +581,7 @@ static int nss_wrr_dump_class(struct Qdi
 	struct nlattr *opts;
 	struct tc_nsswrr_class_qopt qopt;
 
-	nss_qdisc_info("Dumping class %p of Qdisc %x\n", cl, sch->handle);
+	nss_qdisc_info("Dumping class %px of Qdisc %x\n", cl, sch->handle);
 
 	qopt.quantum = cl->quantum;
 
@@ -550,7 +593,7 @@ static int nss_wrr_dump_class(struct Qdi
 	tcm->tcm_handle = cl->cl_common.classid;
 	tcm->tcm_info = cl->qdisc->handle;
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL || nla_put(skb, TCA_NSSWRR_CLASS_PARMS, sizeof(qopt), &qopt)) {
 		goto nla_put_failure;
 	}
@@ -565,7 +608,7 @@ static int nss_wrr_dump_class_stats(stru
 {
 	struct nss_qdisc *nq = (struct nss_qdisc *)arg;
 
-	if (nss_qdisc_gnet_stats_copy_basic(d, &nq->bstats) < 0 ||
+	if (nss_qdisc_gnet_stats_copy_basic(sch, d, &nq->bstats) < 0 ||
 			nss_qdisc_gnet_stats_copy_queue(d, &nq->qstats) < 0) {
 		return -1;
 	}
@@ -580,7 +623,7 @@ static void nss_wrr_walk(struct Qdisc *s
 	struct nss_wrr_class_data *cl;
 	unsigned int i;
 
-	nss_qdisc_info("In nss_wrr walk %p\n", sch);
+	nss_qdisc_info("In nss_wrr walk %px\n", sch);
 	if (arg->stop)
 		return;
 
@@ -600,14 +643,22 @@ static void nss_wrr_walk(struct Qdisc *s
 	}
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_init_qdisc(struct Qdisc *sch, struct nlattr *opt)
 {
+	struct netlink_ext_ack *extack = NULL;
+#else
+static int nss_wrr_init_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+{
+#endif
 	struct nss_wrr_sched_data *q = qdisc_priv(sch);
+	struct nlattr *tb[TCA_NSSWRR_MAX + 1];
 	int err;
 	struct nss_if_msg nim;
 	struct tc_nsswrr_qopt *qopt;
 
-	nss_qdisc_info("Init nss_wrr qdisc %p\n", sch);
+	nss_qdisc_info("Init nss_wrr qdisc %px\n", sch);
 
 	err = qdisc_class_hash_init(&q->clhash);
 	if (err < 0) {
@@ -620,7 +671,11 @@ static int nss_wrr_init_qdisc(struct Qdi
 	qdisc_class_hash_insert(&q->clhash, &q->root.cl_common);
 	qdisc_class_hash_grow(sch, &q->clhash);
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		nss_qdisc_warning("Failed to parse input");
 		return -EINVAL;
@@ -629,7 +684,7 @@ static int nss_wrr_init_qdisc(struct Qdi
 	/*
 	 * Initialize the NSSWRR shaper in NSS
 	 */
-	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_WRR, 0, qopt->accel_mode) < 0) {
+	if (nss_qdisc_init(sch, &q->nq, NSS_SHAPER_NODE_TYPE_WRR, 0, qopt->accel_mode, extack) < 0) {
 		nss_qdisc_warning("Failed init nss_wrr qdisc");
 		return -EINVAL;
 	}
@@ -661,16 +716,17 @@ static int nss_wrr_init_qdisc(struct Qdi
 
 	nss_qdisc_info("Nsswrr initialized - handle %x parent %x\n", sch->handle, sch->parent);
 
-	/*
-	 * Start the stats polling timer
-	 */
-	nss_qdisc_start_basic_stats_polling(&q->nq);
-
 	return 0;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
 static int nss_wrr_change_qdisc(struct Qdisc *sch, struct nlattr *opt)
+#else
+static int nss_wrr_change_qdisc(struct Qdisc *sch, struct nlattr *opt,
+				struct netlink_ext_ack *extack)
+#endif
 {
+	struct nlattr *tb[TCA_NSSWRR_MAX + 1];
 	struct nss_wrr_sched_data *q;
 	struct tc_nsswrr_qopt *qopt;
 
@@ -680,7 +736,11 @@ static int nss_wrr_change_qdisc(struct Q
 		return -EINVAL;
 	}
 
-	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0))
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS);
+#else
+	qopt = nss_qdisc_qopt_get(opt, nss_wrr_policy, tb, TCA_NSSWRR_MAX, TCA_NSSWRR_QDISC_PARMS, extack);
+#endif
 	if (!qopt) {
 		return -EINVAL;
 	}
@@ -694,8 +754,13 @@ static int nss_wrr_change_qdisc(struct Q
 
 static void nss_wrr_reset_class(struct nss_wrr_class_data *cl)
 {
+	if (cl->qdisc == &noop_qdisc) {
+		nss_qdisc_trace("Class %x has no child qdisc to reset\n", cl->nq.qos_tag);
+		return;
+	}
+
 	nss_qdisc_reset(cl->qdisc);
-	nss_qdisc_info("Nsswrr class resetted %p\n", cl->qdisc);
+	nss_qdisc_info("Nsswrr class resetted %px\n", cl->qdisc);
 }
 
 static void nss_wrr_reset_qdisc(struct Qdisc *sch)
@@ -711,7 +776,7 @@ static void nss_wrr_reset_qdisc(struct Q
 	}
 
 	nss_qdisc_reset(sch);
-	nss_qdisc_info("Nsswrr qdisc resetted %p\n", sch);
+	nss_qdisc_info("Nsswrr qdisc resetted %px\n", sch);
 }
 
 static void nss_wrr_destroy_qdisc(struct Qdisc *sch)
@@ -734,8 +799,8 @@ static void nss_wrr_destroy_qdisc(struct
 			 * care of by the nss_wrr_destroy() function.
 			 */
 			if (cl == &q->root) {
-				nss_qdisc_info("We do not detach or destroy nss_wrr class %p here since this is "
-						"the qdisc %p\n", cl, sch);
+				nss_qdisc_info("We do not detach or destroy nss_wrr class %px here since this is "
+						"the qdisc %px\n", cl, sch);
 				continue;
 			}
 
@@ -743,7 +808,7 @@ static void nss_wrr_destroy_qdisc(struct
 			 * Reduce refcnt by 1 before destroying. This is to
 			 * ensure that polling of stat stops properly.
 			 */
-			atomic_sub(1, &cl->nq.refcnt);
+			 nss_qdisc_atomic_sub(&cl->nq);
 
 			/*
 			 * Detach class before destroying it. We dont check for noop qdisc here
@@ -766,17 +831,12 @@ static void nss_wrr_destroy_qdisc(struct
 	qdisc_class_hash_destroy(&q->clhash);
 
 	/*
-	 * Stop the polling of basic stats
-	 */
-	nss_qdisc_stop_basic_stats_polling(&q->nq);
-
-	/*
 	 * Now we can go ahead and destroy the qdisc.
 	 * Note: We dont have to detach ourself from our parent because this
 	 *	 will be taken care of by the graft call.
 	 */
 	nss_qdisc_destroy(&q->nq);
-	nss_qdisc_info("Nsswrr destroyed %p\n", sch);
+	nss_qdisc_info("Nsswrr destroyed %px\n", sch);
 }
 
 static int nss_wrr_dump_qdisc(struct Qdisc *sch, struct sk_buff *skb)
@@ -794,7 +854,7 @@ static int nss_wrr_dump_qdisc(struct Qdi
 
 	opt.accel_mode = nss_qdisc_accel_mode_get(&q->nq);
 
-	opts = nla_nest_start(skb, TCA_OPTIONS);
+	opts = nss_qdisc_nla_nest_start(skb, TCA_OPTIONS);
 	if (opts == NULL) {
 		goto nla_put_failure;
 	}
@@ -809,9 +869,18 @@ nla_put_failure:
 	return -EMSGSIZE;
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static int nss_wrr_enqueue(struct sk_buff *skb, struct Qdisc *sch)
+#else
+static int nss_wrr_enqueue(struct sk_buff *skb, struct Qdisc *sch,
+				struct sk_buff **to_free)
+#endif
 {
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	return nss_qdisc_enqueue(skb, sch);
+#else
+	return nss_qdisc_enqueue(skb, sch, to_free);
+#endif
 }
 
 static struct sk_buff *nss_wrr_dequeue(struct Qdisc *sch)
@@ -819,11 +888,13 @@ static struct sk_buff *nss_wrr_dequeue(s
 	return nss_qdisc_dequeue(sch);
 }
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 static unsigned int nss_wrr_drop(struct Qdisc *sch)
 {
 	nss_qdisc_info("Nsswrr drop\n");
 	return nss_qdisc_drop(sch);
 }
+#endif
 
 const struct Qdisc_class_ops nss_wrr_class_ops = {
 	.change		= nss_wrr_change_class,
@@ -831,8 +902,19 @@ const struct Qdisc_class_ops nss_wrr_cla
 	.graft		= nss_wrr_graft_class,
 	.leaf		= nss_wrr_leaf_class,
 	.qlen_notify	= nss_wrr_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_wrr_get_class,
 	.put		= nss_wrr_put_class,
+#else
+	.find       = nss_wrr_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block	= nss_qdisc_tcf_block,
+#endif
+	.bind_tcf	= nss_qdisc_tcf_bind,
+	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_wrr_dump_class,
 	.dump_stats	= nss_wrr_dump_class_stats,
 	.walk		= nss_wrr_walk
@@ -848,7 +930,9 @@ struct Qdisc_ops nss_wrr_qdisc_ops __rea
 	.enqueue	= nss_wrr_enqueue,
 	.dequeue	= nss_wrr_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_wrr_drop,
+#endif
 	.cl_ops		= &nss_wrr_class_ops,
 	.priv_size	= sizeof(struct nss_wrr_sched_data),
 	.owner		= THIS_MODULE
@@ -860,8 +944,19 @@ const struct Qdisc_class_ops nss_wfq_cla
 	.graft		= nss_wrr_graft_class,
 	.leaf		= nss_wrr_leaf_class,
 	.qlen_notify	= nss_wrr_qlen_notify,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0))
 	.get		= nss_wrr_get_class,
 	.put		= nss_wrr_put_class,
+#else
+	.find       = nss_wrr_search_class,
+#endif
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0))
+	.tcf_chain	= nss_qdisc_tcf_chain,
+#else
+	.tcf_block	= nss_qdisc_tcf_block,
+#endif
+	.bind_tcf	= nss_qdisc_tcf_bind,
+	.unbind_tcf	= nss_qdisc_tcf_unbind,
 	.dump		= nss_wrr_dump_class,
 	.dump_stats	= nss_wrr_dump_class_stats,
 	.walk		= nss_wrr_walk
@@ -877,9 +972,10 @@ struct Qdisc_ops nss_wfq_qdisc_ops __rea
 	.enqueue	= nss_wrr_enqueue,
 	.dequeue	= nss_wrr_dequeue,
 	.peek		= qdisc_peek_dequeued,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
 	.drop		= nss_wrr_drop,
+#endif
 	.cl_ops		= &nss_wrr_class_ops,
 	.priv_size	= sizeof(struct nss_wrr_sched_data),
 	.owner		= THIS_MODULE
 };
-
